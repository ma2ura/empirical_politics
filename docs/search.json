[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rによる計量政治学ノート",
    "section": "",
    "text": "はじめに\nこのウェブサイトは、2023年度秋学期に開講される「プレゼミ」のための学習用教材です。 プレゼミでは、25名の学生が集まって静かに教員の講義を聴く、といったようなことはしません。 むしろ、授業を受ける前に学生が自分で教科書や資料を読んで宿題をやり、そして教室で発表をして議論をする、という形式をとります。 いわゆる「反転授業」というやつです。\nこのプレゼミの目的は、3〜4年次に所属する専門演習(以下、ゼミ)で卒業論文を書く際に、いわゆる「実証研究」で卒論を書くための基礎知識を提供することです。 したがって、会計を専門とする学生以外もいることを想定し、どの分野のゼミに入っても役立つように、広く統計学や計量経済学の知識を習得し、それをプログラミング言語Rを使って実装できるようになることが主目的です。 このウェブサイトは、そのための教材として、以下の教科書をベースに作成されています。"
  },
  {
    "objectID": "index.html#補足",
    "href": "index.html#補足",
    "title": "計量会計学ノート",
    "section": "補足",
    "text": "補足\n本ノートは、Posit社(以前はRstudio社)が開発したQuartoというソフトウェアを使って作成されています。Quartoとは、RMarkdownの記法で書かれたテキストファイルを、knitrというソフトウェアを介して、HTMLやPDF、MS Word、EPUBなどのファイルを作成するためのソフトウェアです。\n最大の特徴は、MS ExcelとMS Wordのようにデータを分析する場所と文章を書く場所が別々ではなく、一つの画面の中でデータ分析とレポート・論文執筆を同時に行える、というものです。\nまた、Rだけでなく、PythonやJuliaといった他のプログラミング言語も文章内に埋め込むことができるため、データ分析と文章執筆を統合させる環境として非常に優れています。 プレゼミでも、Quartoを使って最終レポートの作成を行う予定です。 Quartoは今も開発が進んでいる新しいレポート作成ソフトウェアなので、情報が少ないことが難点ですが、公式サイトと私たちのRを見れば大抵のことは分かります。"
  },
  {
    "objectID": "Empoli_Chap01.html#会計を計量する",
    "href": "Empoli_Chap01.html#会計を計量する",
    "title": "1  計量会計学？",
    "section": "1.1 会計を計量する？",
    "text": "1.1 会計を計量する？\nここでは、教科書「Rによる計量政治学」の内容を「会計学」に置き換えて考えてみます。 「計量会計学」という言葉は一般的ではなく、会計学の世界では「実証的会計研究」とか「実証会計学」いう言葉が使われています。\n社会科学において、社会で生じる様々な現象（たとえば、経営現象や会計実務）を、数値化して分析することを計量化(quantification)と呼びます。 計量化されたデータを用いて、社会現象を説明しようとするアプローチを計量分析(quantitative analysis)と呼びます。 計量分析の手法は、統計学や計量経済学などの数理的な手法を用いて、社会現象を説明しようとするものです。\n会計とは経営活動から生み出される価値の変化を貨幣的に計測・記録し、その情報を整理し、集約することで、最終成果物として報告書(たとえば貸借対照表など)を作成し、それを利害関係者に報告することで、投資意思決定に役立つ情報を提供したり、利害関係者間の利害調整を行うことを目的とした一連のプロセスを意味します。 つまり会計そのものが、経営現象を計量化することを目的としているため、その最終成果物である財務諸表は、経営現象を計量化したデータの集合体と言えます。 この会計という経営実務を研究対象とした学問を会計学(accounting)といいます。\n会計学には様々な研究分野があります。 会計の歴史を研究対象とする会計史(accounting history)、会計の計算構造を研究対象とする計算構造研究(accounting structure)、簿記そのものを研究対象とする簿記論(bookkeeping)、そして、会計の実務を説明し予想するための理論の構築を目指す事実解明的な会計研究(positive accounting research)などがあります。\nとりわけ事実解明的な会計研究のうち、公表された情報を計量分析の手法を用いて分析する会計研究を、実証会計学(archival based empirical accounting)とか、単に実証会計と呼びます。 実証会計以外の事実解明的な研究には、実験により生成されたデータを分析する実験会計研究(experimental accounting)、データを必要とせず、数理モデルを用いて行われる分析会計研究(analytical accounting)などがあります。\n国際的に評価の高い会計学の学術誌である、The Accounting Review(TAR)、Journal of Accounting and Economics(JAE)、Journal of Accounting Research(JAR)、Review of Accounting Studies(RAST)、Contemporary Accounting Research(CAR)の五大誌に掲載されている論文の大部分が、会計情報を用いた計量分析となっています。 ただこの5誌はすべて北米の研究機関や大学が発行している雑誌ですので、実証、実験、分析的な会計研究がメインストリームの扱いとなりますが、ヨーロッパでは、 Accounting, Organisation snd Society(AOS)、European Accounting Research(EAR)、British Accounting Research(BAR)、Critical Accounting Research(CAR)といった、定性的研究も重要視し、経済学ではなく社会学をベースとした研究が主流？となっている雑誌もあります。しかし松浦は社会学について語れる知識がないので、やはり沈黙します。"
  },
  {
    "objectID": "Empoli_Chap01.html#分析的会計研究と実証的会計研究",
    "href": "Empoli_Chap01.html#分析的会計研究と実証的会計研究",
    "title": "1  計量会計学？",
    "section": "1.2 分析的会計研究と実証的会計研究",
    "text": "1.2 分析的会計研究と実証的会計研究\n会計研究の世界では、1960年頃までは規範的研究(normative research)という「〇〇するべき」という主張をする研究が主流でした。たとえば企業が保有する株式を時価評価すべきかとか、ある特徴をもつリース資産を購入したものとして扱うべきか、といったものです。\nしかし、1968年にJournal of Accounting Researchに掲載されたBall and Brown (1968) An Empirical Evaluation of Accounting Income Numbersを皮切りに、実際に会計情報は投資家の役に立っているのかをデータを使って確かめる、という、いわゆる実証研究が行われるようになり、今日まで会計研究の主要分野となっています。\n実証的会計研究を行うために必要な知識・技術として、\n\n会計基準・会計理論\nミクロ経済学（ゲーム理論、契約理論、情報の経済学）\n計量経済学\nファイナンス理論（コーポレート・ファイナンス）\nプログラミング\n\nが挙げられます。\n同じ事実解明型研究の中でも、証拠では無く論理による主張を目指す分析的会計研究で必要な知識・技術として、\n\n会計基準・会計理論\nミクロ経済学（ゲーム理論、契約理論、情報の経済学）\n最適化理論\n差分方程式\n\nが挙げられます。 そもそも分析的会計研究は、会計現象を抽象化し、数学でその現象を表現するモデルを作り、そのモデルを解くことで得られる均衡解を比較静学することで様々なインプリケーションを得るため、実際に発生していない問題も研究することできる利点があります。 その反面、要求されるモデルを作るセンスや、解けるモデルを構築するための数学レベルも高く、また研究に要する時間も長いため、実証的会計研究に比べて論文が少ないです。 しかし、理論と実証は研究の両輪をなすものであり、どちらも重要であることに違いはないので、完全に理解することはできなくても、目を通す努力は必要でしょう。\nただやはり難しい数式が出てくる会計研究は松浦には完全に理解することはできないので、ここでは実証的会計研究について考えていきます。ヴィトゲンシュタインの言葉を借りれば、語り得ないものは語らないということで、分析的会計研究は沈黙するべきです。"
  },
  {
    "objectID": "Empoli_Chap01.html#footnotes",
    "href": "Empoli_Chap01.html#footnotes",
    "title": "1  計量会計学？",
    "section": "",
    "text": "ちなみに(広義の)事実解明的な会計研究(positive accounting research)とは、会計実務を説明し予想するための理論の構築を目指す学問を指す会計研究を意味します。いまのところは、特に覚える必要はないです。\n他にも、事実解明的な会計研究として、数理モデルを用いた分析的会計研究(analytical accounting research)、実験経済を用いた実験会計研究(experimental accounting research)、行動科学の理論を用いた会計研究(behavioral accounting research)があります。\nその他にも、簿記を研究対象とした簿記論、会計計算の仕組みを研究する計算構造研究、会計の歴史を研究する会計史など様々な研究分野があります。↩︎"
  },
  {
    "objectID": "Empoli_Chap02.html#リサーチクエスチョンの種類",
    "href": "Empoli_Chap02.html#リサーチクエスチョンの種類",
    "title": "2  研究テーマの選び方",
    "section": "2.1 リサーチ・クエスチョンの種類",
    "text": "2.1 リサーチ・クエスチョンの種類\nリサーチ・クエスチョン(research question)とは、研究対象となる会計に関する、抽象度の高い問いのことです。 リサーチ・クエスチョンが決まれば、その問いに答えるために、何をするべきなのかが決まるため、非常に重要な要素となります。 たとえば、\n\n会計情報の質が高いと、投資家の意思決定がよりよいものになるのか？\n大きな監査法人は、財務報告の質を高めているのか？\nCSR活動に積極的な会社は、納税も積極的か？\nのれんは償却するべきか？\nIFRS採用企業と非採用企業の違いはあるのか？\nコロナ禍における利益圧縮活動は行われたのか？\n\nこれらのリサーチ・クエスチョンを3つに分類してみましょう。\n\n2.1.1 実証的問題\n実証的問題では、事実を調べることが目的となります。 たとえば、「のれんの非償却はM&Aを促進させるのか」という問いに対しては、のれんの非償却を行っている企業と、行っていない企業のM&Aの実施率を比較することで、その問いに答えることができます。\n実証的問題を扱う会計研究でも、定量的な研究だけでなく、インタビューによる定性的な研究もあります。参与観察研究はあまり見ません。 事実に注目する研究となるため、主観的な要素はできるだけ排して、観察されたデータや発言といった客観的なデータを用いることが多いです。 このプレゼミでは、主として経営学分野における実証的問題を扱います。\n\n\n2.1.2 規範的問題\nいわゆる「べき論」を扱う問題で、日本の会計研究では今でも盛んに行われている研究です。 たとえば、「のれんは償却すべきか」という問いに対しては、のれんの償却を行うことで、どのようなメリットがあるのか、どのようなデメリットがあるのかを考え、そのメリットとデメリットを比較することで、その問いに答えることができます。 ただ、この場合でも、「誰にとっての」メリットを重視するべきなのか、という問題がでますが、そこは研究者の価値判断によって決まることになり、研究者の主観が大きく反映されることになります。\nしたがって教科書でも、規範的問題を実証的問題に変換する方法を考え、規範的問題を直接あつかう研究課題は取りあげません。\n\n\n2.1.3 分析的問題\n分析的問題は、まだ起こっていない、観察されていない現象を扱います。 そもそも起こっていない現象なのでデータも取りようがありません。 そこで、分析的問題では、モデル(model)を用いて、現象の起こりうるメカニズムを考えます。\n基本的には、関心のある問題を抽象化して数式で表現し、前提条件と仮定を設定し、その問題を解くことで得られた結果を解釈することで、その問いに答えることができます。 たとえば、税務会計や監査といった情報が入手困難な領域において、ゲーム理論や契約理論、最適化理論を用いた分析が行われることが多いような気がしますが、そこまで詳しくないでし、難しいので、ここでは扱いません。\nしたがって、このプレゼミでは、各自がたてた実証的問題について考えていきます。"
  },
  {
    "objectID": "Empoli_Chap02.html#よい研究テーマの見つけ方",
    "href": "Empoli_Chap02.html#よい研究テーマの見つけ方",
    "title": "2  研究テーマの選び方",
    "section": "2.2 「よい研究テーマ」の見つけ方",
    "text": "2.2 「よい研究テーマ」の見つけ方\n政治学のMonroe (2000, pp.8–10)によると、\n\n明快さ\n検証可能性\n理論的重要性\n実用性\n独創性\n\nがよい研究テーマに必要な要素らしいです。\n詳しくは教科書を読むとして、会計学や経営学でもほぼ同じですが、卒業論文においては、理論的重要性と独創性はあればよいですが、必ずしも必要ではありません。 なぜなら、理論的重要性を理解し、論文で示すことは、研究で用いる推論の背後にある理論や仕組みを完全に理解する必要がありますし、独創性を主張するためには、膨大な先行研究を読み、自分の主張が他の人とどう違うのか、どの点が新しいのかを明らかにする必要があり、とても時間がかかるからです。\nしたがって、明快な推論で導き出された仮説を、客観的なデータを用いて、適切な手法で分析し、その結果を解釈し、経営実務にどういう影響があるのか、を主張できれば、卒業論文としては申し分ないレベルです。\nとりわけ、このプレゼミでは、検証可能性を重視します。 そのレポート・論文を読めば、他の人でも同じ分析を行うことが可能であり、誰でも追試が行えることが重要です。 データの集め方や変数の作り方、データ分析のプロセスが明確にしめされており、それを自分でもすぐに再現することが重要です。そのためにRは非常に有効なツールとなります。\n\n2.2.1 規範的問題から実証的問題への変換\n「べき論」は研究者の価値判断が大きく反映され、その研究者が主張する価値は主観的なものになるため検証ができません。 そこで規範的問題を実証的問題になるように問い方を変える方法を考えます。\n\n1つめの方法は、参照枠組みを変える方法です。 「会計は投資意思決定に役立つべきである」という問いは規範的問題で、それは「会計は株主のためのものである」という価値判断が含まれています。このままでは検証できないので、「会計は投資意思決定に役に立っているのか？」に変えることで、検証可能な問いになります。\n\n2つめの方法は、規範的問題の前提条件に注目する方法です。 「会計は投資意思決定の役立つべきである」という規範的記述の背後には、\n\n会計は投資家のためのものである\n投資家が会計(情報)を使えば儲かる。\n投資家の投資が活発になれば、経済は活性化する。\n\nという前提条件があると考えられます。 これを実証的な問題にするには、\n\n会計(情報)の主な利用者は投資家なのか？\n会計情報を使えば儲かるのか？\n投資の役に立つ会計情報を提供することで、経済は活性化するのか？\n\nのように、規範的問題の背後にある前提条件を検証可能な問いに変えることで、実証的な問題になります。\n\n\n2.2.2 パズルを探す\nパズル(puzzle)とは、ある現象を説明するために、既存の理論では説明できない現象のことです。 たとえば、配当パズル(dividend puzzle)とは、配当がなぜ存在するのか、という問題です。 配当は、株主に対する利益配分の一つであり、株主にとっては配当が高いほうがよいはずです。しかし、実際には、配当が高いほど株価が低くなるという現象が観察されます。 このような現象を説明するために、既存の理論では説明できないので、パズルと呼ばれ、研究題材としては非常に魅力的です。\n\n\n2.2.3 研究論文の構成\n実証研究の論文構成は、ほぼ以下のような構成となっています。\n\nイントロダクション\n先行研究\n理論\n仮説\n対抗仮説\n作業化\n証拠\n結論\n\nこのうち、1-4は、研究の背景を説明する部分であり、5-7は、研究の主要な部分であり、8は、研究のまとめです。"
  },
  {
    "objectID": "Empoli_Chap03.html#よい理論とは",
    "href": "Empoli_Chap03.html#よい理論とは",
    "title": "3  理論と仮説",
    "section": "3.1 「よい理論」とは？",
    "text": "3.1 「よい理論」とは？\n実証研究のリサーチ・デザイン(research design)のプロセスは次のような手順になります。\n\nパズルを見つける（簡単には見付からないです）\nパズルを説明するための複数の前提条件を使って理論を作る。（前提条件を自分で考えるのは難しすぎるので、先行研究を参考にすることが多いです。理論はパズルを説明するための仮説の集合体です。）\n理論から作業仮説(working hypothesis, hypothesis)を引き出す。\n作業仮説を検証するためのデータを集める。\nデータを使って作業仮説を検証し、理論の妥当性を確かめる。\n\n理想的にはこうなるでしょうが、現実にはこんなにうまくいきませんが、この講義では3〜5のプロセスを重視します。というのも、1と2のステップはかなり難しいので、現実には、\n\n興味のある経営現象を見つけて調べる。\n経営現象の発生を説明するための理論を見つけるために、先行研究を漁る。\n先行研究を参考にして作業仮説を作る。\n\nという風に行われることが多い（と思います。たぶん）\n\n3.1.1 因果法則の3つの条件\n因果関係(causality)と相関関係(correlation)の違いを理解しておきましょう。\n因果関係は、近年の社会科学領域の研究で最も注目されているキーワードでしょう。 もともと因果関係を特定し、推定する研究は数多く行われてきましたが、近年になって発達した計量経済学や実験経済学の手法を使って、より厳密に因果関係を特定しようとする研究が増え、因果関係を適切に特定することの重要性が認識されるようになりました。\n例えば、こんな本が近年出版されています。\n\n\n\n\n\n\n因果推論入門：基礎から現代的アプローチまで\n\n\n\n\n\n\n\n統計的因果推論の理論と実装\n\n\n\n\n\n\n\n効果検証入門\n\n\n\n\n\n因果関係とは、原因(causal)と結果(outcome)の関係のことです。正確に言うと、ある要因Xを操作するとき、別の要因Yが変化することです(Imbens and Rubin, 2015, p.4)。\n因果関係を考える際には、「効果をもたらした原因」(causal of effect)と「原因のもたらす効果」(effect of cause)の両方を考える必要があります。 例えば、ある企業が従業員の給料を上げたとします。 このとき、従業員の給料が上がったことが「効果をもたらした原因」であり、従業員の給料が上がったことによって、従業員のモチベーションが上がったことが「原因のもたらす効果」です。 定量的な研究では、「原因のもたらす効果」を分析することが多いです。\n因果関係があると考えるためには、3つの条件を確かめる必要があります。\n\n原因が結果より先に起こる。\n原因と結果が共変する。\n原因以外の重要な要因が変化しない。\n\nこの因果関係を記述するものを理論といいます。\n\n\n3.1.2 理論とは\n理論とは「原因と結果について一般的な論述」で、「〇〇であるとき、△△が起こる」というようなものです。推論といってもよいです。 原因と結果の関係を「説明変数X」(explanatory variable)と「応答変数Y」(response variable)の関係として表現します。\n\nX \\Longrightarrow Y\n\n推論を作る際には，どれだけ説得力があり納得できる仮定を設定するかが重要となります。仮定のない推論など役に立たないからです。 経営学は独自の理論をもたない学問とも言われ，とりわけ会計学における事実解明的研究(positive research)では，心理学や経済学で蓄積された理論を借用することが多いです（松浦は経済学に基づく推論を行っています）。\n\n\n3.1.3 良い理論とは？\n良い理論・推論が持つべき性質は次のようなものです。\n\n反証可能であること\n観察可能な予測が多いこと\n具体的であること\nシンプルであること\n\n以下ではそれぞれについて簡単に説明します。\n\n反証可能であること\n「反証可能性」(falsifiability)という科学で最も重要な特性の1つを確保する必要があります 1 。\nつまり，論文を読んだ人ならだれでも，「この理論は間違っている」ということを示すことができるようにする必要があります。 反証可能性がない主張は占いと変わりません。\n\n\n観察可能な予測が多いこと\n結果として発生する現象が観察可能である予測を行う必要があることを示しています。 当然ですが，自分の主張を証拠を用いて説得力を高めようとしているのですから，その予測が当たっているのかどうかを確認できる必要があります。\n\n\n具体的であること\n「業績が悪くなる」のようにあいまいな表現ではなく，「昨年度と比べて利益が減少する」とか「累積リターンがマイナスになる」といったように，具体的な予測を行う必要があります。「リスク」とか「パフォーマンス」とか「悪くなる」とか「加速する」といったあいまいな言葉は常に定義してから使うようにしましょう。\n\n\nシンプルであること\n理論はシンプルでなければなりません。 理解しやすく，使える範囲が広く，反証可能性が高い理論は，シンプルになっていきます。\n基本的には，先行研究で使われている理論を援用することが多い経営学・会計学では，先行研究で用いられた理論や推論に無駄がないかどうか，よりシンプルにいえないかどうか，を考えることが多いです。\n理論をシンプルにするには，前提となる条件を少なくする必要があります。 観察された経営現象をそのまま記述しようとすると非常に長く，複雑な文章になるでしょう。 それでは何が本質的に重要か分からないので，経営現象を抽象化・単純化することで，本質以外のものをそぎ落とし，理論をシンプルにすることがで，経営現象への理解がより深まります(オッカムの剃刀)。"
  },
  {
    "objectID": "Empoli_Chap03.html#仮説と仮説検証",
    "href": "Empoli_Chap03.html#仮説と仮説検証",
    "title": "3  理論と仮説",
    "section": "3.2 仮説と仮説検証",
    "text": "3.2 仮説と仮説検証\n\n3.2.1 仮説とは\n科学的には，「理論」と「仮説」とは同じものです。 反証されずに生き残った理論を仮説(hypothesis)と呼びます。 たとえば、ニュートンの万有引力の法則は，現在でも仮説として使われています。\nこの「仮説」をより具体的にしたものを「作業仮説」(working hypothesis)と呼びます。\n\n作業仮説とは，自分が使える特定の変数についての記述\n「もしこの仮説が正しければ・・・のはず」\n理論より作業仮説の方が具体的である\n仮説から引き出される観察可能な予測について述べる\n\n\n\n3.2.2 作業仮説\nたとえば「監査の質が高いほど，財務報告の質が高くなる」という理論から，作業仮説を引き出してみましょう。 この文章の中で，\n\n監査の質\n高い\n財務報告の質\n高い\n\nという4つの用語を，測定可能な尺度にして，その高低を定義する必要があります。\nたとえば，監査の質を「監査報酬額」で測定して，財務報告の質を利益操作の程度で測定するとします。利益操作の程度を異常アクルーアルで代理すると\n\n監査報酬が、同業他社平均より高い企業ほど，異常アクルーアルの絶対値が小さい\n\nという作業仮説を立てることができます。\n理論から作業仮説を導出することは、構成概念から代理変数を導出すること深く関連しています。 この作業のコツをつかむには、良質な論文を読んで、自分でまとめてみて、他人に聞いてもらい、議論することが重要です。 そうして、自分の理論を作り上げていくのです。"
  },
  {
    "objectID": "Empoli_Chap03.html#footnotes",
    "href": "Empoli_Chap03.html#footnotes",
    "title": "3  理論と仮説",
    "section": "",
    "text": "「反証不可能な理論は科学ではない」といったのは，科学哲学者カール・ポパー(Karl Popper)です。 Popper (1959) The Logic of Scientific Discovery, London: Hutchinson.（邦訳：ポパー（1971）『科学的発見の論理 上下巻』，恒星社厚生閣）↩︎"
  },
  {
    "objectID": "Empoli_Chap04.html#rとrstudio",
    "href": "Empoli_Chap04.html#rとrstudio",
    "title": "4  Rの使い方",
    "section": "4.1 RとRstudio",
    "text": "4.1 RとRstudio\n教科書を見ながらRとRstduioを自分PCにインストールしてください。 以下のウェブサイトが超参考になります。 自分のPCのOSに応じて、資料を見ながらインストールしてください。\n矢内先生のウェブサイト\nあるいは、Posit Cloudを使ってウェブ上でRstudioを使えるようにしてください。\nPosit Cloud"
  },
  {
    "objectID": "Empoli_Chap04.html#visual-studio-codeの使い方",
    "href": "Empoli_Chap04.html#visual-studio-codeの使い方",
    "title": "4  Rの使い方",
    "section": "4.2 Visual Studio Codeの使い方",
    "text": "4.2 Visual Studio Codeの使い方\nPosit Cloudを使わずに、自分のPCでRを使うことを選択した人は、以下の作業に進みますが、まずは矢内先生のウェブサイトなどを参考に、RとRstudioをインストールはインストールしておいてください。\n教科書では、Posit社のRstudioの説明をしていますが、RstudioはR専用のIDE（統合開発環境）で、R以外の言語を書くことはできませんし、少々重たいです。 そこでここでは、Microsoft社のVisual Studio Codeを使ってRを書く方法を説明します。\nマイクロソフト社のウェブサイトから、自分のPCのOSに合わせて、Visual Studio Codeをインストールしてください。\nまずGoogle等で「Visual Studio Code」と検索して、オフィシャルサイトにアクセスします。\n\n\n\nVisual Studio Codeのオフィシャルサイト\n\n\nそして、「Visual Studio Codeをダウンロードする」をクリックすると、次のページにいきます。\n\n\n\nVisual Studio Codeのダウンロードページ\n\n\nここから自分に合ったOSを選んで、ダウンロードしてください。 詳しい人なら、下の小さな項目から、適切なものをえらんでください。 MacBookでM2チップを使っている人は、MacのApple siliconのzipをダウンロードして、Zipファイルを展開してインストールしてください。\n\n4.2.1 Quarto\n次に、RstudioやVisual Studio Codeで、レポートや論文を書くためのパッケージであるQuartoをインストールします。 QuartoはRstudioを作ったPosit社が開発している文書作成システムなので、Rとの相性もばっちりです。\nまずGoogle等で「Quarto」と検索して、オフィシャルサイトにアクセスします。\n\n\n\nQuartoのオフィシャルサイト\n\n\nそして、「Get Started」をクリックすると、次のページにいきます。\n\n\n\nQuartoのダウンロードページ\n\n\nここから自分に合ったOSを選んで、ダウンロードしてください。\nここまでで、\n\nR (本体)\nRstudio (R用IDE)\nVisual Studio Code (R以外の言語も書けるIDE)\nQuarto (レポートや論文を書くためのパッケージ)\n\nのインストールが完了しました。 次に、Visual Studio CodeでRのソースコードを書くための準備をします。\n\n\n4.2.2 VS Codeの準備\nVisual Studio Code(以下、VS Code)の準備をします。 VS Codeを開くと、次のような画面が表示されます。 VS Codeは、機能を拡張するために、拡張パッケージをインストールすることができます。 VS Codeを起動して、左のメニューの中の、四角が4つ並んだアイコンをクリックしてください。\n\n\n\nVS Codeの初期画面\n\n\nVS Codeの左のメニュー上部に拡張パッケージの検索画面が表示されます。 そこに拡張パッケージの名前を入れて、必要なものをインストールしていきます。 以下の拡張パッケージは、Rの分析をするために必要あるいは推奨されるものです。\n\nJapanese Language Pack for Visual Studio Code : VS Codeの日本語化\nR : とりあえず入れておく\nQuarto : Quartoを使うために必要\n\nとりあえずこの3つを入れておけば、このプレゼミでは十分です。\n\n\n\nVS Codeの拡張パッケージ\n\n\n\n\n4.2.3 フォルダを開く\nVS Codeでは、分析に使うCSVファイルや、分析のためのRファイル、レポートや論文を書くためのQuartoファイルを、一つのフォルダにまとめておくと便利です。 分かりやすい場所にフォルダを作成し、好きな名前をつけてください。\nVS Codeの上部メニューの中の「ファイル」をクリックして、「フォルダーを開く」をクリックして、先ほど作成したフォルダを選択してください。 すると、左のメニューにフォルダの中身が表示されます。まだ何も入っていなければ、何も表示されません。\nVS Codeではフォルダを指定して開いておくと、そこが作業フォルダとなり、Rは常にそのフォルダの中を参照するようになります。\n\n\n4.2.4 Rスクリプトの書き方\nではVS Code上でRのソースコードを書いてみましょう。 新しいファイルを作成するためには、上のメニューから「ファイル」をクリックして、「新しいファイル」をクリックしてください。\nするとメニューが表示されその中に「R Document」を選ぶと、Rのソースコードを書くためのファイルが作成されます。 Rのソースコードは拡張子が.rというファイルになります。 拡張子が何か分からないひとは、ググっておいてください。 WindowsやMacOSでもファイルの拡張子が表示されるように設定しておいてください。"
  },
  {
    "objectID": "Empoli_Chap04.html#rの基本操作",
    "href": "Empoli_Chap04.html#rの基本操作",
    "title": "4  Rの使い方",
    "section": "4.3 Rの基本操作",
    "text": "4.3 Rの基本操作\nここまでの準備が出来ていれば、画面にRのソースコードを書くためのファイルが表示されているはずです。 何も書かれていないので、まずは何か書いてみましょう。 まずは、1+2を計算してみます。\n\n1 + 2\n\nと書いて、その行にカーソルがある状態で、Ctrl + Enterを押すと、その行の計算結果が表示されます。\n\n\n[1] 3\n\n\nあとは教科書をみて、練習しておいてください。 以下の事ができるようになっていればOKです。\n\n四則演算\nsqrt()関数で平方根の計算\nc()関数でベクトルの作成\nmean()関数で平均を計算\nseq()関数で数列の作成"
  },
  {
    "objectID": "Empoli_Chap04.html#パッケージ",
    "href": "Empoli_Chap04.html#パッケージ",
    "title": "4  Rの使い方",
    "section": "4.4 パッケージ",
    "text": "4.4 パッケージ\nRはパッケージを使って機能を拡張することができます。\n\ninstall.packages()関数でパッケージをインストールして、\nlibrary()関数でパッケージを読み込むと、\n\n拡張した機能を使えるようになります。 教科書やこの資料で使う関数はたくさんあるので、その都度説明しますが、ほぼ必ずつかうのが、tidyverseというパッケージ群です。\n以下のコードを実行して、tidyverseをインストールしてください。\n\ninstall.packages(\"tidyverse\") # 最初の一回だけ実行\n\nそして、ほぼ毎回以下のコードを実行して、tidyverseを読み込みます。\n\nlibrary(tidyverse)\n\nついでに、今後使うであろう次のパッケージもインストールしておいてください。\n\ninstall.packages(\"bloom\") # 結果の整形\ninstall.packages(\"ggthemes\") # グラフの見た目\ninstall.packages(\"modelsummary\") # 回帰結果の作表\ninstall.packages(\"kableExtra\") # 表の整形\ninstall.packages(\"gt\") # 表の整形\ninstall.packages(\"patchwork\") # グラフを並べて表示\n\n\n4.4.1 Githubとの連携\nGitHubは、Gitというバージョン管理システムを使って、ソースコードのバージョン管理をクラウド上で行うことができる無料サービスです。 使いこなすには、少々勉強が必要ですが、使えれば非常に有用なので、是非やってみてください。 Visual Studio CodeはGit/GitHubとの連携も簡単なので、複数人でウェブ開発やプログラミングをする場合には、非常に有益です。\nまずは、GitHubのウェブサイトにアクセスし、アカウントを作成してください。\nGitHub\nそこから先は、書籍やウェブサイトを参考にしてください。 例えばこんな本が便利です。\n\n\n\n\n\n\nGitHubのオススメ本\n\n\n\n\n\n\n\nはじめてでもできるGitとGitHubの教科書\n\n\n\n\n\n\n\nわかばちゃんと学ぶGit使い方入門\n\n\n\n\n\n\n\n4.4.2 GitHub Copilotを使う\nGitHub Copilotは、AIがコードの作成を支援してくれる超便利なツールです。 学生は無料で利用できるので、プログラミングを学習しようとしている人は、導入の検討をしてみてください。\nGitHub Copilot"
  },
  {
    "objectID": "Empoli_Chap04.html#まとめ",
    "href": "Empoli_Chap04.html#まとめ",
    "title": "4  Rの使い方",
    "section": "4.5 まとめ",
    "text": "4.5 まとめ\nここでは、\n\nRのインストール\nRstudioのインストール\nVS Codeのインストール\nQuartoのインストール\n\nを行い、VS Code上での分析・レポート作成環境を整えました。 また、ソースコードの書き方や、パッケージのインストール方法、GitHubとの連携方法を学び、GitHub Copilotの紹介をしました。"
  },
  {
    "objectID": "Empoli_Chap05.html#データの読み込み",
    "href": "Empoli_Chap05.html#データの読み込み",
    "title": "5  Rによるデータ操作",
    "section": "5.1 データの読み込み",
    "text": "5.1 データの読み込み\n\n5.1.1 CSVファイルの読み込み\n多くのプログラミング言語で、読み込むデータとして最も多いのが、CSV形式のファイルです。ファイルの拡張子は.csvです。 CSVとは、Comma Separated Valuesの略で、カンマで区切られたデータのことです。 次のような形をしています。\n企業ID,決算年月,売上高\n13,2020/03,1000\n13,2021/03,1200\n13,2022/03,1500\n24,2020/03,2000\n24,2021/03,2200\n24,2022/03,2500\n33,2020/03,3000\n33,2021/03,3200\n33,2022/03,3500\nこのように、値とコンマ,のみで構成されたファイルのため、余計な情報が入っておらず、またファイルサイズも小さく、加工が簡単なので、データのやり取りによく使われます。\nではファイルを読み込んでみます。ここでは、松浦のウェブサイトにあるデータkeshohin_2023.csvを読み込んでみます。 Rの場合は、read.csvという関数を使って、URLを直接指定して読み込むことができます。読み込んだデータをdfという変数に代入しています。\nExcelの場合は、インターネット上のデータを直接取り込むことは難しいので、いったんパソコンの中に保存してから、ファイルを開くとします。\n\n\n\n\n\n\nRの場合\n\n\n\n\ndf &lt;- read.csv(\"https://so-ichi.com/kesho_2023.csv\")\n\n\n\n\n\n\n\n\n\nMS Excelの場合\n\n\n\n\nURLhttps://so-ichi.com/kesho_2023.csvをブラウザに入力してファイルをダウンロードし、任意の場所に保存\n「ファイル」から「開く…」をクリックして、保存したCSVファイルを選択し「開く」をクリック\n\n\n\n\n\n5.1.2 Excelファイルの読み込み\nMS Excelのファイルは拡張子が.xlsx、古いMS Excelだと.xlsです。 RでExcelファイルを読み込むときは、read_excelという関数を使います。 Excelファイルを用意するのが面倒なので、ここではこうやれば読み込めるよ、というコードだけ説明します。ファイル名はhoge.xlsxとします。\n\n\n\n\n\n\nRの場合\n\n\n\n\ndfx &lt;- readxl::read_excel(\"hoge.xlsx\")\n\n\n\n\n\n\n\n\n\nMS Excelの場合\n\n\n\n\n「ファイル」から「開く…」をクリックし、保存してあるExcelファイルを選択し「開く」をクリック\n\n\n\nMS Excelの問題点は、目的のデータがどのExcelファイルに入っていて、それがどこに保存されているのかを覚えておかないと、いちいちファイルを開いて探さないといけないことです。\nRだとソースコードを残すことができますので、 どこにあるファイルを読み込んで、そこに何が入っているのかをコメントで残しておくことができます。"
  },
  {
    "objectID": "Empoli_Chap05.html#読み込んだデータの確認",
    "href": "Empoli_Chap05.html#読み込んだデータの確認",
    "title": "5  Rによるデータ操作",
    "section": "5.2 読み込んだデータの確認",
    "text": "5.2 読み込んだデータの確認\nMS Excelは読み込んだデータが画面上に表として表示されていますが、Rでは変数に代入しただけでは、画面には何も表示されません。 そこでデータの中身を確認する関数として、次のようなものがあります。\n\nhead() : 最初の数行を表示させる基本関数\nstr() : データの構造を表示させる基本関数\nglimpse() : データの構造を表示させるdplyrパッケージの関数\nnames() : 変数名を表示させる基本関数\n\nこれらを使って、データの中身を確認し、データの形に適した処理方法を学ぶ必要があります。 以下では、head()関数を使って、データの最初の数行を表示させてから、str()関数でデータの中の変数とその型を確認します。\nExcelは目視が中心ですが、見ただけでは、文字列なのか数なのかが分からないので、やはりデータの型は確認する必要があります。\n\n\n\n\n\n\nRの場合\n\n\n\n\nhead(df)\n\n  code   name    term shubetsu ren  sales netincome month\n1  641 資生堂 1985/11       10   1 371040     14526    12\n2  641 資生堂 1986/11       10   1 375294     13632    12\n3  641 資生堂 1987/11       10   1 378977      9014    12\n4  641 資生堂 1988/11       10   1 401311      9515    12\n5  641 資生堂 1989/03       10   1 130654      4265     4\n6  641 資生堂 1990/03       10   1 456352     11362    12\n\nstr(df)\n\n'data.frame':   130 obs. of  8 variables:\n $ code     : int  641 641 641 641 641 641 641 641 641 641 ...\n $ name     : chr  \"資生堂\" \"資生堂\" \"資生堂\" \"資生堂\" ...\n $ term     : chr  \"1985/11\" \"1986/11\" \"1987/11\" \"1988/11\" ...\n $ shubetsu : int  10 10 10 10 10 10 10 10 10 10 ...\n $ ren      : int  1 1 1 1 1 1 1 1 1 1 ...\n $ sales    : int  371040 375294 378977 401311 130654 456352 517252 553299 561549 549178 ...\n $ netincome: int  14526 13632 9014 9515 4265 11362 15850 16011 13290 14668 ...\n $ month    : int  12 12 12 12 4 12 12 12 12 12 ...\n\n\n\n\n\n\n\n\n\n\nMS Excelの場合\n\n\n\n画面を見て確認する。\n\n\nこのデータには，\n\ncode : 企業コード (文字列)\nname : 企業名 (文字列)\nterm : 決算年月 (文字列)\nshubetsu : 会計基準の種類 (数値)\nren : 連結か単体 (数値)\nsales : 売上高 (数値)\nnetincome : 当期純利益 (数値)\nmonth : 決算月数 (数値)\n\nが入っています。"
  },
  {
    "objectID": "Empoli_Chap05.html#データの整形",
    "href": "Empoli_Chap05.html#データの整形",
    "title": "5  Rによるデータ操作",
    "section": "5.3 データの整形",
    "text": "5.3 データの整形\n\n5.3.1 データ操作の基礎\nさあ面白くなってきました。 次はデータを操作していきます。 Rによるデータ操作では、tidyverseパッケージ群のdplyrパッケージが大活躍します。\ndplyrパッケージの関数の中でもよく使うものに次のようなものがあります。\n\nselect() : 変数を選択する\nfilter() : データを抽出する\nmutate() : 変数を追加する\narrange() : データを並び替える\nsummarise() : データを集計する\ngroup_by() : データをグループ化する\n\n\n\n5.3.2 パイプ演算子\nRでソースコードを書く際に，理解しやすく，読みやすいコードにするために非常に便利なのが，パイプ演算子%&gt;%です。 パイプ演算子%&gt;%は，左側のオブジェクトを右側の関数の第一引数に渡すという処理を行います。 たとえば，\n\n(1 + 2) %&gt;% sqrt()\n\n[1] 1.732051\n\n\nと書くと，sqrt(1 + 2)と同じ意味になります。 たとえば，rnorm()関数を使って平均0，分散1の標準正規分から100個のデータを作りたいとします。 rnorm()関数は3つの引数を取ります。\n\nデータの個数\n平均\n標準偏差\n\nしたがって，rnorm(100, 0, 1)と書くと，平均0，分散1の標準正規分布から100個のデータを取り出すことができます。 パイプ演算子を使うと，\n\n100 %&gt;% rnorm(mean = 0, sd = 1)\n\n  [1] -0.13855058  0.40630229 -0.99453364  1.82637391  0.53433558  0.26774452\n  [7] -0.75391277 -0.21386603  1.76205549  0.77312930 -0.49398273  0.50950365\n [13] -1.94310940 -1.13288362  0.02335503 -0.55956493 -1.30008072  1.71416832\n [19] -0.05590614 -0.79401097 -0.54611232  0.23278497  1.07999316 -0.66926774\n [25] -0.83472708 -0.18949715 -0.80648950  0.80834639  1.39743796  1.36830439\n [31] -1.65260223  1.24692659 -0.37195543 -1.43073219 -0.08068893 -1.25474192\n [37]  0.97206599  0.83081302 -0.01415092 -0.10134002 -0.48715443 -0.28273983\n [43]  0.36219639 -0.58118159  1.15875307 -3.26000186  0.74109267 -0.58075828\n [49]  1.16215761 -1.88863553  0.59915306 -1.42044416  0.15569788  1.04825193\n [55] -1.67622648  0.90884928  1.28356441  1.69870694  1.28658601 -0.57671467\n [61]  0.85096354  0.52023258 -1.29704114 -0.30973293  0.03369616  0.24250059\n [67]  1.20759313  1.24918593  0.46159647 -0.71770017  1.07297631  0.92915068\n [73]  1.00395820  1.14613336 -2.51166950  0.57258539  0.03582698 -0.92353430\n [79]  0.65630560 -1.50510045  0.68704892  1.96018690 -1.54048033 -0.36515740\n [85]  1.14022894 -0.51815577 -0.16114490 -1.25452696 -0.20637687 -2.20431278\n [91]  1.66275829 -0.13087813  1.00450181 -0.52948458 -1.10537571 -0.35919723\n [97] -0.01651456  0.81600796 -1.03855261  1.39119317\n\n\nとなります。 これはrnorm()関数の第1引数がデータの個数なので，そこに100を渡しています。 ここで平均に値を渡したい場合を考えます。 mean引数は第2引数なので，パイプ演算子では自動で渡してくれません。 そこで.を使って渡す場所を指定してあげます。\n\n100 %&gt;% rnorm(100, mean =. , sd = 1)\n\n  [1]  98.75318 100.33160 100.31035 102.08964 101.53147 101.07662 100.34746\n  [8]  99.81971  98.58614  97.89641 101.39231 100.35587 100.34040  97.90392\n [15] 100.90750  98.77400  99.90225 100.04275  99.19179 100.96493 100.52943\n [22] 100.38889 100.07317 101.86721  99.01861 100.07284 100.81163 100.07328\n [29] 100.85011 101.75133 101.24087  98.03313  99.16988  99.38769  98.20347\n [36] 102.03106  99.40235  99.92934  98.56714  98.16564  99.36703  99.65467\n [43] 100.51258  97.72171 100.02221 100.90865  98.27255 101.32566 102.18289\n [50]  99.93390 100.66779 102.87640 101.38058 100.60997 101.19266 100.41579\n [57] 100.56317  99.05145  99.28811  99.85939  98.98776 101.34850 100.47601\n [64]  99.96010 100.75102 100.77460  99.66502  99.92668 100.47253  99.85054\n [71]  99.89800 100.23464 100.23778 101.58759 100.47922  99.64237 101.63308\n [78] 100.02748 100.33454  99.93674 100.22901 101.18423 101.32615  99.73707\n [85] 101.50705  99.57612  98.95207 100.27058  98.90994  99.65414  99.04782\n [92]  98.35419 100.55828 100.15433 100.78514  99.15741 100.95199  99.55684\n [99] 100.74646  98.04072\n\n\nこれで平均100，標準偏差1の正規分布から100個のデータを取り出せました。\nこれだけだとパイプ演算子%&gt;%の便利さが伝わらないので，たとえば次のような処理を考えてみましょう。\n\n2020年のデータを抜き出し，\n売上高当期純利益率を計算し，\n産業グループごとに平均を計算する\n利益率が高い順番に並び替える\n\nをパイプ演算子を使って書くと，\n\ndf &lt;- df %&gt;%\n    filter(term == \"2020\") %&gt;% # 2020年のみ\n    mutate( # 新しい変数を作成\n        ratio = netincome / sales # 売上高利益率\n        ) %&gt;%\n    group_by(sangyo) %&gt;% # 産業グループごとに\n    summarise( # 平均を計算\n        mean_ratio = mean(ratio) # 利益率の平均\n        ) %&gt;%\n    arrange(desc(mean_ratio)) # 利益率の高い順に並び替え\n\nのように，上から順番に処理を実行し，次に渡す，というプロセスが分かりやすく，読みやすいコードができました。 コメントも残しておけば，後から見返したときにも分かりやすいですし，他人によんでもらうときも親切ですね。 したがって，以下ではパイプ演算子を駆使して，データ操作を行っていきます。\n\n\n新しい変数を作成する mutate\n新しい変数を作成するには，dplyrパッケージのmutate()関数を使います。 先ほど読みこんだデータから，当期純利益を売上高で除して売上高当期純利益率を計算して，ratioという変数を作ってみましょう。\n\n\n\n\n\n\nRの場合\n\n\n\n\ndf &lt;- df %&gt;%\n    mutate( # 新しい変数を作成\n        ratio = netincome / sales # 売上高利益率\n        )\n\n\n\n\n\n\n\n\n\nMS Excelの場合\n\n\n\nI1のセルに変数名を表すratioと入力する。 F列のsaleとG列のnetincomeを使って，I2のセルに\n= G2 / F2\nとし，I2セルの右下の四角をダブルクリックすると，自動で下のセルにも同じ計算がコピーされる。\n\n\n次に，ある変数の値に応じて異なる値をとる変数を作るには，mutate()関数とifelse()関数を同時に使います。ifelse()関数は次のような引数を取ります。\n\nifelse(条件, 条件が真のときの値, 条件が偽のときの値)\n\n先ほど計算した売上高当期純利益率が5%以上ならば「高い」，そうでなければ「低い」という変数highlowを作ってみましょう。\n\n\n\n\n\n\nRの場合\n\n\n\n\ndf &lt;- df %&gt;%\n    mutate( # 新しい変数を作成\n        highlow = ifelse(ratio &gt;= 0.05, \"高い\", \"低い\") # 売上高利益率\n        )\n\n\n\n\n\n\n\n\n\nMS Excelの場合\n\n\n\nJ1セルにhighlowと入力する。 J2セルに\n= if(I2 &gt;= 0.05, \"高い\", \"低い\")\nと入力し，J2セルの右下の四角をダブルクリックすると，自動で下のセルにも同じ計算がコピーされる。\n\n\nExcelだとセルの移動や変数名の入力，計算式の入力，セルのコピーといった作業で，キーボードとマウスを行ったり来たりする必要があり，若干面倒です。\nついでに，mutate()関数を使って，長すぎる企業名を短くしてみます。 ここでは「ポーラ・オルビスホールディングス」を「ポーラ」と略してみます。 mutate()とifelseを使って，name変数の値が「ポーラ・オルビスホールディング」ならば「ポーラ」という値をとる変数name上書きします。を作ってみましょう。\n\n\n\n\n\n\nRの場合\n\n\n\n\ndf &lt;- df %&gt;%\n    mutate( # 新しい変数を作成\n        name = ifelse(\n            name == \"ポーラ・オルビスホールディング\", \"ポーラ\", name) # 企業名\n        )\n\n\n\n\n\nデータを抽出する filter\nデータを抽出するには，dplyrパッケージのfilter()関数を使います。 filter()関数は，次のような引数を取ります。\n\nfilter(データ, 条件)\n\n先ほど作成したratio2が「高い」企業だけを抽出してみましょう。 filter()関数の中の条件は，==を使って，\"高い\"という文字列と一致するかどうかを確認しています。 ここでは，highlow変数の値が\"高い\"と一致する企業だけを抽出し，df_highという変数に代入しています。\n\n\n\n\n\n\nRの場合\n\n\n\n\ndf_high &lt;- df %&gt;%\n    filter(highlow == \"高い\") # 条件\n\n\n\n\n\n\n\n\n\nMS Excelの場合\n\n\n\nhighlow変数のあるJ列をクリックして枠を移動させ，上の「ホーム」メニューから「並び替えとフィルター」をクリックし，「フィルター」をクリックする。 すると，変数名highlowのヨコに漏斗のようなマークが出るので，それをクリックすると，記録されたデータの種類が出てくるので，「高い」だけにチェックが入った状態にする。\n\n\nExcelのクリック回数が増えてきましたね。\nfilter()関数の中で指定する条件は，\n\n== : 一致する\n!= : 一致しない\n&gt;=や&lt;= : 以上や以下\n&gt;や&lt; : より大きいや小さい\n%in% : いずれかに一致する\n\nなどがあります。またこれらの条件を組み合わせることもできます。 その場合は，以下のように&や|を使います。\n\n& : かつ\n| : または\n\nたとえば，資生堂と花王を抽出したり，売上高当期純利益率が5%以上かつ売上高が1000億円以上の企業を抽出するには， 次のように書きます。\n\n\n\n\n\n\nRの場合\n\n\n\n\ndf_shiseido_kao &lt;- df %&gt;%\n    filter(name %in% c(\"資生堂\", \"花王\")) # 2社だけ抽出\ndf_high2 &lt;- df %&gt;%\n    filter(ratio &gt;= 0.05 & sales &gt;= 1000) # 2条件を同時に満たす\n\n\n\n\n\n変数を選択する select\nデータの中から必要な変数だけを選択するには，dplyrパッケージのselect()関数を使います。 たとえば，先ほど作成したdfから，企業コード，企業名，売上高当期純利益率の3つの変数だけを選択してみましょう。\n\n\n\n\n\n\nRの場合\n\n\n\n\ndf3 &lt;- df %&gt;%\n    select(code, name, ratio) # 3つの変数だけ選択\n\n\n\n\n\n\n\n\n\nMS Excelの場合\n\n\n\nオリジナルのデータをコピーして，下のタブから別のシートを選択し，そこに貼り付ける。\n貼り付けたデータからcodeとnameとratio以外の列を削除する。\n\n\nMS Excelだと，不要なデータを削除するのが怖い作業で，必要になったときにまた元のデータを読み込まないといけないので，面倒ですし，ミスのもとです。\nselect()関数の中で使えるものには，以下のようなものがあります。 とても便利なので，覚えておくとよいでしょう。\n\n- : 除外する (-ratioとかくとratio以外を選択)\n: : 連続する変数を選択 (code:renと書くとcodeからrenまでを選択)\nstarts_with() : ある文字列で始まる変数を選択\nends_with() : ある文字列で終わる変数を選択\n\nたとえば，mutate()で新しい変数を作る場合に，変数名に法則性をつけておけば，starts_with()を使って一気に変数を選択することができます。 たとえば，比率を表す変数はratioで始まるように統一しておく，基準化した変数には_Kを最後に付けておく，などです。\n\n\nデータを並び替える arrange\nデータを並び替えるには，dplyrパッケージのarrange()関数を使います。 たとえば，先ほど作成したdfから，売上高当期純利益率を並び替えてみましょう。\n\n\n\n\n\n\nRの場合\n\n\n\n\ndf %&gt;%\n    select(name, ratio) %&gt;% # 2つの変数だけ選択\n    arrange(ratio) %&gt;%\n    head()\n\n    name       ratio\n1 ポーラ -0.43495809\n2 資生堂 -0.07576384\n3 資生堂 -0.03859062\n4 資生堂 -0.02166802\n5 資生堂 -0.01384122\n6 資生堂 -0.01266169\n\n\n\n\n小さい順に並び替えられました。 大きい順にするには，desc()関数を使います。 ついでにknitrパッケージのkabble()関数で表を見やすく加工してみます。\n\n\n\n\n\n\nRの場合\n\n\n\n\ndf %&gt;%\n    select(name, ratio) %&gt;% # 2つの変数だけ選択\n    arrange(desc(ratio)) %&gt;%\n    head(10) %&gt;% # 先頭の10行\n    knitr::kable(booktabs = TRUE) # 表をきれいに表示\n\n\n\n\nname\nratio\n\n\n\n\nポーラ\n0.1110647\n\n\n花王\n0.1019213\n\n\n花王\n0.0987028\n\n\n花王\n0.0986613\n\n\nユニ・チャーム\n0.0929384\n\n\n花王\n0.0912752\n\n\nポーラ\n0.0895507\n\n\nユニ・チャーム\n0.0891383\n\n\nユニ・チャーム\n0.0890311\n\n\nユニ・チャーム\n0.0869777\n\n\n\n\n\n\n\nこれでどの企業のどの年度の売上高当期純利益率が大きいのかが一目瞭然になりました。\nMS Excelだと，\n\n\n\n\n\n\nMS Excelの場合\n\n\n\n「ホーム」メニューから「並び替えとフィルター」をクリックし，「昇順」をクリックする。\n必要なデータだけ選択してコピペすれば，表が完成します。\n\n\nとなります。 簡単ですが，MS Excelの並び替えは注意が必要で，並び替えた後にデータを追加すると，並び替えが解除されてしまい，元に戻せなくなったり，空列があると並び替えがうまくいかなかったりします。\n\n\n5.3.3 long形式とwide形式\n人間には読みやすいけれどパソコンは読みにくい，というデータの形式があります。 例えば下の表を見てみましょう。\n\n\n\n地点\n6時\n12時\n18時\n\n\n\n\n札幌\n12℃\n15℃\n13℃\n\n\n大阪\n20℃\n24℃\n22℃\n\n\n福岡\n23℃\n25℃\n25℃\n\n\n\nこのような形のデータをワイド形式(wide)といいます。 天気予報で見かけそうなこの表は，人間にとっては分かりやすいですが，実はコンピュータにとっては，分かりにくいものです。 コンピュータが理解しやすいデータとして表すなら，次のような表になります。\n\n\n\n地点\n時間\n気温(℃)\n\n\n\n\n札幌\n6時\n12\n\n\n札幌\n12時\n15\n\n\n札幌\n18時\n13\n\n\n大阪\n6時\n20\n\n\n大阪\n12時\n24\n\n\n大阪\n18時\n22\n\n\n福岡\n6時\n23\n\n\n福岡\n12時\n25\n\n\n福岡\n18時\n25\n\n\n\nこのような形式のデータをロング型(long)といいます。 このロング型のうち，一定のルールに従って作成されたデータを整然データ(tidy data)といい，Rでは，この整然データを扱うことが多いです。\nR神Hadley Wickham氏は，データの型を理解することを，データ分析の第一歩とし，その一貫として整然データという考え方を提唱しています。 整然データとは，次のような原則に従って構築されたデータのことです(Wickham, 2014) 参考https://id.fnshr.info/2017/01/09/tidy-data-intro/。\n\n個々の変数 (variable) が1つの列 (column) をなす。\n個々の観測 (observation) が1つの行 (row) をなす。\n個々の観測の構成単位の類型 (type of observational unit) が1つの表 (table) をなす。\n個々の値 (value) が1つのセル (cell) をなす\n\n上の表は，地点，時間，天気，気温の4つの変数があり1つの列をつくっています(ルール1)。 大阪12時の天気は雨，気温は12℃といったように1つの行が1つの観測を表しています(ルール2)。 このデータには種類の異なる観測はない(ルール3)。 また，各セルには1つの値が入っています(ルール4)。 よって，これが整然データとなります。\n上のロング型の天気データを使って，ロングからワイド，ワイドからロングの操作を学びましょう。\nまずデータを作ります。\n\ndf_weather &lt;- data.frame(\n    place = c(\"札幌\",\"札幌\",\"札幌\",\"大阪\",\"大阪\",\"大阪\",\"福岡\",\"福岡\",\"福岡\"), # 各地を3個ずつ\n    time = rep(c(\"6時\", \"12時\", \"18時\"),3),\n    temp = c(12,15,13,20,24,22,23,25,25)\n)\nprint(df_weather)\n\n  place time temp\n1  札幌  6時   12\n2  札幌 12時   15\n3  札幌 18時   13\n4  大阪  6時   20\n5  大阪 12時   24\n6  大阪 18時   22\n7  福岡  6時   23\n8  福岡 12時   25\n9  福岡 18時   25\n\n\nこれはロング型の整然データとなります。\n\n\nロングからワイド pivot_wider\nRで使うならこのままでよいのですが，あえてこれをワイド型に変えてみましょう。\n教科書で使用されているspread()は「根本的に設計ミスってた」と公式で発表されているので，R神が作ったpivot_wider()を使います。widerという名前の通り，ワイド型に変換する関数です。\npivot_wider()の引数は，names_fromとvalues_fromです。names_fromは，ワイド型に変換するときに，どの変数を列にするかを指定します。values_fromは，ワイド型に変換するときに，どの変数の値を使うかを指定します。\n以下のコードでは，time変数の値を列に，temp変数の値を値にして，df_wideという変数に代入しています。\n\ndf_wide &lt;- df_weather %&gt;%\n    pivot_wider(names_from = time, values_from = temp)\nprint(df_wide)\n\n# A tibble: 3 × 4\n  place `6時` `12時` `18時`\n  &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 札幌     12     15     13\n2 大阪     20     24     22\n3 福岡     23     25     25\n\n\nこれでワイド型に変換できました。\n\n\nワイドからロング pivot_longer\n次に，このワイド型のデータをロング型に変換してみます。 教科書では，tidyrのgather()を使っていますが，これもwider()と同じ問題を持っているので，R神によるpivot_longer()を使います。\npivot_longer()の引数は，colsとnames_toとvalues_toです。\n\ncolsは，ロング型に変換するときに，どの変数を行にするかを指定\nnames_toは，ロング型に変換するときに，どの変数の値を使うかを指定\nvalues_toは，ロング型に変換するときに，どの変数の値を使うかを指定\n\n以下のコードでは，6時，12時，18時の3つの変数を行に，timeという変数の値を列に，tempという変数の値を値にして，df_longという変数に代入しています。\n\ndf_long &lt;- df_wide %&gt;%\n    pivot_longer(\n        cols = c(\"6時\", \"12時\", \"18時\"), # 縦にする変数\n        names_to = \"time\", # 縦にした変数名\n        values_to = \"temp\") # 値\nprint(df_long)\n\n# A tibble: 9 × 3\n  place time   temp\n  &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1 札幌  6時      12\n2 札幌  12時     15\n3 札幌  18時     13\n4 大阪  6時      20\n5 大阪  12時     24\n6 大阪  18時     22\n7 福岡  6時      23\n8 福岡  12時     25\n9 福岡  18時     25\n\n\n元のロング型に戻りました。\n\n\n5.3.4 データの結合\n別々のデータを結合させて使いたいことはよくあります。 例えば，次のようなデータを結合させる場合を考えてみましょう。\n\n表A\n\n\n\nname\nterm\nsale\n\n\n\n\nトヨタ\n2020\n1000\n\n\nトヨタ\n2021\n900\n\n\nトヨタ\n2022\n1400\n\n\nホンダ\n2020\n800\n\n\nホンダ\n2021\n700\n\n\nホンダ\n2022\n900\n\n\n\n\ndf_A &lt;- data.frame(\n    name = c(\"トヨタ\", \"トヨタ\", \"トヨタ\", \"ホンダ\", \"ホンダ\", \"ホンダ\"),\n    term = c(2020, 2021, 2022, 2020, 2021, 2022),\n    sale = c(1000, 900, 1400, 800, 700, 900)\n)\n\n\n\n表B\n\n\n\nname\nterm\nsale\n\n\n\n\n日産\n2020\n400\n\n\n日産\n2021\n500\n\n\n日産\n2022\n900\n\n\nマツダ\n2020\n300\n\n\nマツダ\n2021\n400\n\n\nマツダ\n2022\n200\n\n\n\n\ndf_B &lt;- data.frame(\n    name = c(\"日産\", \"日産\", \"日産\", \"マツダ\", \"マツダ\", \"マツダ\"),\n    term = c(2020, 2021, 2022, 2020, 2021, 2022),\n    sale = c(400, 500, 900, 300, 400, 200)\n)\n\n\n\n表C\n\n\n\nname\nterm\nnetincome\n\n\n\n\nトヨタ\n2020\n100\n\n\nトヨタ\n2021\n90\n\n\nトヨタ\n2022\n150\n\n\nホンダ\n2020\n140\n\n\nホンダ\n2021\n100\n\n\nホンダ\n2022\n90\n\n\nスバル\n2020\n30\n\n\nスバル\n2021\n35\n\n\nスバル\n2022\n50\n\n\n\n\ndf_C &lt;- data.frame(\n    name = c(\"トヨタ\", \"トヨタ\", \"トヨタ\", \"ホンダ\", \"ホンダ\", \"ホンダ\", \"スバル\", \"スバル\", \"スバル\"),\n    term = c(2020, 2021, 2022, 2020, 2021, 2022, 2020, 2021, 2022),\n    netincome = c(100, 90, 150, 140, 100, 90, 30, 35, 50)\n)\n\nこの3つのデータを結合させる場合を考えます。 まず表Aと表Bは同じ変数をもつデータなので，これらを結合させるには，縦につなげる必要があります。 このような結合を縦結合とか連結といいます。 縦結合は，dplyrパッケージのbind_rows()関数を使います。\n\ndf_AB &lt;- bind_rows(df_A, df_B)\nprint(df_AB)\n\n     name term sale\n1  トヨタ 2020 1000\n2  トヨタ 2021  900\n3  トヨタ 2022 1400\n4  ホンダ 2020  800\n5  ホンダ 2021  700\n6  ホンダ 2022  900\n7    日産 2020  400\n8    日産 2021  500\n9    日産 2022  900\n10 マツダ 2020  300\n11 マツダ 2021  400\n12 マツダ 2022  200\n\n\n縦に結合できたので，トヨタ，ホンダ，日産，マツダのデータが入ったデータベースdf_ABができました。\n次に，このdf_ABとdf_Cを結合させます。 df_Cはnetincomeというdf_ABにはない変数があり，異なる変数をもつデータ同士の結合となります。 これらを結合させるには，横につなげる必要があります。 このような結合を結合といいます。\n結合には，\n\n内部結合(inner join)\n外部結合(outer join)\n\nがあり，外部結合には，\n\n完全結合(full join)\n左結合(left join)\n右結合(right join)\n\nがあります。\n内部結合は両方のデータベースに存在する観測値のみを保持するため，多くのデータが欠落することになりますが，外部結合は、少なくとも1つのテーブルに存在する観測値を保持するので，大部分のデータが欠落することにはなりません。\n3つの外部結合の特徴は次の通りです。\n\n完全結合は、xとyのすべての観測値を保持します。\n左結合は、xのすべての観測値を保持します。\n右結合は、yのすべての観測値を保持します。\n\nR神の神書籍R for Data Science (2e)の図がわかりやすいので，ここで紹介します。\n\n\n\n外部結合の例\n\n\n内部結合と3つの外部結合をベン図で表すとこうなります。\n\n\n\n外部結合のベン図\n\n\n最もよく使われる結合は左結合です。 元データに他のデータを結合する場合，元データに含まれるデータのみ保持したい場合が多いので，追加データを調べるときはいつもこれを使います。 左結合はデフォルトの結合であるべきで、他の結合を選択する強い理由がない限り、これを使用します。\nでは，df_ABとdf_Cを左結合してみましょう。 結合する際にキーとなる変数を指定する必要があります。 ここではnameとtermの2つの変数をキーとして指定します。 こうすることで，nameとtermが一致する観測値を結合します。\n\ndf_left &lt;- df_AB %&gt;%\n    left_join(df_C, by = c(\"name\", \"term\"))\nprint(df_left)\n\n     name term sale netincome\n1  トヨタ 2020 1000       100\n2  トヨタ 2021  900        90\n3  トヨタ 2022 1400       150\n4  ホンダ 2020  800       140\n5  ホンダ 2021  700       100\n6  ホンダ 2022  900        90\n7    日産 2020  400        NA\n8    日産 2021  500        NA\n9    日産 2022  900        NA\n10 マツダ 2020  300        NA\n11 マツダ 2021  400        NA\n12 マツダ 2022  200        NA\n\n\ndf_ABにはトヨタ，ホンダ，日産，マツダのデータがありますが，df_Cには日産とマツダのデータがなく，スバルのデータがあります。 そのため左結合すると，日産とマツダのnetincomeにはNAが入り，スバルは欠落します。\ndf_ABとdf_Cを右結合してみましょう。\n\ndf_right &lt;- df_AB %&gt;%\n    right_join(df_C, by = c(\"name\", \"term\"))\nprint(df_right)\n\n    name term sale netincome\n1 トヨタ 2020 1000       100\n2 トヨタ 2021  900        90\n3 トヨタ 2022 1400       150\n4 ホンダ 2020  800       140\n5 ホンダ 2021  700       100\n6 ホンダ 2022  900        90\n7 スバル 2020   NA        30\n8 スバル 2021   NA        35\n9 スバル 2022   NA        50\n\n\ndf_Cには日産とマツダのデータがなく，トヨタとホンダとスバルのデータがあります。 そのため右結合すると日産とマツダのデータが欠落し，df_Cに含まれていたトヨタ，ホンダ，スバルのデータが残ります。 しかしスバルのsaleにはNAが入ります。\n最後に，df_ABとdf_Cを完全結合してみましょう。\n\ndf_full &lt;- df_AB %&gt;%\n    full_join(df_C, by = c(\"name\", \"term\"))\nprint(df_full)\n\n     name term sale netincome\n1  トヨタ 2020 1000       100\n2  トヨタ 2021  900        90\n3  トヨタ 2022 1400       150\n4  ホンダ 2020  800       140\n5  ホンダ 2021  700       100\n6  ホンダ 2022  900        90\n7    日産 2020  400        NA\n8    日産 2021  500        NA\n9    日産 2022  900        NA\n10 マツダ 2020  300        NA\n11 マツダ 2021  400        NA\n12 マツダ 2022  200        NA\n13 スバル 2020   NA        30\n14 スバル 2021   NA        35\n15 スバル 2022   NA        50\n\n\ndf_ABにはトヨタ，ホンダ，日産，マツダのデータがありますが，df_Cにはトヨタ，ホンダ，スバルのデータがあるため， 完全結合したdf_fullにはすべての企業のデータが入ります。 しかし，日産とマツダのnetincomeにはNAが入り，スバルのsaleにもNAが入ります。\nこのように，結合するデータによって，結合したデータに含まれるデータが変わるので，自分が望む結合後のデータの形を考えて，どの結合を使うかを選ぶ必要があります。\nついでに内部結合もやってみましょう。\n\ndf_inner &lt;- df_AB %&gt;%\n    inner_join(df_C, by = c(\"name\", \"term\"))\nprint(df_inner)\n\n    name term sale netincome\n1 トヨタ 2020 1000       100\n2 トヨタ 2021  900        90\n3 トヨタ 2022 1400       150\n4 ホンダ 2020  800       140\n5 ホンダ 2021  700       100\n6 ホンダ 2022  900        90\n\n\n予想どおり，両方のデータに含まれているトヨタとホンダだけが残り，片方のデータにしか含まれていない日産，マツダ，スバルのデータは欠落してしまいました。 このように内部結合は，両方のデータに存在する観測値のみを保持するため，多くのデータが欠落することになり，利用する機会があまりないです。"
  },
  {
    "objectID": "Empoli_Chap05.html#データの保存",
    "href": "Empoli_Chap05.html#データの保存",
    "title": "5  Rによるデータ操作",
    "section": "5.4 データの保存",
    "text": "5.4 データの保存\n前処理が終わったデータは，ファイルとして保存しておくとよいでしょう。 たとえば，df_leftをdf_left.csvというファイル名で保存するには，readrパッケージのwrite_csv()関数を使います。\nwrite_csv()関数の第1引数は保存したいオブジェクト(ここではdf_left)で，あとの主要な引数は，\n\nfile\nna = \"NA\"\nappend = FALSE\n\nとなります。 fileは保存するファイル名を指定します。 naは欠損値をどうするかを指定します。デフォルトではNAとなっています。 appendは，既存のファイルに追記するかどうかを指定します。基本は上書きなので，FALSEにしておきます。\n\nwrite_csv(df_left, file = \"df_left.csv\")\n\nこれで，作業ディレクトリにdf_left.csvが保存されました。 分析を進める際は，このようにして保存したデータを読み込んで使います。"
  },
  {
    "objectID": "Empoli_Chap06.html#変数の種類と記述統計",
    "href": "Empoli_Chap06.html#変数の種類と記述統計",
    "title": "6  記述統計とデータの可視化・視覚化",
    "section": "6.1 変数の種類と記述統計",
    "text": "6.1 変数の種類と記述統計\n数値データには「カテゴリ変数」(category variable)と「量的変数」(quantitative variable)あるいは「連続変数」(continuous variable)があり，それぞれに対して適切なグラフの種類があります。\n\n6.1.1 カテゴリー変数と量的変数\nカテゴリー変数(category variable)とは、観測値が属するカテゴリーを表す変数です。 たとえば、日経産業中分類の「水産」は35、鉱業は37，建設は41ですが、これらの数値の大きさ自体に意味は無く，したがって足したり引いたりすることにも意味はありません。\n量的変数(quantitative variable)とは、観測値が数値で表される変数で，その数値の大きさに意味があります。 たとえば、売上高や株価は金額で表され，その数値に意味があり，他の数値と比較したり，数値を足したり引いたり、さらには平均や分散を計算することに意味があります。\nしたがって、手元にあるデータベースの各変数がカテゴリー変数か量的変数かを把握することは極めて重要です。 Rでは自動で両者を区別したりはしてくれないので、データを読み込んだ後に変数の種類を確認し、自分で指定します。\n\n\n練習用データの読み込み\nここでは、教科書とは違う、企業の財務データを使いながら、データの可視化を学びます。 tidyverseのglimpse()関数を使って，データの詳細を確認します。\n\ndf &lt;- read_csv(\"data/RD_2022.csv\")\nglimpse(df)\n\nRows: 57,823\nColumns: 23\n$ 会社コード                     &lt;chr&gt; \"0000001\", \"0000001\", \"0000001\", \"00000…\n$ 企業名                         &lt;chr&gt; \"極洋\", \"極洋\", \"極洋\", \"極洋\", \"極洋\",…\n$ 決算期                         &lt;chr&gt; \"1999/03\", \"2000/03\", \"2001/03\", \"2002/…\n$ 決算種別                       &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,…\n$ 連結基準                       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ 決算月数                       &lt;dbl&gt; 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,…\n$ 上場コード                     &lt;dbl&gt; 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,…\n$ 日経業種コード                 &lt;dbl&gt; 235341, 235341, 235341, 235341, 235341,…\n$ 現金預金                       &lt;dbl&gt; 6307, 4951, 3818, 4185, 4015, 3456, 277…\n$ 資産合計                       &lt;dbl&gt; 62109, 60885, 60599, 57069, 55373, 5856…\n$ 資本金                         &lt;dbl&gt; 5664, 5664, 5664, 5664, 5664, 5664, 566…\n$ 資本剰余金                     &lt;dbl&gt; NA, NA, NA, NA, 742, 742, 742, 743, 749…\n$ 利益剰余金                     &lt;dbl&gt; 2739, 4238, 4812, 5485, 6254, 6378, 727…\n$ 自己株式                       &lt;dbl&gt; NA, NA, -79, -154, -387, -464, -368, -2…\n$ 売上高                         &lt;dbl&gt; 171944, 171031, 166644, 158006, 162773,…\n$ 経常利益                       &lt;dbl&gt; 1600, 2299, 1947, 2333, 3314, 2895, 335…\n$ 法人税等                       &lt;dbl&gt; 620, 606, 908, 856, 1234, 1302, 1422, 1…\n$ 法人税等調整額                 &lt;dbl&gt; NA, -178, -114, 44, -272, -234, 136, -3…\n$ 親会社株主に帰属する当期純利益 &lt;dbl&gt; -251, 327, 927, 1026, 1122, 1248, 1388,…\n$ 研究開発費IFRS                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ 研究開発費                     &lt;dbl&gt; 210, 201, 190, 179, 197, 212, 201, 193,…\n$ `開発費・試験研究費`           &lt;dbl&gt; 210, 105, 119, 153, 176, 156, 122, 148,…\n$ 現金及び現金同等物の期末残高   &lt;dbl&gt; NA, 4865, 3729, 4097, 3923, 3359, 2725,…\n\n\n23個の変数があり、データの個数は57,823となっています。 第1列に変数名があり，第2列目に変数の型，第3列目以降はデータの内容になります。 第2列目の変数の型として，\n\n&lt;chr&gt; : 文字列\n&lt;dbl&gt; : 数値\n\nの2種類があることが分かります。 以下ではこのデータを使って、データの可視化を学びます。\n\n\n6.1.2 基本的な統計量の確認\n基本関数summary()で記述統計量の確認をします。\n\nsummary(df)\n\n  会社コード           企業名             決算期             決算種別 \n Length:57823       Length:57823       Length:57823       Min.   :10  \n Class :character   Class :character   Class :character   1st Qu.:10  \n Mode  :character   Mode  :character   Mode  :character   Median :10  \n                                                          Mean   :10  \n                                                          3rd Qu.:10  \n                                                          Max.   :10  \n                                                                      \n    連結基準        決算月数       上場コード    日経業種コード  \n Min.   :1.000   Min.   : 1.00   Min.   :11.00   Min.   :101001  \n 1st Qu.:1.000   1st Qu.:12.00   1st Qu.:11.00   1st Qu.:121204  \n Median :1.000   Median :12.00   Median :11.00   Median :241403  \n Mean   :1.062   Mean   :11.98   Mean   :11.46   Mean   :190751  \n 3rd Qu.:1.000   3rd Qu.:12.00   3rd Qu.:12.00   3rd Qu.:257561  \n Max.   :3.000   Max.   :17.00   Max.   :13.00   Max.   :271704  \n                                                                 \n    現金預金           資産合計             資本金          資本剰余金     \n Min.   :       4   Min.   :       70   Min.   :      1   Min.   :-161917  \n 1st Qu.:    2023   1st Qu.:    14062   1st Qu.:   1198   1st Qu.:    965  \n Median :    5370   Median :    39028   Median :   3363   Median :   2995  \n Mean   :   38172   Mean   :   363536   Mean   :  16481   Mean   :  20259  \n 3rd Qu.:   16467   3rd Qu.:   125705   3rd Qu.:  10090   3rd Qu.:   9927  \n Max.   :68502665   Max.   :303846980   Max.   :3500000   Max.   :4503856  \n NA's   :193        NA's   :44          NA's   :198       NA's   :7714     \n   利益剰余金          自己株式            売上高            経常利益      \n Min.   : -972773   Min.   :-3306037   Min.   :       1   Min.   :-869562  \n 1st Qu.:    2250   1st Qu.:   -1368   1st Qu.:   13366   1st Qu.:    425  \n Median :    9163   Median :    -279   Median :   38209   Median :   1626  \n Mean   :   75680   Mean   :   -5144   Mean   :  237440   Mean   :  14070  \n 3rd Qu.:   34436   3rd Qu.:     -39   3rd Qu.:  127091   3rd Qu.:   6126  \n Max.   :26453126   Max.   :      -1   Max.   :31379507   Max.   :5670456  \n NA's   :299        NA's   :10800      NA's   :27         NA's   :21       \n    法人税等       法人税等調整額       親会社株主に帰属する当期純利益\n Min.   : -21709   Min.   :-1139009.0   Min.   :-1708029              \n 1st Qu.:    159   1st Qu.:    -134.5   1st Qu.:     163              \n Median :    586   Median :      -7.0   Median :     823              \n Mean   :   4827   Mean   :    -114.7   Mean   :    7707              \n 3rd Qu.:   2170   3rd Qu.:      91.0   3rd Qu.:    3372              \n Max.   :1190782   Max.   : 1097414.0   Max.   : 4987962              \n NA's   :391       NA's   :3736         NA's   :29                    \n 研究開発費IFRS     研究開発費      開発費・試験研究費\n Min.   :    48   Min.   :      1   Min.   :     1    \n 1st Qu.:  2440   1st Qu.:    131   1st Qu.:   169    \n Median : 24628   Median :    547   Median :   651    \n Mean   : 91248   Mean   :   8441   Mean   :  7528    \n 3rd Qu.:108096   3rd Qu.:   2330   3rd Qu.:  2710    \n Max.   :806905   Max.   :1124262   Max.   :662610    \n NA's   :57583    NA's   :21525     NA's   :38296     \n 現金及び現金同等物の期末残高\n Min.   :    -292            \n 1st Qu.:    1913            \n Median :    5328            \n Mean   :   39185            \n 3rd Qu.:   16954            \n Max.   :68419223            \n NA's   :1591                \n\n\n文字列となっている変数以外の量的変数については、\n\nMin : 最小値\n1st Qu : 第1四分位\nMedian : 中央値\nMean : 平均値\n3rd Qu : 第3四分位\nMax : 最大値\nNA's : 欠損値の数\n\nといった項目が計算されます。 しかし数値データのうち、カテゴリー変数の統計量については，意味をなしません。\n23個の変数の型を確認すると、大部分の財務データは数値&lt;dbl&gt;ですが、\n\n会社コード\n企業名\n決算期\n\nの3つは文字列&lt;chr&gt;となっています。\nまた、数値dblとなっているけれど、実際はカテゴリー変数であるものとして、\n\n決算種別 : 10 = 本決算\n連結基準 : 1 = 日本基準, 2 = 米国基準, 3 = IFRS, 0 = 単独\n上場コード : 11 = 東証1部, 12 = 東証2部, 13 = 東証マザーズ,\n日経業種コード : 後で説明あり\n\nがあります。 文字列以外の量的変数についても記述統計量が計算されていますが，実際はカテゴリー変数である決算種別，連結基準，上場コード，日経業種コードの統計量はもちろん意味をなしていません。 そこでRにカテゴリー変数であることを明示するためにファクター型に変換する必要があります。 データの型をファクター型に変換するための基本関数がfactor()です。 これと，新変数を作成するdplyrパッケージのmutate()関数を使って，カテゴリー変数をファクター型に変換します。\n\ndf &lt;- df %&gt;%\n  mutate(\n    上場コード = factor(\n      上場コード,\n      levels = c(11,12,13),\n      labels = c(\"1部\",\"2部\",\"マザーズ\")),\n    連結基準 = factor(\n      連結基準,\n      levels = c(1,2,3,0),\n      labels = c(\"日本基準\",\"米国基準\",\"IFRS\",\"単独\"))\n      )\n\n上場コードと連結基準の2つのカテゴリー変数がファクター型に変換されたので，再度summary()関数を使って，概要統計量を確認してみましょう。\n\nsummary(df)\n\n  会社コード           企業名             決算期             決算種別 \n Length:57823       Length:57823       Length:57823       Min.   :10  \n Class :character   Class :character   Class :character   1st Qu.:10  \n Mode  :character   Mode  :character   Mode  :character   Median :10  \n                                                          Mean   :10  \n                                                          3rd Qu.:10  \n                                                          Max.   :10  \n                                                                      \n     連結基準        決算月数        上場コード    日経業種コード  \n 日本基準:55727   Min.   : 1.00   1部     :33171   Min.   :101001  \n 米国基準:  581   1st Qu.:12.00   2部     :22529   1st Qu.:121204  \n IFRS    : 1515   Median :12.00   マザーズ: 2123   Median :241403  \n 単独    :    0   Mean   :11.98                    Mean   :190751  \n                  3rd Qu.:12.00                    3rd Qu.:257561  \n                  Max.   :17.00                    Max.   :271704  \n                                                                   \n    現金預金           資産合計             資本金          資本剰余金     \n Min.   :       4   Min.   :       70   Min.   :      1   Min.   :-161917  \n 1st Qu.:    2023   1st Qu.:    14062   1st Qu.:   1198   1st Qu.:    965  \n Median :    5370   Median :    39028   Median :   3363   Median :   2995  \n Mean   :   38172   Mean   :   363536   Mean   :  16481   Mean   :  20259  \n 3rd Qu.:   16467   3rd Qu.:   125705   3rd Qu.:  10090   3rd Qu.:   9927  \n Max.   :68502665   Max.   :303846980   Max.   :3500000   Max.   :4503856  \n NA's   :193        NA's   :44          NA's   :198       NA's   :7714     \n   利益剰余金          自己株式            売上高            経常利益      \n Min.   : -972773   Min.   :-3306037   Min.   :       1   Min.   :-869562  \n 1st Qu.:    2250   1st Qu.:   -1368   1st Qu.:   13366   1st Qu.:    425  \n Median :    9163   Median :    -279   Median :   38209   Median :   1626  \n Mean   :   75680   Mean   :   -5144   Mean   :  237440   Mean   :  14070  \n 3rd Qu.:   34436   3rd Qu.:     -39   3rd Qu.:  127091   3rd Qu.:   6126  \n Max.   :26453126   Max.   :      -1   Max.   :31379507   Max.   :5670456  \n NA's   :299        NA's   :10800      NA's   :27         NA's   :21       \n    法人税等       法人税等調整額       親会社株主に帰属する当期純利益\n Min.   : -21709   Min.   :-1139009.0   Min.   :-1708029              \n 1st Qu.:    159   1st Qu.:    -134.5   1st Qu.:     163              \n Median :    586   Median :      -7.0   Median :     823              \n Mean   :   4827   Mean   :    -114.7   Mean   :    7707              \n 3rd Qu.:   2170   3rd Qu.:      91.0   3rd Qu.:    3372              \n Max.   :1190782   Max.   : 1097414.0   Max.   : 4987962              \n NA's   :391       NA's   :3736         NA's   :29                    \n 研究開発費IFRS     研究開発費      開発費・試験研究費\n Min.   :    48   Min.   :      1   Min.   :     1    \n 1st Qu.:  2440   1st Qu.:    131   1st Qu.:   169    \n Median : 24628   Median :    547   Median :   651    \n Mean   : 91248   Mean   :   8441   Mean   :  7528    \n 3rd Qu.:108096   3rd Qu.:   2330   3rd Qu.:  2710    \n Max.   :806905   Max.   :1124262   Max.   :662610    \n NA's   :57583    NA's   :21525     NA's   :38296     \n 現金及び現金同等物の期末残高\n Min.   :    -292            \n 1st Qu.:    1913            \n Median :    5328            \n Mean   :   39185            \n 3rd Qu.:   16954            \n Max.   :68419223            \n NA's   :1591                \n\n\nすると，先ほどは平均などが出力されていた上場コードと連結基準の2つの変数については，カテゴリーごとの個数が表示されています。 このように，データの型を適切に指定することで，分析結果の出力も適したものに変化することが分かります。\n\n\n6.1.3 カテゴリ変数の内容確認\n次に日経業種コードのカテゴリー変数について見ていきましょう。 日経業種コードは6ケタの数字ですが、最初の1ケタが大分類、次の2ケタ目が中分類、最後の3ケタ目が小分類を表します。 つまりXYYZZZのような構造になっており，Xが大分類，YYが中分類，ZZZが小分類を表します。\n実証会計研究では、産業中分類をよく使うので、ここでは中分類を抽出してみましょう。 手順としては，日経業種コードに対して，substr()関数を使って2〜3ケタ目を抽出し、中分類という変数に格納します。 ついでに，決算期のデータがYYYY/MMという形式になっているので，最初の4桁を抽出して，年度という変数に格納します。\n\ndf &lt;- df %&gt;%\n  mutate(\n    中分類 = substr(日経業種コード, 2, 3), # 中分類コードを抽出\n    年度 = substr(決算期, 1, 4) # 年を抽出\n    )\n\n新しく作成した中分類の内容を確認するためにtable()関数を使います。 カテゴリー変数にtable()関数を用いると，そのカテゴリー変数の内容とカテゴリーに属する個数が表示されます。 以下でも出てきますが，このtable()関数の引数となるベクトル変数は，文字列でも数値でも構いません。\n\ntable(df$中分類)\n\n\n   01    03    05    07    09    11    13    15    17    19    21    23    25 \n 2215   934   432  3915   947   178   459  1066   906  2174  4338  5016    96 \n   27    29    31    33    35    37    41    43    45    52    53    55    57 \n 1651   253  1035  1936   203   131  2715  5926  3501   832  1674   670   640 \n   59    61    63    65    67    69    71 \n  261    96   746   625   285   214 11753 \n\n\nこのように、中分類ごとの企業数が計算されました。 このカテゴリー変数中分類の型をclass()関数で確認します。\n\nclass(df$中分類)\n\n[1] \"character\"\n\n\ncharacter，つまり文字列となっています。 これをファクター型に変えて、カテゴリー変数であることを明示します。 as.factor()関数を使うと文字型をファクター型に変換できますが，産業コードだけだとどの産業なのか分かりづらいままです。 そこで、factor()関数を使って、カテゴリー変数の内容を指定します。\nまずどんな中分類があるのかを確認します。 ある変数にどんなカテゴリーがあるのかを確認するには、unique()関数を使います。\n\nchu_level &lt;- sort(unique(df$中分類))\nchu_level\n\n [1] \"01\" \"03\" \"05\" \"07\" \"09\" \"11\" \"13\" \"15\" \"17\" \"19\" \"21\" \"23\" \"25\" \"27\" \"29\"\n[16] \"31\" \"33\" \"35\" \"37\" \"41\" \"43\" \"45\" \"52\" \"53\" \"55\" \"57\" \"59\" \"61\" \"63\" \"65\"\n[31] \"67\" \"69\" \"71\"\n\n\n中分類コードとして，01から71まで33種類の産業があることが分かりました。 この中分類コードに対応する産業名称を指定するには，factor()関数の引数として，levels =とlabels =を指定します。 以下では，mutate()と組み合わせて，中分類をファクター型に変換します。 最初に産業名称をベクトルとして収納しておきます。\n\nchu_name &lt;- c(\n  \"食品\",\"繊維\",\"パルプ・紙\",\"化学工業\",\"医薬品\",\"石油\",\"ゴム\",\"窯業\",\"鉄鉱業\",\"非金属及び金属製品\",\"機械\",\"電気機器\",\"造船\",\"自動車・自動車部品\",\"その他輸送用機器\",\"精密機器\",\"その他製造業\",\"水産\",\"鉱業\",\"建設\",\"商社\",\"小売業\",\"その他金融業\",\"不動産\",\"鉄道・バス\",\"陸運\",\"海運\",\"空輸\",\"倉庫・運輸関連\",\"通信\",\"電力\",\"ガス\",\"サービス業\")\n\n次に，この産業名を代入したchu_nameに産業コードを対応付けるため，levels =とlabels =を指定します。\n\ndf &lt;- df %&gt;%\n  arrange(中分類) %&gt;%\n  mutate(\n    中分類 = factor(\n      中分類,\n      levels = chu_level, # 中分類コード\n      labels = chu_name # 中分類名称\n      )\n      )\n\nカテゴリー変数がファクター型に変換されたので，再度summary()関数を使って，概要統計量を確認してみましょう。\n\nsummary(df)\n\n  会社コード           企業名             決算期             決算種別 \n Length:57823       Length:57823       Length:57823       Min.   :10  \n Class :character   Class :character   Class :character   1st Qu.:10  \n Mode  :character   Mode  :character   Mode  :character   Median :10  \n                                                          Mean   :10  \n                                                          3rd Qu.:10  \n                                                          Max.   :10  \n                                                                      \n     連結基準        決算月数        上場コード    日経業種コード  \n 日本基準:55727   Min.   : 1.00   1部     :33171   Min.   :101001  \n 米国基準:  581   1st Qu.:12.00   2部     :22529   1st Qu.:121204  \n IFRS    : 1515   Median :12.00   マザーズ: 2123   Median :241403  \n 単独    :    0   Mean   :11.98                    Mean   :190751  \n                  3rd Qu.:12.00                    3rd Qu.:257561  \n                  Max.   :17.00                    Max.   :271704  \n                                                                   \n    現金預金           資産合計             資本金          資本剰余金     \n Min.   :       4   Min.   :       70   Min.   :      1   Min.   :-161917  \n 1st Qu.:    2023   1st Qu.:    14062   1st Qu.:   1198   1st Qu.:    965  \n Median :    5370   Median :    39028   Median :   3363   Median :   2995  \n Mean   :   38172   Mean   :   363536   Mean   :  16481   Mean   :  20259  \n 3rd Qu.:   16467   3rd Qu.:   125705   3rd Qu.:  10090   3rd Qu.:   9927  \n Max.   :68502665   Max.   :303846980   Max.   :3500000   Max.   :4503856  \n NA's   :193        NA's   :44          NA's   :198       NA's   :7714     \n   利益剰余金          自己株式            売上高            経常利益      \n Min.   : -972773   Min.   :-3306037   Min.   :       1   Min.   :-869562  \n 1st Qu.:    2250   1st Qu.:   -1368   1st Qu.:   13366   1st Qu.:    425  \n Median :    9163   Median :    -279   Median :   38209   Median :   1626  \n Mean   :   75680   Mean   :   -5144   Mean   :  237440   Mean   :  14070  \n 3rd Qu.:   34436   3rd Qu.:     -39   3rd Qu.:  127091   3rd Qu.:   6126  \n Max.   :26453126   Max.   :      -1   Max.   :31379507   Max.   :5670456  \n NA's   :299        NA's   :10800      NA's   :27         NA's   :21       \n    法人税等       法人税等調整額       親会社株主に帰属する当期純利益\n Min.   : -21709   Min.   :-1139009.0   Min.   :-1708029              \n 1st Qu.:    159   1st Qu.:    -134.5   1st Qu.:     163              \n Median :    586   Median :      -7.0   Median :     823              \n Mean   :   4827   Mean   :    -114.7   Mean   :    7707              \n 3rd Qu.:   2170   3rd Qu.:      91.0   3rd Qu.:    3372              \n Max.   :1190782   Max.   : 1097414.0   Max.   : 4987962              \n NA's   :391       NA's   :3736         NA's   :29                    \n 研究開発費IFRS     研究開発費      開発費・試験研究費\n Min.   :    48   Min.   :      1   Min.   :     1    \n 1st Qu.:  2440   1st Qu.:    131   1st Qu.:   169    \n Median : 24628   Median :    547   Median :   651    \n Mean   : 91248   Mean   :   8441   Mean   :  7528    \n 3rd Qu.:108096   3rd Qu.:   2330   3rd Qu.:  2710    \n Max.   :806905   Max.   :1124262   Max.   :662610    \n NA's   :57583    NA's   :21525     NA's   :38296     \n 現金及び現金同等物の期末残高        中分類          年度          \n Min.   :    -292             サービス業:11753   Length:57823      \n 1st Qu.:    1913             商社      : 5926   Class :character  \n Median :    5328             電気機器  : 5016   Mode  :character  \n Mean   :   39185             機械      : 4338                     \n 3rd Qu.:   16954             化学工業  : 3915                     \n Max.   :68419223             小売業    : 3501                     \n NA's   :1591                 (Other)   :23374                     \n\n\n変数中分類の結果をみると，産業分類とそこに含まれる個数を表示しています。 これで，数値データとして収録されていたため，意味の無い平均値などを返してしまっていたカテゴリー変数に対して，ファクター型に変換することで，意味のある結果を返すようになりました。\n\n6.1.3.1 記述統計量の計算\n次に，数値データのうち、カテゴリー変数ではないものについて、統計量を計算してみます。 主要な統計量を返す関数には以下のものがあります。\n\nmean() : 算術平均を計算する\nmedian() : 中央値を計算する\nsd() : (不偏)標準偏差を計算する\nvar() : (不偏)分散を計算する\nmin() : 最小値を計算する\nmax() : 最大値を計算する\n\nでは、売上高の平均を計算してみましょう。 データフレームdfの売上高にアクセスするには、df$売上高のように、$を使って変数名を指定します(ここ重要)。 Excelでいうと，dfがシート名，売上高が列名に相当します。\n\nmean(df$売上高)\n\n[1] NA\n\n\nNAが返ってきましたね。 実は、このmean()関数は、引数となるベクトル変数の中に欠損値NAがあると、結果としてNAを返します。 欠損値を意味するNAは，その観測値が存在しないことを表します。 したがって，NAを除外して平均を計算したい場合には、na.rm = TRUEという引数を追加します。\n\nmean(df$売上高, na.rm = TRUE)\n\n[1] 237440.1\n\n\nこれで、売上高の平均が2.3744011^{5}となりました。\n同じように、他の記述統計量を計算する関数でもna.rm = TRUEあるいは略してna.rm = Tを追加することで、欠損値を除外して計算することができます。\n\nmedian(df$売上高, na.rm = T)\n\n[1] 38209\n\nsd(df$売上高, na.rm = T)\n\n[1] 938244.4\n\n\n\n\n\n6.1.4 2つのカテゴリー変数の関係を確かめる\n2つの変数から表を作成する方法について学びます。 典型的な表として，2変数のクロス集計表があります。 例えば，連結基準，つまり企業が採用している会計基準の種類と，上場コード，つまり企業が上場している市場の種類，の2変数について，それぞれのカテゴリーごとの企業数を計算することができます。\n\ntable(df$連結基準, df$上場コード)\n\n          \n             1部   2部 マザーズ\n  日本基準 31290 22432     2005\n  米国基準   580     0        1\n  IFRS      1301    97      117\n  単独         0     0        0\n\n\n圧倒的に，日本基準で上場している企業が多いことがわかります。 2020年度のデータだけを抽出して，同じようにクロス集計表を作成してみましょう。\n\ndf %&gt;%\n  filter(年度 == 2020) %&gt;%\n  with(table(連結基準, 上場コード))\n\n          上場コード\n連結基準  1部  2部 マザーズ\n  日本基準 1474 1177      259\n  米国基準   11    0        0\n  IFRS      194   15       22\n  単独        0    0        0\n\n\n東証1部に上場している企業に注目すると，日本基準採用企業が1474社，米国基準採用企業が11社，IFRS採用企業が194社となっていることがわかりました。\nこのように，table()関数の引数として2つのカテゴリー変数を指定すると，そこからカテゴリー数 \\times カテゴリー数のグループに属する企業数を計算し，表を作成してくれます。 ここではカテゴリー変数連結基準には4つのカテゴリーがあり，カテゴリー変数上場コードには3つのカテゴリーがあるので，4 \\times 3 = 12の表が作成されました。\nここで急に登場したwith()関数ですが，便利なので少し解説しておきます。 with()関数は主として次の2つの引数をとります。\n\nデータ\n式\n\n例えば，先の表を作る場合を考えてみましょう。 普通に書くと\n\ntable(df$連結基準, df$上場コード)\n\nとなり，参照するデータフレームdf$を何度書く必要があり，面倒かつ書き間違えてしまいそうです。 そこでwith()関数を使って上のコードを書き直してみます。\n\nwith(df, table(連結基準, 上場コード))\n\nwith()関数で第1引数にdfを指定すれば，第2引数の式の中でdf$を書く必要がなくなります。したがって，パイプ演算子を使って，\n\ndf %&gt;% with(table(連結基準, 上場コード))\n\nと処理をつなげることができます。 同じ事を何度も書くことを避け，シンプルな表現にしたほうがプログラムの可読性やメンテナンス性が高いため，with()関数は便利です。\n\n\n6.1.5 カテゴリー別に量的変数の値を調べる\n次は，量的変数をカテゴリーごとに分析したいときがあります。 たとえば，産業別や年度別に売上高の平均値を知りたい，ということが何度もあります。 任意のグループごとに処理を繰り返したいときは，dplyrパッケージのgroup_by()関数を使います。 group_by()関数は，第1引数にグループ化したい変数を指定します。\nそしてgroup_by()関数と同時に使うことで，グループごとの統計量を計算するために便利なのがdplyrパッケージのsummarize()関数です。 summarize()関数は，次のような引数をとり，各種統計量を計算してくれます。\n\nmean = : 平均\nmedian = : 中央値\nsd = : 標準偏差\nvar = : 分散\nn() : グループごとの観測値の個数\n\n例えば，上場場所ごとに売上高の平均値を計算するには，次のようにします。\n\ndf %&gt;%\n  group_by(上場コード) %&gt;%\n  summarize(\n    企業数 = n(),\n    平均売上高 = mean(売上高, na.rm = TRUE) # 平均\n    ) %&gt;%\n  ungroup() %&gt;%\n  knitr::kable(booktabs = TRUE)\n\n\n\n\n上場コード\n企業数\n平均売上高\n\n\n\n\n1部\n33171\n393156.220\n\n\n2部\n22529\n29884.533\n\n\nマザーズ\n2123\n5459.012\n\n\n\n\n\n結果を見れば分かるとおり，group_by()で上場場所ごとにグループ化し，summarize()で企業数と平均売上高を計算しているので，上場場所，企業数，平均売上高の3変数が3つの観測値をもつ3 \\times 3の表が作成されています。 group_by()とsummarize()を組み合わせると，結果としてグループ数に応じた統計量を計算した結果となり，元のデータよりも小さなデータフレームとなって返ってきます。\nついでに，産業別の売上高合計，利益平均値，利益中央値，利益の標準偏差を計算してみましょう。\n\ndf %&gt;%\n  group_by(中分類) %&gt;%\n  summarize(\n    企業数 = n(),\n    売上合計 = sum(売上高, na.rm = TRUE), # 合計\n    利益平均値 = mean(親会社株主に帰属する当期純利益, na.rm = TRUE), # 平均\n    利益中央値 = median(親会社株主に帰属する当期純利益, na.rm = TRUE), # 中央値\n    利益標準偏差 = sd(親会社株主に帰属する当期純利益, na.rm = TRUE) # 標準偏差\n    ) %&gt;%\n  arrange(desc(売上合計)) %&gt;%\n  ungroup() %&gt;%\n  knitr::kable(booktabs = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n中分類\n企業数\n売上合計\n利益平均値\n利益中央値\n利益標準偏差\n\n\n\n\n電気機器\n5016\n1941560030\n10167.927\n1084.0\n62674.007\n\n\n商社\n5926\n1909721701\n6754.815\n738.0\n43249.527\n\n\n自動車・自動車部品\n1651\n1688864541\n39250.629\n1851.0\n210604.044\n\n\n小売業\n3501\n793035711\n4590.688\n880.0\n14968.112\n\n\n化学工業\n3915\n736860746\n7564.608\n1445.0\n23530.649\n\n\nサービス業\n11753\n694250494\n2578.502\n361.0\n17729.118\n\n\n通信\n625\n647052927\n67415.843\n3040.0\n284105.640\n\n\n機械\n4338\n616584704\n5310.454\n1007.0\n20211.162\n\n\n建設\n2715\n597371111\n4868.903\n1073.5\n22122.402\n\n\n食品\n2215\n553185961\n8370.878\n1211.0\n32427.752\n\n\n電力\n285\n435223159\n24108.284\n21988.0\n127809.199\n\n\n非金属及び金属製品\n2174\n333425028\n3537.316\n704.0\n15694.021\n\n\n鉄道・バス\n670\n309477897\n16710.421\n3660.0\n61053.123\n\n\n鉄鉱業\n906\n306858163\n8887.185\n903.0\n47067.285\n\n\n石油\n178\n247483911\n14830.657\n1510.5\n81496.356\n\n\n医薬品\n947\n199368660\n20915.376\n4157.0\n48451.048\n\n\nその他製造業\n1936\n189462230\n2630.949\n595.0\n8999.953\n\n\n不動産\n1674\n181588397\n5826.409\n1192.0\n20315.917\n\n\n窯業\n1066\n145506672\n4485.089\n909.5\n13623.277\n\n\nその他金融業\n832\n142861287\n9388.689\n1657.5\n47428.745\n\n\nゴム\n459\n133429682\n12362.357\n1381.0\n43652.986\n\n\n精密機器\n1035\n132220025\n6338.030\n1015.0\n17597.021\n\n\n陸運\n640\n118243116\n4662.080\n1285.5\n9675.867\n\n\n繊維\n934\n115700455\n2405.079\n542.0\n10837.288\n\n\n海運\n261\n104869365\n15152.031\n1012.0\n93497.186\n\n\nパルプ・紙\n432\n100989604\n3345.630\n693.5\n9869.195\n\n\nガス\n214\n89266508\n16210.327\n3620.0\n26366.794\n\n\n空輸\n96\n70396355\n13813.062\n1053.0\n105853.201\n\n\n造船\n96\n50404788\n4001.927\n968.5\n18613.163\n\n\n倉庫・運輸関連\n746\n48088368\n1876.247\n622.0\n3991.522\n\n\n水産\n203\n35003357\n2327.473\n1122.0\n4202.917\n\n\nその他輸送用機器\n253\n27993041\n4227.802\n1102.0\n12600.550\n\n\n鉱業\n131\n26740727\n15827.588\n2096.0\n46860.380\n\n\n\n\n\n次のグラフ作成のためのデータを作成するため，年度別ごとに，ROEの平均値を計算し，その結果をdf_yearという変数に代入します。 ROEは，ある年度の親会社に帰属する当期純利益を期首株主資本で割った値です。 株主資本は，資本金と資本剰余金，利益剰余金，自己株式の合計で計算しますが，欠損値になっている会社もあるので，replace_na()関数を使って欠損値にはゼロを代入します。\n\ndf &lt;- df %&gt;%\n  replace_na(list(資本剰余金 = 0, 利益剰余金 = 0, 自己株式 = 0)) %&gt;%\n  group_by(企業名) %&gt;% # 会社ごとに\n  mutate(\n    株主資本 = 資本金 + 資本剰余金 + 利益剰余金 + 自己株式, # 株主資本を計算\n    ) %&gt;%\n    filter(株主資本 &gt;0 ) %&gt;% # 株主資本がマイナスの企業を除外\n  mutate(\n    ROE = 親会社株主に帰属する当期純利益 / lag(株主資本) # ROEを計算\n    ) %&gt;%\n  ungroup()\n\ndf_year &lt;- df %&gt;%\n  group_by(年度) %&gt;%\n  summarize(\n    平均ROE = mean(ROE, na.rm = TRUE)\n    ) %&gt;%\n  ungroup()\n\nこれで，年度ごと，上場場所ごとに，平均ROEを計算したデータフレームdf_yearができました。\nここで注意しなければならない点として，group_by(企業名)とした上で，lag()関数を使っている点です。 lag()関数は，引数として指定した変数の値の1つ前の値に変換します。 したがって，group_by()を使わないと次のような結果になります。\n\n\n\n\n\n\n\n\n\n\n\n\n企業名\n年度\n親会社株主に帰属する当期純利益\n株主資本\nROE\n\n\n\n\nニップン\n2020\n8941\n129587\n0.0723101\n\n\nニップン\n2021\n8636\n135597\n0.0666425\n\n\nニップン\n2022\n9327\n142166\n0.0687847\n\n\n日清製粉グループ本社\n1999\n7327\n156543\n0.0515383\n\n\n日清製粉グループ本社\n2000\n10822\n175112\n0.0691312\n\n\n日清製粉グループ本社\n2001\n11136\n177671\n0.0635936\n\n\n\n\n\nここで問題になっているのが，日清製粉グループ本社の1999年のROEが計算されている点である。 ROEは分子に親会社株主に帰属する当期純利益，分母に期首株主資本，つまりは前期末の株主資本を使います。 したがって，1999年のROEを計算するためには，1998年の株主資本を使う必要がありますが，データは1999年からしか存在しないので欠損値にならないといけないのに，計算されてしまっています。 つまり，一つ上のニップンの2022年の株主資本のデータを使っているのです。 そこで，group_by()により企業ごとにグループ化して，lag()関数を使って，一つ前の観測値を使うようにし，1999年のROEは欠損値になるようにします。\n\n\n\n\n\n企業名\n年度\n株主資本\nROE\n\n\n\n\nニップン\n2020\n129587\n0.0723101\n\n\nニップン\n2021\n135597\n0.0666425\n\n\nニップン\n2022\n142166\n0.0687847\n\n\n日清製粉グループ本社\n1999\n156543\nNA\n\n\n日清製粉グループ本社\n2000\n175112\n0.0691312\n\n\n日清製粉グループ本社\n2001\n177671\n0.0635936"
  },
  {
    "objectID": "Empoli_Chap06.html#変数の可視化視覚化",
    "href": "Empoli_Chap06.html#変数の可視化視覚化",
    "title": "6  記述統計とデータの可視化・視覚化",
    "section": "6.2 変数の可視化・視覚化",
    "text": "6.2 変数の可視化・視覚化\nカテゴリー変数のファクター化，with()関数とtable()関数を使ったクロス集計表の作成，group_by()関数とsummarize()関数を使ったグループごとの統計量の計算について学んだので，これらの結果を使ってグラフを作ることで，読者に伝わるデータの可視化を行いたいと思います。 キレイなグラフを比較的簡単に作ることができるggplot2パッケージを使います。\n\n6.2.1 ggplot()関数の基本的な使い方と変数の特徴把握\nggplot2パッケージのggplot()関数は，次のような引数をとります。\n\ndata = : データフレーム\nmapping = aes() : グラフの構成要素を指定する関数\ngeom_*** : グラフの種類を指定する関数\n各種オプション\n\n最初の注意点として，ggplot()関数は，第1引数data =でtibbleかdata.frameを指定する必要があります。 データの型に気をつけましょう。\nでは，年度ごとに平均ROEを示した折れ線グラフを作図していきます。 まず土台となるデータフレームを指定します。\n\nggplot(data = df_year)\n\n\n\n\n土台ができましたが，まだ何も表示されていません。 次に，グラフの構成要素を指定するために，mapping = aes()で，軸を指定します。 今回は，横軸に年度，縦軸に平均ROEを指定します。\n\nggplot(data = df_year, mapping = aes(x = 年度, y = 平均ROE))\n\n\n\n\n縦軸と横軸が表示されました。 軸のラベルが文字化けしているので，最初に作成しておいたスタイルmystyleを適用します。\n\nggplot(data = df_year, mapping = aes(x = 年度, y = 平均ROE)) + mystyle\n\n\n\n\n次に，グラフを作成するために，geom_line()関数を使います。 ggplot関数では，次のようなgeom_***()関数を使って，グラフの種類を指定します。\n\ngeom_point() : 散布図\ngeom_line() : 折れ線グラフ\ngeom_bar() : 棒グラフ\ngeom_boxplot() : 箱ひげ図\ngeom_histogram() : ヒストグラム\ngeom_density() : カーネル密度推定図\ngeom_violin() : バイオリンプロット\ngeom_smooth() : 平滑化曲線\n\nここでは横軸が年度という文字列，縦軸が平均ROEという量的変数となるグラフを作るので，geom_bar()を使います。\n\nggplot(data = df_year, mapping = aes(x = 年度, y = 平均ROE)) +\n  geom_bar(stat = \"identity\") + mystyle\n\n\n\n\n横軸が順序に意味のある変数であれば，geom_line()で折れ線グラフを作るほうが良いでしょう。 この場合，年度は文字列ですが，本来は順序に意味のあるカテゴリー変数ですので，factor()関数を使って，ファクター型に変換します。\n\ndf_year &lt;- df_year %&gt;%\n  mutate(年度f = factor(年度,\n  levels = c(1999:2022),\n  ordered = TRUE))\n\n横軸が順序付きのファクターの年度fとなったので，geom_line()を使って折れ線グラフを作成します。 ここで，オプションとして，group = 1を指定して，データ全体が1つのグループであることを明示します。 横軸がファクター型であるときは，group = 1をつける，というおまじないを覚えておきましょう。\n\nggplot(data = df_year, mapping = aes(x = 年度f, y = 平均ROE, group = 1)) +\n  geom_line() + geom_point() + xlab(\"年度\") + ylab(\"平均ROE\") + mystyle\n\n\n\n\n上のコードは，必要な引数を省略せずに書きましたが，省略できるものを省略しつつ， すべての要素を+でつなぐよりも，レイヤーごとに代入していくほうが，コードが読みやすくなります。\n\ng &lt;- ggplot(df_year) + aes(年度f, 平均ROE, group = 1) # 基本要素\ng &lt;- g + geom_line() + geom_point() # 折れ線グラフと散布図\ng &lt;- g + xlab(\"年度\") + ylab(\"平均ROE\") + mystyle # 見た目の調整\nprint(g)\n\n\n\n\n\n\n6.2.2 ヒストグラム\n次に，前年度のROEのヒストグラムを作成してみましょう。\n\ng &lt;- ggplot(df) + aes(ROE) +\n  geom_histogram(fill=\"skyblue\", color = \"black\") +\n  xlim(-1,1) + mystyle\nprint(g)\n\n\n\n\n\n\n6.2.3 箱ひげ図とバイオリンプロット\n次に，上場場所別ROEの分布を箱ひげ図とバイオリンプロットで比較してみましょう。 箱ひげ図は，geom_boxplot()を使います。\n\ng &lt;- ggplot(df) + aes(x = factor(上場コード), y = ROE) + geom_boxplot() + mystyle\nprint(g)\n\n\n\n\nROEのばらつきが大きく，極端にROEが大きかったり小さかったりする異常値のせいで，箱ひげ図がうまく描写されていません。 そこで異常値を除外するため，ROEの範囲を[-0.5,0.5]に限定してみましょう。 先ほど箱ひげ図を作成するために作ったオブジェクトgにylim()を追加して，Y軸の範囲を指定します。\n\ng &lt;- g + ylim(-.5,.5)\nprint(g)\n\n\n\n\n箱ひげ図の箱の下辺は第1四分位(Q1)で，上辺は第3四分位(Q3)です。 真ん中の太い横棒は中央値です。 箱から出ているひげはデータの四分位範囲を超えた値の範囲ですが，黒丸は外れ値を表しています。\n次に，バイオリンプロットを作成します。 バイオリンプロットもほぼ箱ひげ図と同じですが，geom_violin()を使います。\n\ng &lt;- ggplot(df) + aes(x = factor(上場コード), y = ROE)\ng &lt;- g + geom_violin() + ylim(-.5,.5) + mystyle\nprint(g)\n\n\n\n\n箱ひげ図やバイオリンプロットから，東証1部と東証2部の上場企業のROEは中央値に差があるものの，分布の形は似ていますが，マザーズの企業は，ROEの分布が大きく異なることがわかります。\n\n\n6.2.4 図の保存\n最後に，作成した図を保存するには，ggsave()関数を使います。 ggsave()関数は，次のような引数をとります。\n\nfilename = : 保存するファイル名\nplot = : 保存する図\nwidth = : 図の幅\nheight = : 図の高さ\ndpi = : 解像度\n\n日本語を含まないグラフであったり，Windowsならこれでうまくいくのですが，Macで日本語を含むggplotのグラフを保存するには一手間必要です。\n\nMacの場合\nMacの場合，ggsave()関数を使っても，日本語が文字化けしてしまいます。 そこでquartz()関数を用いて，次のようにすれば，日本語を含むグラフを保存することができます。 quartz()は以下の引数を取ります。\n\nfilename = : 保存するファイル名\nwidth = : 図の幅\nheight = : 図の高さ\npointsize = : フォントサイズ\nfamily = : フォントファミリー\ntype = : ファイルタイプ\nantialias = : アンチエイリアス\n\n\nquartz(\"violin_plot.pdf\", width = 10, height = 6, pointsize = 10)\nprint(g)\ndev.off()\n\nこれで作業ディレクトリにviolin_plot.pdfが保存されました。"
  },
  {
    "objectID": "Empoli_Chap07.html#母集団と標本",
    "href": "Empoli_Chap07.html#母集団と標本",
    "title": "7  統計的推定",
    "section": "7.1 母集団と標本",
    "text": "7.1 母集団と標本\n\n母集団(population)とは、研究問題(research question)に基づいて選定された対象全体の集まりを指します。 しかし、その全体を調査・分析することは、時間や費用の制約から現実的ではありません。そのため、母集団から一部を抜き出した標本(sample)を選び、この標本を通じて母集団の特性を推定します。\n\n統計学とは、限られた標本から母集団の特性（母数またはパラメータとも呼ばれます）をどのように探求するかについて研究する学問です。 例えば、作ったお味噌汁全体の味を確かめるには、お味噌汁を全部飲むのではなく、しっかりお味噌汁を鍋の中でかき混ぜてから、スプーン一杯を試飲し、その全体の味を推定する、という作業と同じです。\n標本の特徴を調べることで，観察できない母集団の母数(parameter)を推定することを，統計的推定(statistical estimation)とよびます。 統計的推定には，標本から計算される統計量(statistic)を用います。 母数の推定のために利用される統計量を推定量(estimator)といいます。\n母数は定数ですが，標本が変われば値が変わるので推定量は確率変数です。 1つの標本から計算された1つの標本平均は，たまたま今手元にある標本から計算された1つの平均値にすぎず，別の標本を集めて再度標本平均を計算すれば，異なる値になることが予想されます。\nまた母数を推定するために用いられる統計量と一般的な数式記号は以下の通りです。\n\n\n\n母数\n記号\n統計量\n記号\n\n\n\n\n母平均\n\\mu\n標本平均\n\\bar x\n\n\n母比率\n\\pi\n標本比率\np\n\n\n母分散\n\\sigma^2\n標本分散\ns^2\n\n\n母標準偏差\n\\sigma\n標本標準偏差\ns\n\n\n\n標本から母数を推定するためには，適切な方法で標本を集めなければなりません。 1限の講義に出席している学生にアンケートをとっても，学生全体の推定には適切とはいえない標本があつまるでしょう。\n母集団から標本を選ぶ標本抽出方法として代表的なものが，単純無作為抽出(simple randome sampling)です。 単純無作為抽出で選ばれた標本は、母集団の偏りのない標本といえます。 たとえば，平均10，標準偏差1の正規分布からランダムに100個のデータを抽出して標本を作り，その平均値を計算してみます。\n\nn = 100 # 標本サイズ\nx &lt;- rnorm(n, 10, 1) # 標本抽出\nmean(x) # 標本平均\n\n[1] 10.04175\n\n\n平均値は10.0417459となり，母平均10とほぼ同じ値になりましたが、ぴったり10ではありませんよね。 この母平均10と標本平均10.0417459の差を誤差といい、母集団と標本のズレを意味します。\n平均10，標準偏差1の正規分布からランダムに100個のデータを抽出して標本を作り，その平均値を計算する，という試行(trial)を10000回繰り返して，10000個の標本から10000個の標本平均を計算して、標本平均のヒストグラムで表示してみます。\n\nn = 100 # 標本サイズ\ntrial = 10000 # 標本数\nresult &lt;- numeric(trial) # 結果を入れる空の変数\nfor (i in 1:trial) { # 以下の処理をtrial回繰り返す\n  x &lt;- rnorm(n, 10, 1) # 標本抽出\n  result[i] &lt;- mean(x) # 標本平均\n}\nhist(result) # 基本関数histでヒストグラム作成\n\n\n\n\nこの図をみると、キレイな左右対称の釣り鐘型の分布になっていることが分かります。 この10000個の平均値の平均は，\n\nmean(result)\n\n[1] 9.999426\n\n\nとほぼ10と等しくなります。 このように，標本数を増やしていくと，標本平均の平均値は母平均に近づく，という法則を大数の法則(law of large numbers)といいます。 統計学における極めて重要な概念です。"
  },
  {
    "objectID": "Empoli_Chap07.html#標本分布",
    "href": "Empoli_Chap07.html#標本分布",
    "title": "7  統計的推定",
    "section": "7.2 標本分布",
    "text": "7.2 標本分布\n関心の対象となる母集団から同じサイズの標本を取り出すにしても，その組み合わせは1つではありません。\nたとえば，プレゼミのメンバー25名から5名の標本を選ぶなら，その組み合わせは，\n\n{}_{25} \\mathrm{C}_5 = \\binom{25}{5} = \\frac{25!}{5!(25-5)!} = 53130\n\nたったこの人数でもこれだけの組み合わせがあるので，すべての株式会社から標本を選ぶ組み合わせは無数になります。 したがって，その標本から計算した統計量は標本ごとに異なる値となります。このような統計量の分布を標本分布(sampling distribution)といいます。\n\n不偏推定量\n「偏りのない」(unbiased)標本をたくさん集めることができれば，標本分布は母集団の分布に近づきます。 この多くの標本から計算される統計量の平均が母数に一致する性質を不偏性(unbiasedness)といい，普遍性をもつ推定量を不偏推定量(unbiased estimator)といいます。\nたとえば，5個のデータ(2,4,6,7,9)について考えてみましょう。 ここから3つのデータを取り出して標本を作ります。 その組み合わせは，\n\n{}_{5} \\mathrm{C}_3 = \\binom{5}{3} = \\frac{5!}{3!(5-3)!} = 10\n\nとなります。 この10個の標本から計算される標本分散と標本平均を計算してみます。 それぞれの定義は次のとおりです。\n\n\\begin{aligned}\n\\text{標本平均} &= \\frac 1n \\sum_{i=1}^n x_i \\\\\n\\text{標本分散} &= \\frac 1n \\sum_{i=1}^n \\left (x_i - \\bar{x} \\right )^2\n\\end{aligned}\n 標本平均と標本分散を計算する関数を作ります。 関数の作り方については，また後で勉強する予定ですので，ここでは関数の使い方だけを覚えておいてください。\n\nmeanp &lt;- function(x){\n  sum(x) / length(x) # 合計をデータの個数で割る\n}\nvarp &lt;- function(x){\n  sum((x - meanp(x))^2) / length(x) # 分散の計算式\n}\n\nこれで平均と分散を計算する関数ができました。 これを使って，標本平均と標本分散を計算してみましょう。 まず5のサイズをもつ母集団から標本サイズ3の標本を10通り作成します。\n\nx &lt;- c(2,4,6,7,9)\nmeanp(x) # 母平均 5.6\n\n[1] 5.6\n\nres &lt;- combn(x,3) # 3つのデータを取り出す組み合わせ\nprint(res)\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n[1,]    2    2    2    2    2    2    4    4    4     6\n[2,]    4    4    4    6    6    7    6    6    7     7\n[3,]    6    7    9    7    9    9    7    9    9     9\n\n\nこれですべての組み合わせを作り出せましたので，それぞれの標本から標本平均と標本分散を計算します。 各列に，先ほど作ったmeanp()関数をapply関数で適用し，10の標本平均を作り，sample_meanという変数に代入し，その平均を計算します。\n\nsample_mean &lt;- apply(res, 2, meanp)\nmeanp(sample_mean) # 標本平均の平均は5.6\n\n[1] 5.6\n\n\n標本平均の平均5.6が母平均5.6に一致したので，標本平均は不偏推定量であることが分かります。\n次に分散を計算してみましょう。\n\nvarp(x) # 母分散 5.84\n\n[1] 5.84\n\nsample_var &lt;- apply(res, 2, varp)\nmeanp(sample_var) #\n\n[1] 4.866667\n\n\n標本分散の平均4.8666667は母分散5.84より小さな値になりました。つまり標本分散は不偏推定量ではありません。またこの結果は自明のことです(後述します)。 これには自由度という概念が関係しています。 自由度とは，標本から計算される統計量の値を決めるのに使える情報の数のことですが，ここではスルーして，標本分散ではなく標本不偏分散を計算します。 違いは，分母がnではなくn-1になっていることです。 \n\\text{標本不偏分散} = \\frac{1}{n-1} \\sum_{i=1}^n \\left (x_i - \\bar{x} \\right )^2\n\nRの基本関数であるvar()は標本分散ではなく標本不偏分散を計算するので，これを使って先ほどの計算を再現してみましょう。\n\nvar(x) # 母分散 5.84\n\n[1] 7.3\n\nres &lt;- combn(x,3) # 3つのデータを取り出す組み合わせ\nsample_var &lt;- apply(res, 2, var)\nmeanp(sample_var) # 標本平均の平均は5.6\n\n[1] 7.3\n\n\n母分散と標本不偏分散の平均は一致しました。 つまり母数である母分散を推定するためには，標本不偏分散を使う必要があるということです。\nとはいえ，違いはnで割るか，n-1で割るか，という点だけなので，標本サイズnが大きければ，標本分散と標本不偏分散の違いは無視できるので，経営学の研究ではそこまで気にしなくてもよいでしょう。\n\n\n一致推定量\n標本数が増えると，標本分布は母集団の分布に近づく，という特徴をもつ推定量を一致推定量(consistent estimator)といいます。 これが最も重要な特徴です。\n例えば，関心のある母集団が\n\n母平均\\mu = 62\n母分散\\sigma^2 = 25\n\nという母数をもつ正規分布に従っている，としましょう。 グラフにする前に，必要なパッケージの読み出しと，グラフのスタイルを設定します。\n\nlibrary(tidyverse)\nlibrary(ggthemes)\nmystyle &lt;- list (#  ggplotのテーマ\n  theme_few(), # ggthemesパッケージ\n  theme(\n    text = element_text(\n      size=16,  #  フォントサイズ\n      family = \"HiraKakuProN-W3\" # ヒラギノフォント\n    )\n  )\n)\n\nグラフにすると次のようになります。\n\np &lt;- ggplot(data = data.frame(X = c(47,77)))\np &lt;- p +aes(x = X)\np &lt;- p + stat_function(\n  fun = dnorm,\n  args = list(mean = 62, sd = 5)\n  ) + mystyle\nprint(p)\n\n\n\n\nここから，標本サイズ10の標本を取り出し，標本平均を計算する，という試行を1000回繰り返し，1000個の標本平均を作りましょう。\n\nn = 10 # 標本サイズ\ntrial = 1000 # 試行回数\nresult &lt;- numeric(trial) # 結果を入れる空の箱\nfor (i in 1:trial) { # 以下をtrial回繰り返す\n  x &lt;- rnorm(n, 62, 5) # 標本を生成\n  result[i] &lt;- mean(x) # 標本平均を計算\n}\nmean(result) # 標本平均の平均\n\n[1] 62.00974\n\n\nヒストグラムの中心が母平均の62に近づいていることが分かります。 標本平均の平均は62.0097367となりますが，これは母平均62に近い値になっています。\nグラフで確認すると，\n\nresult &lt;- as.tibble(result)\ng &lt;- ggplot(result) + aes(value) # 軸の設定\ng &lt;- g + geom_histogram( # ヒストグラム\n  aes(y = ..density..), bins = 60, # y軸を密度に\n  fill = \"white\", color = \"black\") # ヒストグラムの色\ng &lt;- g + stat_function(fun=dnorm, args=list(mean = 62, sd = 5))　# 母集団の分布\ng &lt;- g + geom_vline(xintercept = 62, color = \"red\") # 母平均の縦線\ng &lt;- g + xlim(47,77) + mystyle # x軸の範囲を指定\nprint(g)\n\n\n\n\nと母平均と標本平均のヒストグラムの中心が一致していることが分かります。 ただ，母分散と比べて標本分散が非常に小さいことが一目瞭然です。\n標本サイズを先ほどの100倍の1000として，同じ試行を1000回繰り返してみましょう。\n\n\n\n\n\nどんどん標本サイズを増やして，100000として，同じ試行を1000回繰り返してみましょう。\n\n\n\n\n\nこのように，標本平均の分散は，標本サイズが大きくなるにつれて，どんどん小さくなっていくことが分かります。 たとえば30から150の間の値をとり，母平均62，母分散25の正規分布にしたがう母集団から標本を採ったとしましょう。 母集団が30から150の値をとるのに対して，標本サイズが大きいとき，標本平均が30とか150の値をとることはあり得ません。\n標本平均の標準偏差SD(\\bar x)は，\n\nSD(\\bar x) = \\frac{\\sigma}{\\sqrt{n}}\n\nこのように，標本サイズを大きくすると，標本平均が母平均の近くの値をとる確率が大きくなる，という性質を一致性(consistency)と呼び，一致性をもつ推定量を一致推定量(consistent estimator)といいます。"
  },
  {
    "objectID": "Empoli_Chap07.html#母平均の推定と信頼区間",
    "href": "Empoli_Chap07.html#母平均の推定と信頼区間",
    "title": "7  統計的推定",
    "section": "7.3 母平均の推定と信頼区間 ",
    "text": "7.3 母平均の推定と信頼区間 \n標本から得た統計量をつかって母数である母平均を予想したいとき，手元にある1つの標本から計算した標本平均は，どの程度の精度をもつでしょうか？\n\n7.3.1 母平均の信頼区間 \n信頼区間(confidence interval)は，非常に難解な概念です。 まず確認として，母数である母平均は観察できない数値ですが，確率変数ではなく定数です。 この母平均が計算した信頼区間に含まれるか，含まれないか，のどちらかしかありません。 信頼区間の正しい解釈は，母集団から標本を取ってきて、その標本平均から95%信頼区間を求める、という作業を100回やったときに、95回はその区間の中に母平均が含まれる，というものです。 この信頼区間の計算をしてみます。\n\n標本平均の標準偏差を推定する– 標準誤差\n標本の統計量は確率変数なので，統計量は分布します。 標本平均の標準偏差は，\n\nSD(\\bar x) = \\frac{\\sigma }{\\sqrt{n}}\n\nと定義されます。 ここでnは標本サイズなのですぐ分かりますが，$は母標準偏差なので未知です。 そこでまず$の推定のために，不偏標準偏差\n\nu = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n \\left (x_i - \\bar{x} \\right )^2}\n\nを計算します。 先ほど定義したSD(\\bar x)の分子\\sigmaの代わりに推定量uを使ったものを標準誤差(standard error: SE)と呼びます。 \nSE = \\frac{u}{\\sqrt{n}}\n\nこの標準誤差を標本平均の標準誤差の代わりに使います。\n\n\nt分布\nさて，とうとう統計学の真骨頂であるt分布の登場です。 t分布(t-distribution)は，母集団が正規分布にしたがうとき，標本平均の分布が従う確率分布です。 絵で描くとこんな感じです。\n\nx &lt;- seq(-4, 4, length.out = 100)\n\ndf1 &lt;- dt(x, df = 1)\ndf5 &lt;- dt(x, df = 5)\ndf100 &lt;- dt(x, df = 100)\n\n# データフレームに変換\ndf &lt;- data.frame(x = rep(x, 3),\n                 y = c(df1, df5, df100),\n                 freedom = factor(rep(c(\"df = 1\", \"df = 5\", \"df = 100\"), each = length(x)), ordered = TRUE)\n                 )\n# プロット\nggplot(df, aes(x = x, y = y, color = freedom)) +\n  geom_line() +\n  scale_color_manual(values = c(\"red\", \"blue\", \"green\")) +\n  labs(title = \"自由度が異なるt分布のプロット\") + xlab(\"t値\") + ylab(\"確率密度\") + mystyle\n\n\n\n\n標本平均\\bar xから母平均を引いて，それを標準誤差SEで割った値をt値(t-value)といい，このt値はt分布にしたがうことが知られていますが，ここでは詳細に触れません。\n自由度99のt分布の場合，95%の確率でt値は-1.98から1.98の間に入ります。\n\n# 自由度を設定\ndf &lt;- 99\n\n# データを生成\ndata &lt;- data.frame(x = seq(-5, 5, by = 0.01))\ndata$y &lt;- dt(data$x, df)\n\n# 90%の領域の上限と下限をqt()で計算\nql &lt;- qt(0.025, df)\nqu &lt;- qt(0.975, df)\n\n# t分布を書く\ng &lt;- ggplot(data) + aes(x=x, y=y) + geom_line()\ng &lt;- g + geom_area(data = data %&gt;% filter(x &gt; ql & x &lt; qu), fill = \"blue\", alpha = 0.3)\ng &lt;- g + xlab(\"t値\") + ylab(\"確率密度\") + labs(title = \"90%の確率で起こるt値の範囲\") + xlim(-3,3)\ng &lt;- g + annotate(geom = \"text\", x = qu, y = 0.12,\n  label = \"1.98\", size = 6) +\n  annotate(# 始点や終点などを指定して矢印を追加\n  geom = \"segment\", x = qu, xend = qu,\n  y = 0.1, yend = 0.07, color = \"black\", size = 0.3,\n  arrow = arrow(length = unit(0.3, \"cm\"))\n  )\ng &lt;- g + annotate(geom = \"text\", x = 0, y = 0.15,\n  label = \"95%\", size = 8)\ng &lt;- g + annotate(geom = \"text\", x = ql, y = 0.12,\n  label = \"-1.98\", size = 6) +\n  annotate(# 始点や終点などを指定して矢印を追加\n  geom = \"segment\", x = ql, xend = ql,\n  y = 0.1, yend = 0.07, color = \"black\", size = 0.3,\n  arrow = arrow(length = unit(0.3, \"cm\"))\n  ) + mystyle\nprint(g)\n\n\n\n\nt分布は確率分布ですので，面積は1となります。 青い領域が95％の確率でt値が入る範囲です。 ということは両側の白い領域は，片方が2.5％と面積となっています。 これを次のように書きます。\n\n[ -t _{100-1, 0.025}, \\ t_{100-1, 0.025}]\n\nt分布表を使って，自由度99のときのt値を調べると，t_{100-1, 0.025} = 1.98となります。 Rだとqt()関数を使って計算できます。\n\nround(qt(0.025, df = 99),digits =2)\n\n[1] -1.98\n\nround(qt(0.975, df = 99),digits =2)\n\n[1] 1.98\n\n\n\n\n信頼区間を求める\n標本サイズnの標本から計算される標本平均\\bar xから計算される次のt値 \nt = \\frac{\\bar x - \\mu}{SE}\n が自由度n-1のt分布にしたがうことが知られています。\nつまり，標本の95％のt値は，t_{n-1, 0.025}からt_{n-1, 0.975}の間に入ります。 よって，\n\n-t _{n-1, 0.025} \\leq \\frac{\\bar x - \\mu}{SE} \\leq  t_{n-1, 0.025}\n 両辺にSEをかけると， \n-t _{n-1, 0.025} \\times SE \\leq \\bar{x} - \\mu \\leq  t_{n-1, 0.025}\\times SE\n\nこの区間を95％信頼区間といいます。\n\n\n\n7.3.2 信頼区間の解釈\n信頼区間とは、観察できない真の値である母数が存在し、その母集団から標本を抽出し、標本平均を計算するということを繰り返したときに、95%の標本平均の信頼区間の中に真の値である母平均が入っている、ということです。\n先の例を使って、信頼区間を表現してみます。 いま、母集団が平均62，標準偏差5の正規分布にしたがうとします。 この母集団から標本サイズ50の標本を100個抽出して，標本平均と標本標準偏差を計算します。\n\ntrial &lt;- 100 # 標本数\nn &lt;- 50 # 標本サイズ\nmu &lt;- 62 # 母平均\nsigma &lt;- 5 # 母標準偏差\n\nset.seed(1234) # 乱数を準備\n\n# 標本ごとの統計量を収納する空のベクトルを作成\nsample_mean &lt;- numeric(trial) # 標本平均の入れ物\nsample_sd   &lt;- numeric(trial) # 標本標準偏差の入れ物\nuplimit     &lt;- numeric(trial) # 信頼区間の上限の入れ物\nlowlimit    &lt;- numeric(trial) # 信頼区間の下限の入れ物\n\n# 標本の数だけ，以下の計算を繰り返す\nfor (i in 1:trial) {\n  temp_sample    &lt;- rnorm(n, mu, sigma) # 標本を抽出\n  sample_mean[i] &lt;- mean(temp_sample) # 標本平均を計算\n  sample_sd[i]   &lt;- sd(temp_sample) # 標本標準偏差を計算\n}\n\n# 信頼区間の計算\np &lt;- .95 # 信頼水準の設定 (95%信頼区間)\nalpha &lt;- qt( (1 - p) / 2, df = n - 1, lower.tail=FALSE) # 限界値の計算\n\n# 信頼区間の上限と下限の計算\nuplimit  &lt;- sample_mean + alpha * sample_sd/sqrt(n) # 信頼区間上限\nlowlimit &lt;- sample_mean - alpha * sample_sd/sqrt(n) # 信頼区間下限\n\n# 信頼区間の計算結果をデータフレームにまとめる\nconfidence_interval &lt;- data.frame(\n  標本平均 = sample_mean,\n  上限 = uplimit,\n  下限 = lowlimit,\n  標本番号 = 1:trial\n)\n\n# Plot using ggplot2\ng_ci &lt;- ggplot(confidence_interval) +\n  aes(x = 標本番号, y = 標本平均)\n  # aes(x = reorder(標本番号, 標本平均), y = 標本平均)\ng_ci &lt;- g_ci + geom_errorbar( # 信頼区間を表す線を描く\n  aes(ymin = 下限, ymax = 上限,\n      color = (下限 &lt;= 62 & 上限 &gt;= 62)\n      ), width = 0.2)\ng_ci &lt;- g_ci + scale_color_manual( # 色の設定\n  values = c(\"magenta\", \"black\"),\n  guide = FALSE)\ng_ci &lt;- g_ci + geom_point(aes(y = 標本平均)) # 標本平均を点で表す\ng_ci &lt;- g_ci + geom_hline(yintercept = 62, color = \"red\") # 母平均を赤い線で表す\ng_ci &lt;- g_ci + xlab(\"標本ID\") + ylab(\"95%信頼区間\") # 軸ラベルの設定\ng_ci &lt;- g_ci + ylim(47,77) + coord_flip() + mystyle # 軸の範囲と向きの設定\n\np &lt;- ggplot(data.frame(X = c(47,77))) + aes(x = X) # 母集団を描く範囲\np &lt;- p + stat_function(fun = dnorm, args = list(mean = 62, sd = 5)) # 正規分布を描く\np &lt;- p + geom_vline(xintercept = 62, color=\"red\") + mystyle　# 母平均を赤い線で表す\n\nlibrary(patchwork) # グラフを並べるためのパッケージ\np / g_ci # グラフを縦に並べる\n\n\n\n\n本当は未知である母平均62，母標準偏差5の母集団から標本を100個取り出し，100個の標本平均と95%信頼区間を計算し，グラフにしています。 この100個の標本から計算した95％信頼区間に母平均62が含まれているかどうかを確認すると，7つの95％信頼区間に母平均が含まれていないことが分かります。7/100の割合で信頼区間に母平均が含まれていないので，信頼水準は1-7/100=0.93となります。\n信頼区間を50%にするとどうなるでしょうか？ こうなります。\n\n\n\n\n\n信頼区間が短くなり，母平均を含まない50%信頼区間が増えました。\n標本サイズを大きくすればどうでしょうか。 先ほどまでは標本サイズ50の標本でしたが、標本サイズを500にして、95%信頼区間を計算してみます。\n\n\n\n\n\n標本サイズnが大きくなると、信頼区間の上限と下限を計算するさいの\\sqrt{n}が大きくなるため、信頼区間が短くなっていることがわかります。"
  },
  {
    "objectID": "Empoli_Chap08.html#統計的仮説検定の基礎",
    "href": "Empoli_Chap08.html#統計的仮説検定の基礎",
    "title": "8  統計的仮説検定",
    "section": "8.1 統計的仮説検定の基礎",
    "text": "8.1 統計的仮説検定の基礎\n母集団の母数(パラメータ)を知りたいけれど観察できないので、母集団から標本(sample)を抽出して、標本の特徴をつかって母集団の母数を予想しようとすることを、統計的推定(statistical estimation)といいます。\nこの章では、母数に対して立てた仮説が妥当かどうかを検証する方法を学びます。\n\n仮説をたてる\n有意水準を設定する\n検定統計量を計算する\n検定統計量の確率分布を求めて有意水準で棄却域を決める\n検定統計量が棄却域に入るかどうかを確認する\n\n\n8.1.1 仮説の立て方：帰無仮説と対立仮説\n仮説の立て方は、帰無仮説(null hypothesis)と対立仮説(alternative hypothesis)の2つに分けられます。 (頻度主義)統計学では、本当に示したい仮説(対立仮説)ではなく、その排反事象である帰無仮説を立てて、帰無仮説が棄却されることで、対立仮説が採択されるという考え方をとります。 排反事象(incompatible events)とは、同時に起こりえない事象のことです。\n例えば、\n\n帰無仮説H_0 : 利益反応係数ERCはゼロである。　ERC =0\n対立仮説H_A : 利益反応係数$ERCはゼロではない。 ERC \\not = 0\n\nというように、帰無仮説は対立仮説と背反となるように立てます。 また、帰無仮説は母数に対して等号で成立する仮説となります。 なぜこんなことをするのかというと、母数がある特定の値をとる、という帰無仮説を否定するためには、その値以外の取りうることを示せばよいだけですが、もし対立仮説がERC=0であったなら、これを示すためには、ERC \\not = 0を示す必要があります。 これは不可能です。\n\n\n8.1.2 有意水準の設定\n次に、どんなときに帰無仮説を棄却するのかを決めます。 帰無仮説として仮定した母数の値から標本から計算した値が大きく異なる場合には、帰無仮説を棄却する、とします。 このとき、どのくらい帰無仮説として仮定した母数の値から離れたら帰無仮説を棄却するのかを決めるのが有意水準(significance level)です。優位水準と書かないように気をつけましょう。\n有意水準は、\\alphaで表され、会計研究では0.01、0.05、0.10が使われることが多いです。 標本サイズが大きい場合だと、0.001とか0.005とかも使われます。\n例えば、母集団の平均\\muが0である、という帰無仮説を考えます。このとき対立仮説は母集団の平均\\muは0ではない、というものです。 標本サイズ100の標本から抽出した標本平均の分布から計算したt値が自由度100-1のt分布にしたがうとき、\n\nt = \\frac{\\bar{x} - \\mu}{s/\\sqrt{n}}\n となり，今\\bar{x} = \\muという帰無仮説を仮定しているので、t = 0となります。\n\n# 自由度を設定\nn = 100\ndf &lt;- n-1\n\n# データを生成\ndata &lt;- data.frame(x = seq(-5, 5, by = 0.01))\ndata$y &lt;- dt(data$x, df) # 変数yを作成\n\n\n# 90%の領域の上限と下限をqt()で計算\nql &lt;- qt(0.025, df)\nqu &lt;- qt(0.975, df)\n\n# t分布を書く\ng &lt;- ggplot(data) + aes(x = x, y = y) + geom_line()\ng &lt;- g + geom_area(data = data %&gt;% filter(x &lt;= ql), fill = \"blue\", alpha = 0.3) + geom_area(data = data %&gt;% filter(x &gt;= qu), fill = \"blue\", alpha = 0.3)\ng &lt;- g + geom_vline(xintercept = 0, color = \"red\")\ng &lt;- g + xlab(\"t値\") + ylab(\"確率密度\") + labs(title = \"90%の確率で起こるt値の範囲\")\ng &lt;- g + geom_hline(yintercept = 0)\ng &lt;- g + annotate(geom = \"text\", x = 2.4, y = 0.08, label = \"α/2\", size = 10)\ng &lt;- g + annotate(# 始点や終点などを指定して矢印を追加\n  geom = \"segment\", x = 2.4, xend = 2.2,\n  y = 0.07, yend = 0.04, color = \"black\", size = 0.5,\n  arrow = arrow(length = unit(0.3, \"cm\"))\n  )\ng &lt;- g + annotate(geom = \"text\", x = -2.4, y = 0.08, label = \"α/2\", size = 10) +\n  annotate(# 始点や終点などを指定して矢印を追加\n  geom = \"segment\", x = -2.4, xend = -2.2,\n  y = 0.07, yend = 0.04, color = \"black\", size = 0.5,\n  arrow = arrow(length = unit(0.3, \"cm\"))\n  ) + mystyle\nprint(g)\n\n\n\n\n\n\n8.1.3 検定統計量の計算 \n標本から平均などの統計量を計算し，その統計量は確率変数なので分布をもち，その分布 \n\\begin{align*}\nt = \\frac{\\bar{x} - \\mu}{SE} = \\displaystyle \\frac{\\bar{x} - \\mu}{\\frac{u}{\\sqrt{n}}}\n\\end{align*}\n を検定統計量\n\n\nRでやってみる\n母平均62、母標準偏差5の正規分布にしたがう変数Xを考えます。 母集団のサイズは10000とします。 この母集団の分布は次のようになっています。\n\nN &lt;- 10000\nX &lt;- rnorm(N, 62, 5) # 母集団\nggplot(data.frame(X)) + aes(X) + geom_histogram() + ggtitle(\"母集団\") + geom_vline(xintercept = 62, color = \"red\") + mystyle\n\n\n\n\nこの母集団から標本サイズ100の標本を100個とりだし、平均を100個計算します。\n\nn &lt;- 100\nsample_mean &lt;- numeric(n) # 空の箱を用意\nfor(i in 1:100){\n  x_sample &lt;- sample(X, n) # 標本を抽出\n  sample_mean[i] &lt;- mean(x_sample) # 標本平均を計算\n}\ndf_mean &lt;- data.frame(sample_mean)\n\nたとえば、ある標本の平均値は62.75はこうなります。\nこの平均値がどのように分布しているのかを調べるために、ヒストグラムを作成してみます。\n\ng_mean &lt;- ggplot(df_mean) + aes(x=sample_mean) +\n  geom_histogram() + xlab(\"標本平均\") + ylab(\"度数\") +\n  geom_vline(xintercept = mean(sample_mean), color = \"blue\") +\n  geom_vline(xintercept = 62, color=\"red\") + mystyle\nprint(g_mean)\n\n\n\n\n\ng_m &lt;- ggplot(df_mean) +\n    aes(x = reorder(seq_along(sample_mean), sample_mean), y = sample_mean) +\n    geom_bar(stat=\"identity\") + geom_hline(yintercept = 62, color = \"red\") +\n   coord_cartesian(ylim = c(60, 64)) +\n    ylab(\"標本平均\") + xlab(\"標本ID\") + ggtitle(\"標本平均の分布\") + mystyle\nprint(g_m)\n\n\n\n\nおおよそ母平均\\mu = 62の周りに分布していることがわかりますが，かなり離れた標本平均をもつ標本もあるようです。 たとえば，100個の標本で最小の標本平均となった標本の平均は60.59です。 このように母平均62，母標準偏差5の母集団から抽出した1つの標本サイズ100の標本平均が，60.59という値になる確率はどのくらいでしょうか。 標本平均からt値を計算し，そのt値が自由度99のt分布にしたがう確率を求めることで，この確率を求めることができます。\n\nt &lt;- (min(df_mean$sample_mean) - 62) / (5 / sqrt(n))\nprint(t)\n\n[1] -2.81836\n\n\n自由度99のt分布の下で，となる確率は求めると，\n\npt(t, df = n-1)\n\n[1] 0.00291464\n\n\nとなり，この確率は非常に小さい値となります。 つまり100個の標本をとってくると，いくつかの標本から計算された標本平均は，母平均62からかなり離れた値となることがわかります。 それぞれの標本平均から計算されたt値の分布を調べると，次のようになります。\n\ndf_mean &lt;- df_mean %&gt;%\n  mutate(\n    t_value = (sample_mean - 62) / (5 / sqrt(n)),\n    p_value = pt(t_value, df = n-1)\n  )\n\nggplot(df_mean) +\n    aes(x = reorder(seq_along(p_value), p_value), y = p_value) + # グラフの設定\n    geom_bar(stat=\"identity\", fill = ifelse(df_mean$p_value &lt; 0.05, \"red\", \"black\")) + #\n    geom_hline(yintercept = 0.05, color = \"red\") + # 有意水準0.05\n    ylab(\"p値\") + xlab(\"標本ID\") + ggtitle(\"p値の分布\") + mystyle # 軸の設定\n\n\n\n\nとなり，t値が生じる確率が5%未満となる標本がいくつかあることがわかった。 自分が集めた標本の1つから計算した標本平均、そしてt値が、帰無仮説が正しいと仮定した場合に、その標本平均がどのくらいの確率で生じるかを調べ、それが5%未満や1%未満であったならば、帰無仮説が正しいと考えるよりも、帰無仮説とは異なる母平均をもつ母集団から標本を集めたから、そのような標本平均が生じたと考えるほうがもっともらしいと考えることができます。 これが統計的仮説検定の考え方です。"
  },
  {
    "objectID": "Empoli_Chap09.html#カテゴリー変数の関連",
    "href": "Empoli_Chap09.html#カテゴリー変数の関連",
    "title": "9  変数間の関連性",
    "section": "9.1 カテゴリー変数の関連",
    "text": "9.1 カテゴリー変数の関連\n\n9.1.1 クロス集計表\nカテゴリー変数は、その値がどのカテゴリーに属するかということを表す変数です。 2つのカテゴリー変数の関連性を調べるためにはクロス集計表を作ることが有益です。 例えば、40名のクラスに、男が25名、女が15名います。 また、クラスの中で、メガネをかけている男が4名、メガネを掛けている女が8名いました。 このクロス集計表は次のようなものになります。\n\n\n\n\nメガネをかけている\nメガネをかけていない\n合計\n\n\n\n\n男\n41\n204\n245\n\n\n女\n81\n74\n155\n\n\n合計\n122\n278\n400\n\n\n\nこの表から、メガネをかけている人の割合は、男性の中で0.2009804、女性の中で0.52であることから、女子学生の方がメガネをかける傾向にあることが分かりました。\n\n\n9.1.2 カイ二乗検定\nこのクロス集計表から読み取れる関係が、統計的に意味があるのかどうかを調べるためには、\\chi ^2(カイ二乗)検定を行います。 \\chi^2検定は次のステップで実行します。\n\n帰無仮説として、カテゴリー変数間に関連性はないと仮定\nその仮定のもとで、観測されたクロス集計表の度数が、理論的に予測される度数と大きく異なるかどうかを検定\n予測される度数と観測された度数の差が大きいほど、帰無仮説が棄却される\n\n\\chi^2検定で用いられる統計量は、\\chi^2統計量と呼ばれ、次の式で計算されます。\n\n\\chi^2 = \\sum_{i=1}^n \\sum_{j=1}^m \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\n ここで、O_{ij}は観測された度数(観測度数)、E_{ij}は理論的に予測される度数(期待度数)です。nとmはカテゴリー変数のカテゴリー数です。 つまり、2つのカテゴリー変数の関連性を調べる場合、\\chi^2統計量は次のように計算されます。\n\n\\begin{aligned}\n\\chi^2 &= \\frac{(O_{11} - E_{11})^2}{E_{11}} + \\frac{(O_{12} - E_{12})^2}{E_{12}} \\\\\n&+ \\frac{(O_{21} - E_{21})^2}{E_{21}} + \\frac{(O_{22} - E_{22})^2}{E_{22}}\n\\end{aligned}\n\nここで、期待度数Eをどうやって求めるのか、が問題となります。 期待度数の「期待」の意味は、帰無仮説のもとで期待される度数です。\n\nE_{ij} = \\frac{O_{i\\cdot} \\times O_{\\cdot j}}{O_{\\cdot \\cdot}}\n ここで、O_{i\\cdot}はi行目の合計(横の合計)、O_{\\cdot j}はj列目の合計(縦の合計)、O_{\\cdot \\cdot}は全体の合計です。\n先のメガネの例で計算してみます。 観察度数Oは次のようになります。\n\n\n\n\nメガネをかけている\nメガネをかけていない\n合計\n\n\n\n\n男\n41\n204\n245\n\n\n女\n81\n74\n155\n\n\n合計\n122\n278\n400\n\n\n\n男の行合計O_{男\\cdot}は245、女の行合計O_{女\\cdot}は155、メガネ有りの列合計O_{\\cdot メガネ有}は122、メガネなしの列合計O_{\\cdot メガネ無}は278、全体の合計O_{\\cdot \\cdot}は400となります。 ここから、期待度数は次のように計算されます。\n\n\\begin{aligned}\nE_{男, メガネ} &= \\frac{245 \\times 122}{400} = 74.725 \\\\\nE_{男, メガネ無} &= \\frac{245 \\times 278}{400} = 170.275 \\\\\nE_{女, メガネ} &= \\frac{155 \\times 122}{400} = 47.275 \\\\\nE_{女, メガネ無} &= \\frac{155 \\times 278}{400} = 107.725\n\\end{aligned}\n\nよって期待度数Eは次のようになります。\n\n\n\n\nメガネをかけている\nメガネをかけていない\n合計\n\n\n\n\n男\n74.725\n170.275\n245\n\n\n女\n47.275\n107.725\n155\n\n\n合計\n122\n278\n400\n\n\n\nここから、定義通りに、\\chi^2統計量を計算します。\n\n\\begin{aligned}\n\\chi^2 = \\frac{(41 - 74.725)^2}{74.725} + \\frac{(204 - 170.275)^2}{170.275} + \\frac{(81 - 47.275)^2}{47.275} + \\frac{(74 - 107.725)^2}{107.725} = 7.2\n\\end{aligned}\n\nここで計算した\\chi^2統計量は、自由度1の\\chi^2分布に従うということが知られています。この自由度は、カテゴリー変数のカテゴリー数から1を引いたものです。 ここでは、2カテゴリー同士のクロス集計表なので、自由度は(2-1) \\times (2-1) = 1となります。\n自由度1のカイ二乗分布の確率密度関数は次のようになります。\n\nx = c(1:2500) / 250\ny1 = dchisq(x,1)\n\ndf &lt;- data.frame(x,y1)\np &lt;- ggplot(df) + aes(x = x,y = y1)\np &lt;- p + geom_line(size = 1)\np &lt;- p + ylim(c(0,1)) + ylab(\"密度\") + xlab(\"カイ二乗値\") +\n  scale_y_continuous(expand = c(0,0), limits = c(0,1)) +\n  scale_x_continuous(expand = c(0,0), limits = c(-0.1,10))\np &lt;- p + ggtitle(\"自由度1のχ2分布の確率密度\") +  mystyle\nprint(p)\n\n\n\n\n参考までに、自由度が変わると\\chi^2分布の形状は次のようなものになります。\n\nx = c(1:2500) / 250\ny1 = dchisq(x,1)\ny3 = dchisq(x,3)\ny5 = dchisq(x,5)\n\ndf &lt;- data.frame(x,y1,y3,y5)\ndf &lt;- df %&gt;% pivot_longer(names_to = \"y\",values_to = \"value\",cols = -x)\np &lt;- ggplot(df) + aes(x = x,y = value, group = y, color = y)\np &lt;- p + geom_line(size = 1)\np &lt;- p + ylim(c(0,1)) + ylab(\"密度\") + xlab(\"カイ二乗値\") +\n  scale_y_continuous(expand = c(0,0), limits = c(0,1)) +\n  scale_x_continuous(expand = c(0,0), limits = c(-0.1,10))\np &lt;- p + ggtitle(\"自由度1,3,5のχ2分布の確率密度\") +  mystyle\nprint(p)\n\n\n\n\n自由度1の\\chi^2分布における有意水準5%の値を調べるにはqchisq()関数を使います。引数は、pに確率、dfに自由度を指定します。\n\nalpha &lt;- 0.05  # 有意水準（ここでは5%）\ndf &lt;- 1        # 自由度\nqchisq(1 - alpha, df)\n\n[1] 3.841459\n\n\n自由度1のカイ二乗分布における有意水準5%の値は3.84であることが分かりました。 この値を超えると、有意水準5%で帰無仮説を棄却することになります。\nでは先程計算した\\chi^2統計量は、有意水準5%で帰無仮説を棄却するかどうかを調べてみましょう。\n\nchi2 &lt;- 7.2\nqchisq(1 - alpha, df) &lt; chi2\n\n[1] TRUE\n\n\nより、\\chi^2統計量は有意水準5%で帰無仮説を棄却することが分かりました。 ちなみに、自由度1のカイ二乗分布の確率密度関数と\\chi^2統計量の位置を重ねてみると次のようになります。\n\ndf &lt;- data.frame(x,y1)\np &lt;- ggplot(df) + aes(x = x,y = y1)\np &lt;- p + geom_line(size = 1)\np &lt;- p + ylim(c(0,1)) + ylab(\"密度\") + xlab(\"カイ二乗値\") +\n  scale_y_continuous(expand = c(0,0), limits = c(0,1)) +\n  scale_x_continuous(expand = c(0,0), limits = c(-0.1,10))\np &lt;- p + ggtitle(\"自由度1のχ2分布の確率密度\") +  mystyle\np &lt;- p + geom_vline(xintercept = chi2, linetype = \"dashed\", color = \"red\")\np &lt;- p + annotate(\"text\", x = chi2, y = 0.1, label = \"χ2 statistics\", color = \"red\")\nprint(p)\n\n\n\n\nこのように、\\chi^2統計量は、自由度1のカイ二乗分布のもとで生じる確率は、\n\n1 - pchisq(chi2, df = 1)\n\n[1] 0.007290358\n\n\nとなり、非常に小さな値であることが分かりました。 つまり、2つのカテゴリー変数の間に関係がない、という帰無仮説の下で、観測された度数が発生することはほぼありえない、ということが言えるので、帰無仮説は棄却され、2つのカテゴリー変数には関係があると結論付けられます。\n\n\n9.1.3 Rでχ2検定\nRではchisq.test()関数を使ってχ2検定を行うことができます。 引数は、xに度数表、correctに補正を行うかどうか、pに期待度数を指定します。\n先ほどの男女とメガネの例をここでも使ってみます。 まずmatrix()関数を使ってクロス集計表を行列として作成します。\n\nO &lt;- matrix(c(41, 81, 204, 74), nrow = 2, ncol = 2)\nrow.names(O) &lt;- c(\"男性\", \"女性\")\ncolnames(O) &lt;- c(\"メガネ\", \"メガネなし\")\n\nE &lt;- matrix(c(\n  sum(O[,1])*sum(O[1,])/sum(O), #男眼鏡\n  sum(O[,1])*sum(O[2,])/sum(O), #男眼鏡無\n  sum(O[,2])*sum(O[1,])/sum(O), #女眼鏡\n  sum(O[,2])*sum(O[2,])/sum(O)  #女眼鏡無\n), nrow = 2, ncol = 2)\n\nprint(O)\n\n     メガネ メガネなし\n男性     41        204\n女性     81         74\n\nprint(E)\n\n       [,1]    [,2]\n[1,] 74.725 170.275\n[2,] 47.275 107.725\n\n\nこの観察度数と期待度数から、定義通りに\\chi^2統計量を計算してみます。\n\nchi &lt;-  (O[1,1] - E[1,1])^2 / E[1,1] + #男眼鏡\n        (O[1,2] - E[1,2])^2 / E[1,2] + #男眼鏡無\n        (O[2,1] - E[2,1])^2 / E[2,1] + #女眼鏡\n        (O[2,2] - E[2,2])^2 / E[2,2]   #女眼鏡無\nprint(chi)\n\n[1] 56.51731\n\n\n\\chi^2統計量がとなりました。 この\\chi^2統計量が自由度1の\\chi^2分布にしたがう場合，この統計量が得られる確率は次のようになります。\n\nprop &lt;- 1 - pchisq(chi, df = 1)\nprint(prop)\n\n[1] 5.57332e-14\n\n\nこの確率は0.0000000000000055733となり，ほぼゼロであることが分かりました。 よって、2つのカテゴリー変数は無関係である，という帰無仮説は棄却され、2つのカテゴリー変数には関係があると結論付けられます。\nちなみに，上記のようなめんどくさい処理をしなくても，Rにはchisq.test()という関数が用意されています。 chisq.test()は引数として、xに度数表、correctに補正を行うかどうか、pに期待度数を指定します。 補正は行わないので，correctはFALSEとします。 pはデフォルトで等確率となっているので，今回は省略します。\n\nchisq.test(O, correct = FALSE)\n\n\n    Pearson's Chi-squared test\n\ndata:  O\nX-squared = 56.517, df = 1, p-value = 5.571e-14\n\n\nとなり，先ほどの結果と一致しました。\n各マスに入る度数が少ない場合には、フィッシャーの直接確率検定を使います。\n\nfisher.test(O)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  O\np-value = 1.204e-13\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.1127341 0.2982245\nsample estimates:\nodds ratio \n 0.1845096"
  },
  {
    "objectID": "Empoli_Chap09.html#量的変数間の関係",
    "href": "Empoli_Chap09.html#量的変数間の関係",
    "title": "9  変数間の関連性",
    "section": "9.2 量的変数間の関係",
    "text": "9.2 量的変数間の関係\nここでは、2つ以上の量的変数間の関係を調べる方法について学びます。 具体的には、相関係数と散布図について学習します。\n\n9.2.1 相関関係の種類・散布図・相関係数\n2つの量的変数(連続変数)が同時に変化する関係を相関関係(correlation)といいます。 相関関係には、\n\n正の相関(positive correlation)\n負の相関(negative correlation)\n無相関(no correlation)\n\nの3種類があります。\nまずは，2つの量的変数を使って散布図(scatter diagram)を描いて，目で見て相関関係があるかどうかを判断します。 そして，相関係数(correlation coefficient)を計算して，数値的に相関関係があるかどうかを判断します。 相関係数は次のように計算されます。\n\nr = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^n (x_i - \\bar{x})^2}\\sqrt{\\sum_{i=1}^n (y_i - \\bar{y})^2}}\n\n分子は、xとyの共分散(covariance)で、分母はxの標準偏差とyの標準偏差の積です。 相関係数rは-1から1の値をとります。 rが1に近いほど正の相関が強く、-1に近いほど負の相関が強く、0に近いほど無相関になります。\n相関係数が-1から1の値をとることを証明することは簡単なのですが，それを書くには余白が足りないので，ここには示しません。 コーシー・シュワルツの不等式を使うか，xとyの偏差のベクトルの角度が\\cosであることを示すか，のどちらかで証明できます。\n\n\n9.2.2 相関係数を使った統計的仮説検定\n相関係数が同じでも統計的に有意になるか否かは、標本サイズで決まるということを教科書で理解しておきましょう。\n\n\nRでやってみる\n母平均0、母標準偏差1の正規分布にしたがう変数XとYを考えます。 母集団のサイズは10000とします。\n\nN &lt;- 10000\nX &lt;- rnorm(N, 0, 1)\nY &lt;- rnorm(N, 0, 1)\nP &lt;- data.frame(X,Y)\nggplot(P) + aes(X,Y) + geom_point() + ggtitle(\"母集団\") + mystyle\n\n\n\n\nこの母集団から標本サイズ100の標本を100個とりだし、相関係数を100個計算します。\n\nn &lt;- 100\nsig &lt;- numeric(n)\ncor &lt;- numeric(n)\nfor(i in 1:100){\n  x_sample &lt;- sample(X, n)\n  y_sample &lt;- sample(Y, n)\n  res &lt;- cor.test(x_sample, y_sample)\n  sig[i] &lt;- res$p.value\n  cor[i] &lt;- cor(x_sample, y_sample)\n}\ndf_cor &lt;- data.frame(cor,sig)\ndf_cor %&gt;% arrange(sig) %&gt;% head()\n\n         cor         sig\n1  0.3032027 0.002166295\n2 -0.2678916 0.007045710\n3 -0.2637771 0.008007666\n4 -0.2509923 0.011774694\n5  0.2344974 0.018857503\n6 -0.2343658 0.018926257\n\n\nたとえば、ある標本の散布図はこうなります。\n\nx_sample &lt;- sample(X, n)\ny_sample &lt;- sample(Y, n)\ndata.frame(x_sample, y_sample) %&gt;%\n    ggplot() + aes(x_sample, y_sample) + geom_point() + geom_smooth(method = \"lm\", se = FALSE) +\n    ggtitle(\"標本\") + mystyle\n\n\n\n\n微妙に右肩上がりの関係がありそうですが、ほぼ無相関といえるでしょう。\nでは、100個の標本から計算した100個の相関係数の大きさを並べてみましょう。 無相関となる母集団からの標本を100個とっているので、標本の相関係数も0に近い値となることが予想されますが、いくつかの標本では-0.3や0.2といった相関があるという結果が得られています。\n\nggplot(data.frame(df_cor)) +\n    aes(x = reorder(seq_along(cor), cor), y=cor) +\n    geom_bar(stat=\"identity\", fill = ifelse(sig &lt; 0.05, \"red\", \"black\")) +\n    ylab(\"相関係数\") + xlab(\"標本ID\") + ggtitle(\"相関係数の分布\") + mystyle\n\n\n\n\nでは、それらの値が、母集団では相関係数が0であるという帰無仮説が正しいとした場合に、どのくらいの確率で得られるのかを調べてみましょう。\n\nggplot(data.frame(df_cor)) +\n    aes(x = reorder(seq_along(sig), sig), y=sig) +\n    geom_bar(stat=\"identity\", fill = ifelse(sig &lt; 0.05, \"red\", \"black\")) +\n    ylab(\"p値\") + xlab(\"標本ID\") + ggtitle(\"相関係数のp値の分布\") + mystyle\n\n\n\n\n相関係数が0である母集団から標本を抜き出して、その標本相関係数の値が0.3となる確率p値は0.002となりました。 もし自分がもっている広告費と売上高のデータから相関係数を計算し、その値が0.3であったなら、母集団では相関係数が0であるという帰無仮説の下では、ほとんど起こりえないことが起こったということになります。 この場合、帰無仮説が間違っていて、対立仮説である広告費と売上高には関係があるという仮説のほうがもっともらしい、ということになります。 逆に、帰無仮説を棄却できなかった場合、広告費と売上高の間に関係は無いと主張することはできません。 帰無仮説が棄却できなかった場合は、関係があるかどうかはわからないということになります。\n\n\n9.2.3 相関関係と因果関係\n\n\n\n\n\n\nImportant\n\n\n\n相関関係があるからといって、必ずしも因果関係があるとは限らない。\n\n\n広告費と売上高の関係について考えてみましょう。\n\n因果関係\n可能性1：広告費が売上高に影響を与えている、という関係を想定しています。\n\n\n\n\ngraph LR\n    A[広告費] --&gt; B[売上高]\n\n\n\n\n\n\n\n因果関係\n可能性2：売上高が広告費に影響を与えている、という関係を想定しています。\n\n\n\n\ngraph RL\n    B[売上高] --&gt; A[広告費]\n\n\n\n\n\n\n\n互恵関係\n可能性3 : 可能性1と可能性2が同時に起こっている、という関係を想定しています。\n\n\n\n\ngraph LR\n    A[広告費] --&gt; B[売上高]\n    B[売上高] --&gt; A[広告費]\n\n\n\n\n\n\n\n見せかけの相関\n広告費と売上高の両方に影響を与える第3の要因が存在する場合、広告費と売上高の間に相関関係があるように見える、という想定です。 ここでは、広告費と売上高の両方に影響を与える第3の要因として、内部資金を想定しています。内部資金が潤沢な会社は、広告宣伝費も増加させることができるし、売上高も増加させることができる、という想定です。\n\n\n\n\ngraph TB\n    A[内部資金] --&gt; B[広告費]\n    A[内部資金] --&gt; C[売上高]\n\n\n\n\n\n\n\n\n\ngraph TB\n    A[内部資金] --&gt; B[広告費]\n    A --&gt; C[売上高]\n    B -.-&gt; C"
  },
  {
    "objectID": "Empoli_Chap10.html#線形回帰-散布図への直線の当てはめ",
    "href": "Empoli_Chap10.html#線形回帰-散布図への直線の当てはめ",
    "title": "10  回帰分析の基礎",
    "section": "10.1 線形回帰 – 散布図への直線の当てはめ",
    "text": "10.1 線形回帰 – 散布図への直線の当てはめ\n前章では2変数の関係を表すために散布図を作り，相関係数を求めましたが，この章では，背後にモデルとして原因と結果の関係をもつと仮定し，そのモデルを表すために直線を当てはめる回帰分析について学びます．\n分析に使うデータとして，2006年から2022年の東京証券取引所のプライム市場に上場している会社の決算データを使います。 売上高と広告宣伝費や研究開発費の関係を分析するために，研究開発費が1億円以上，広告宣伝費が1000万円以上の会社に限定し，決算月数が12ヶ月の会社を対象にします。\n\ndf &lt;- read_csv(\"data/adv_2023.csv\")\ndf &lt;- df %&gt;%\n  filter(決算月数 == 12 & 研究開発費 &gt;= 100 & 広告宣伝費 &gt; 10)\nglimpse(df)\n\nRows: 4,442\nColumns: 14\n$ 日経会社コード &lt;chr&gt; \"0000001\", \"0000001\", \"0000003\", \"0000003\", \"0000003\", …\n$ 企業名称       &lt;chr&gt; \"極洋\", \"極洋\", \"日本水産\", \"日本水産\", \"日本水産\", \"日…\n$ 決算期         &lt;chr&gt; \"2006/03\", \"2007/03\", \"2006/03\", \"2007/03\", \"2008/03\", …\n$ 決算種別       &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,…\n$ 連結基準       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ 決算月数       &lt;dbl&gt; 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,…\n$ 業種           &lt;dbl&gt; 235341, 235341, 235341, 235341, 235341, 235341, 235341,…\n$ 資産合計       &lt;dbl&gt; 65049, 66459, 384819, 404173, 396739, 385462, 383924, 4…\n$ 売上高         &lt;dbl&gt; 152899, 157088, 539653, 552871, 533970, 505250, 481574,…\n$ 販管費         &lt;dbl&gt; 13702, 14455, 95566, 98200, 100394, 98413, 99938, 10490…\n$ 広告宣伝費     &lt;dbl&gt; 304, 279, 2699, 2569, 2953, 2568, 2636, 3160, 3009, 288…\n$ 拡販費         &lt;dbl&gt; 111, 158, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ 研究開発費     &lt;dbl&gt; 193, 188, 3083, 3377, 3718, 3803, 3994, 4499, 4809, 361…\n$ 設備投資額     &lt;dbl&gt; 897, 1841, 17186, 16031, 19105, 28872, 21121, 18633, 16…\n\n\nでは売上高と広告宣伝費の散布図を書いてみます。\n\ng &lt;- ggplot(df) + aes(x = 広告宣伝費, y = 売上高) + geom_point() + mystyle\nprint(g)\n\n\n\n\n散布図を見ると，売上高も広告宣伝費もばらつきが大きいので，とりあえず対数変換してみます。\n\ndf &lt;- df %&gt;%\n  mutate(\n    log_広告宣伝費 = log(広告宣伝費),\n    log_売上高 = log(売上高),\n    log_研究開発費 = log(研究開発費)\n  )\nglimpse(df)\n\nRows: 4,442\nColumns: 17\n$ 日経会社コード &lt;chr&gt; \"0000001\", \"0000001\", \"0000003\", \"0000003\", \"0000003\", …\n$ 企業名称       &lt;chr&gt; \"極洋\", \"極洋\", \"日本水産\", \"日本水産\", \"日本水産\", \"日…\n$ 決算期         &lt;chr&gt; \"2006/03\", \"2007/03\", \"2006/03\", \"2007/03\", \"2008/03\", …\n$ 決算種別       &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,…\n$ 連結基準       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ 決算月数       &lt;dbl&gt; 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,…\n$ 業種           &lt;dbl&gt; 235341, 235341, 235341, 235341, 235341, 235341, 235341,…\n$ 資産合計       &lt;dbl&gt; 65049, 66459, 384819, 404173, 396739, 385462, 383924, 4…\n$ 売上高         &lt;dbl&gt; 152899, 157088, 539653, 552871, 533970, 505250, 481574,…\n$ 販管費         &lt;dbl&gt; 13702, 14455, 95566, 98200, 100394, 98413, 99938, 10490…\n$ 広告宣伝費     &lt;dbl&gt; 304, 279, 2699, 2569, 2953, 2568, 2636, 3160, 3009, 288…\n$ 拡販費         &lt;dbl&gt; 111, 158, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ 研究開発費     &lt;dbl&gt; 193, 188, 3083, 3377, 3718, 3803, 3994, 4499, 4809, 361…\n$ 設備投資額     &lt;dbl&gt; 897, 1841, 17186, 16031, 19105, 28872, 21121, 18633, 16…\n$ log_広告宣伝費 &lt;dbl&gt; 5.717028, 5.631212, 7.900637, 7.851272, 7.990577, 7.850…\n$ log_売上高     &lt;dbl&gt; 11.93753, 11.96456, 13.19868, 13.22288, 13.18809, 13.13…\n$ log_研究開発費 &lt;dbl&gt; 5.262690, 5.236442, 8.033658, 8.124743, 8.220941, 8.243…\n\n\n対数変換した売上高と広告宣伝費の関係を示す、散布図を作成します。\n\ng &lt;- ggplot(df) + aes(x = log_広告宣伝費, y = log_売上高) + geom_point() + mystyle\nprint(g)\n\n\n\n\nキレイに正の相関があるようにみえる散布図ができあがりました。 相関係数を計算してみると，\n\ncor(df$log_広告宣伝費, df$log_売上高)\n\n[1] 0.7530297\n\n\nとなり，非常に高い正の相関があることが分かりました。\nこの散布図に回帰直線を追加するには，geom_smoothを使います。\n\ng &lt;- g + geom_smooth(method = \"lm\", se = FALSE, color = \"red\") + xlab(\"広告宣伝費の対数\") + ylab(\"売上高の対数\") + mystyle\nprint(g)\n\n\n\n\nこの赤い直線を回帰直線(regression line)といい，原因となる変数y(ここでは広告宣伝費)と結果となる変数x(ここでは売上高)の線形関係を表す次のようなモデルとなります。\n\ny = a + bx\n\n先の広告宣伝費と売上高の散布図に引いた直線だと，\n\nres01 &lt;- lm(log_売上高 ~ log_広告宣伝費, data = df)\nsummary(res01)\n\n\n\\text{売上高の対数} = 7.770869 + 0.550978 \\times 広告宣伝費の対数"
  },
  {
    "objectID": "Empoli_Chap10.html#最小二乗法",
    "href": "Empoli_Chap10.html#最小二乗法",
    "title": "10  回帰分析の基礎",
    "section": "10.2 最小二乗法",
    "text": "10.2 最小二乗法\n先ほどの求めた回帰直線の切片や傾きの値を求める方法の1つに最小二乗法(least squares method)があります。\n最小二乗法は、観測値y_iとモデル上の予測値\\hat{y}_iの差を残差(residual)と定義し、この残差の二乗の和を最小にするような回帰直線を求める方法です。\nサイズNの標本(y_i, x_i)_{i \\in N}をデータとして持っているとしましょう。 ここでは、広告宣伝費と売上高のデータがN組あるということです。\nこのデータの関係を線形で表すモデルとして、\\hat y = \\hat a + \\hat b xを考えます。 観測値はy_i = a + bx_i + e_iです。 したがって、残差e_iはy_i - \\hat y_iとなります。\n\ndata &lt;- data.frame(\n  x = c(1, 2, 3, 4, 5),\n  y = c(3, 10, 9, 12, 18)\n)\nmodel &lt;- lm(y ~ x, data = data)\n\n# 回帰直線と残差を含むグラフを作成する\nggplot(data, aes(x, y)) +\n  geom_point(size = 2) +  # 散布図のプロット\n  geom_smooth(method = \"lm\", se = FALSE, fullrange = TRUE) +  # 回帰直線のプロット\n  geom_segment(aes(xend = x, yend = predict(model), color = \"Residuals\")) +  # 残差のプロット\n#  geom_hline(yintercept = 0, linetype = \"dashed\") +  # 残差0の水平線\n  labs(title = \"回帰直線と残差\", x = \"x\", y = \"y\") +  # グラフのタイトルと軸ラベル\n  scale_color_manual(values = c(\"Residuals\" = \"blue\")) + # 残差の色を指定する\n  xlim(0, 6) + ylim(0, 20) + mystyle # x軸とy軸の範囲を指定する\n\n\n\n\nこの観測値を表す点から回帰直線に向けて書かれた垂線の長さが残差eとなります。 この二乗和を最小にするような回帰直線を求めることが最小二乗法です。 残差の二乗和は、次のように計算できます。\n\n\\begin{aligned}\n\\sum_{i \\in N} e_i^2 &= \\sum_{i \\in N} (y_i - \\hat y_i)^2 \\\\\n&= \\sum_{i \\in N} (y_i - \\hat a - \\hat b x_i)^2 \\\\\n&= \\sum_{i \\in N} (y_i - \\bar y + \\bar y - \\hat a - \\hat b x_i)^2 \\\\\n&= \\sum_{i \\in N} (y_i - \\bar y)^2 + \\sum_{i \\in N} (\\bar y - \\hat a - \\hat b x_i)^2 + 2 \\sum_{i \\in N} (y_i - \\bar y)(\\bar y - \\hat a - \\hat b x_i) \\\\\n&= \\sum_{i \\in N} (y_i - \\bar y)^2 + \\sum_{i \\in N} (\\bar y - \\hat a - \\hat b x_i)^2 + 0 \\\\\n\\end{aligned}\n\nこの最小二乗法による回帰直線の傾きと切片を推定するには、lm関数を使います。 lm()関数は引数にformulaとdataを取ります。\n\nformula : 回帰式を指定します。y ~ xとすると、yをxで回帰します。\ndata : データフレームを指定します。\n\n\nres01 &lt;- lm(log_売上高 ~ log_広告宣伝費, data = df)\n\n推定結果を代入したresの中を詳細に見るには、summary関数を使います。\n\nsummary(res01)\n\n\nCall:\nlm(formula = log_売上高 ~ log_広告宣伝費, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.6125 -0.7040 -0.0514  0.7580  3.5226 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    7.770869   0.056878  136.62   &lt;2e-16 ***\nlog_広告宣伝費 0.550978   0.007225   76.26   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.077 on 4440 degrees of freedom\nMultiple R-squared:  0.5671,    Adjusted R-squared:  0.567 \nF-statistic:  5815 on 1 and 4440 DF,  p-value: &lt; 2.2e-16\n\n\n重要な情報が表示されますが、いろいろ表示されすぎて見づらいので、modelsummary関数を使って見やすくします。\n\nlibrary(modelsummary)\nmodelsummary(res01)\n\n\n\n\n\n (1)\n\n\n\n\n(Intercept)\n7.771\n\n\n\n(0.057)\n\n\nlog_広告宣伝費\n0.551\n\n\n\n(0.007)\n\n\nNum.Obs.\n4442\n\n\nR2\n0.567\n\n\nR2 Adj.\n0.567\n\n\nAIC\n13272.0\n\n\nBIC\n13291.2\n\n\nLog.Lik.\n-6632.994\n\n\nF\n5815.313\n\n\nRMSE\n1.08\n\n\n\n\n\n\n\nいろいろオプションを追加して、もっと見やすい表にします。\n\nlibrary(modelsummary)\ncm  &lt;-  c(\n    \"(Intercept)\" = \"切片\", # 切片のラベルを変更する\n    \"log_広告宣伝費\" = \"対数広告宣伝費\" # 傾きのラベルを変更する\n)\nmsummary(res01,\n  stars = TRUE, # p値の有意性を星で表示する\n  fmt = '%.2f',\n  coef_map = cm,\n  gof_omit = \"AIC|BIC|Log.Lik.\",\n  output = 'html'\n)\n\n\n\n\n\n (1)\n\n\n\n\n切片\n7.77***\n\n\n\n(0.06)\n\n\n対数広告宣伝費\n0.55***\n\n\n\n(0.01)\n\n\nNum.Obs.\n4442\n\n\nR2\n0.567\n\n\nR2 Adj.\n0.567\n\n\nF\n5815.313\n\n\nRMSE\n1.08\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\n\nとなり、切片が7.77、傾きが0.55と推定されました。 独立変数も従属変数も対数変換をしているため、解釈としては、 広告宣伝費が1\\%上昇すると、売上が0.55\\%増加する、という統計的に正の関係があるといえます。"
  },
  {
    "objectID": "Empoli_Chap10.html#単回帰と重回帰",
    "href": "Empoli_Chap10.html#単回帰と重回帰",
    "title": "10  回帰分析の基礎",
    "section": "10.3 単回帰と重回帰",
    "text": "10.3 単回帰と重回帰\n今までは説明変数が1つだけでしたが、複数の要因が応答変数に影響を与える場合もあります。その場合は、複数の説明変数を使った重回帰分析を行います。\n\ny_i = \\beta_0 + \\beta _1 x_1 + \\beta_2x_2 + e_i\n\nという回帰式を考えます。 この式は、x_1とx_2の2つの説明変数が応答変数yに影響を与えることを表す回帰モデルとなっています。 先の例で用いたデータを使って、広告宣伝費と研究開発費が与える影響についてみてみましょう。\nまずは、単回帰と同様に、散布図と回帰平面を描いてみます。 単回帰では、説明変数が1つであったため、応答変数との関係を2次元平面上にプロットすることができましたが、今回の重回帰では説明変数2個と応答変数の関係となるため、3次元空間にプロットする必要があります。 そのため、回帰直線では無く、回帰平面を描くことになります。\n\n# install.packages(\"rgl\")\nlibrary(rgl) # 3Dグラフのパッケージ\nlibrary(knitr) # グラフの表示を操作\nknitr::knit_hooks$set(webgl = hook_webgl) # おまじない\n\n# 回帰モデルを推定する\nmodel &lt;- lm(log_売上高 ~ log_広告宣伝費 + log_研究開発費, data = df)\n\n# プロットする範囲の値を指定する\nx1_range &lt;- range(df$log_広告宣伝費)\nx2_range &lt;- range(df$log_研究開発費)\n\n# # メッシュグリッドを作成する\ngrid &lt;- expand.grid(\n  log_広告宣伝費 = seq(x1_range[1], x1_range[2], length.out = 50),\n  log_研究開発費 = seq(x2_range[1], x2_range[2], length.out = 50)\n  )\n# メッシュグリッド上での予測値を計算する\ngrid$log_売上高 &lt;- predict(model, newdata = grid)\n\n# メッシュグリッドの座標を行列に変換する\nx1_matrix &lt;- matrix(grid$log_広告宣伝費, nrow = 50)\nx2_matrix &lt;- matrix(grid$log_研究開発費, nrow = 50)\ny_matrix &lt;-  matrix(grid$log_売上高,    nrow = 50)\n\n# グラフを出力\nplot3d(df$log_広告宣伝費, df$log_研究開発費, df$log_売上高,\n xlab = \"対数広告宣伝費\", ylab = \"対数研究開発費\", zlab = \"対数売上高\"\n ) # 3D散布図を描く\nsurface3d(x1_matrix, x2_matrix, y_matrix, alpha = 0.5, color = \"red\") # 回帰平面を描く"
  },
  {
    "objectID": "Empoli_Chap10.html#会計データを使った重回帰",
    "href": "Empoli_Chap10.html#会計データを使った重回帰",
    "title": "10  回帰分析の基礎",
    "section": "10.4 会計データを使った重回帰",
    "text": "10.4 会計データを使った重回帰\nでは実際に会計データを使った重回帰分析を行ってみましょう。 売上高yを広告宣伝費x_1と研究開発費x_2で説明する、つまり\n\n\\log y_i = \\beta_0 + \\beta_1 \\log x_{1,i} + \\beta_2 \\log x_{2,i} + e_i\n\nという線形回帰モデルを考えます。 重回帰式の推定は、単回帰式と同様にlm関数を使い、複数の説明変数を+でつなげて指定します。\n\nres02 &lt;- lm(log_売上高 ~ log_広告宣伝費 + log_研究開発費, data = df)\nsummary(res02)\n\n\nCall:\nlm(formula = log_売上高 ~ log_広告宣伝費 + log_研究開発費, \n    data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9369 -0.5689 -0.0217  0.5057  3.5677 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    6.298486   0.055753  112.97   &lt;2e-16 ***\nlog_広告宣伝費 0.323990   0.007583   42.73   &lt;2e-16 ***\nlog_研究開発費 0.402482   0.008479   47.47   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8775 on 4439 degrees of freedom\nMultiple R-squared:  0.7128,    Adjusted R-squared:  0.7127 \nF-statistic:  5509 on 2 and 4439 DF,  p-value: &lt; 2.2e-16\n\n\n回帰係数だけを知りたいときは、coef()関数を使うと便利です。 ここでは単回帰の例と同様に、modelsummaryパッケージを使って結果をまとめてみましょう。\n\nresults &lt;- list() # 結果を格納するリストを作成\nresults[[\"単回帰\"]] &lt;- res01 # 単回帰の結果\nresults[[\"重回帰\"]] &lt;- res02 # 重回帰の結果\n\nmodelsummary(results, # 結果を表にして出力\n  stars = TRUE, # p値の有意性を星で表示する\n  fmt = '%.2f', # 小数点以下2桁で表示する\n  gof_omit = \"AIC|BIC|Log.Lik.\", # 不要な指標を除去\n  output = 'html' # 出力形式をhtmlにする\n  )\n\n\n\n\n\n単回帰\n重回帰\n\n\n\n\n(Intercept)\n7.77***\n6.30***\n\n\n\n(0.06)\n(0.06)\n\n\nlog_広告宣伝費\n0.55***\n0.32***\n\n\n\n(0.01)\n(0.01)\n\n\nlog_研究開発費\n\n0.40***\n\n\n\n\n(0.01)\n\n\nNum.Obs.\n4442\n4442\n\n\nR2\n0.567\n0.713\n\n\nR2 Adj.\n0.567\n0.713\n\n\nF\n5815.313\n5509.365\n\n\nRMSE\n1.08\n0.88\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\n\n\n広告宣伝費の対数の回帰係数が、単回帰のときの0.55から0.32に減少しています。 これは、研究開発費の対数が追加されたことで、広告宣伝費が売上高を説明する部分が減少したことを意味します。 そして、研究開発費の対数の回帰係数は0.40となっており、広告宣伝費とともに統計的に有意な値となっています。 つまり、研究開発費も売上高を説明する要因となっていることがわかります。"
  },
  {
    "objectID": "Empoli_Chap10.html#単回帰と重回帰の違い",
    "href": "Empoli_Chap10.html#単回帰と重回帰の違い",
    "title": "10  回帰分析の基礎",
    "section": "10.5 単回帰と重回帰の違い",
    "text": "10.5 単回帰と重回帰の違い\n単回帰と重回帰の違いを、実際にデータを使って確認してみましょう。 つまり、以下の3つの回帰モデルの関係について考えてみます。\n\n\\begin{aligned}\ny &= \\beta_0 + \\beta _1 x_1 + \\beta _2 x_2 + e\\\\\ny &= \\alpha_0 + \\alpha _1 x_1 + e_1\\\\\ny &= \\gamma_0 + \\gamma _1 x_2 + e_2\n\\end{aligned}\n\nこのとき、\\beta_1 = \\alpha_1と\\beta_2 = \\gamma_1でとなるのでしょうか？ やってみましょう。\nまず、研究開発費の対数を説明変数として、売上高の対数を目的変数として回帰分析を行います。\n\nres03 &lt;- lm(log_売上高 ~ log_研究開発費, data = df)\n\nこれをmodelsummaryパッケージを使ってまとめてみましょう。\n\nresults &lt;- list()\nresults[[\"単回帰1\"]] &lt;- res01 # 単回帰の結果\nresults[[\"単回帰2\"]] &lt;- res03 # 単回帰の結果\nresults[[\"重回帰\"]] &lt;- res02 # 単回帰の結果\nmodelsummary(results, # 結果を表にして出力\n  stars = TRUE, # p値の有意性を星で表示する\n  fmt = '%.3f', # 小数点以下3桁で表示する\n  gof_omit = \"AIC|BIC|Log.Lik.\", # 不要な指標を除去\n  output = 'html' # 出力形式をhtmlにする\n  )\n\n\n\n\n\n単回帰1\n 単回帰2\n重回帰\n\n\n\n\n(Intercept)\n7.771***\n6.936***\n6.298***\n\n\n\n(0.057)\n(0.064)\n(0.056)\n\n\nlog_広告宣伝費\n0.551***\n\n0.324***\n\n\n\n(0.007)\n\n(0.008)\n\n\nlog_研究開発費\n\n0.631***\n0.402***\n\n\n\n\n(0.008)\n(0.008)\n\n\nNum.Obs.\n4442\n4442\n4442\n\n\nR2\n0.567\n0.595\n0.713\n\n\nR2 Adj.\n0.567\n0.595\n0.713\n\n\nF\n5815.313\n6515.603\n5509.365\n\n\nRMSE\n1.08\n1.04\n0.88\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\n\n\n\n\\beta_1 = \\alpha_1と\\beta_2 = \\gamma_1にはなっていないようです。 なぜでしょう？ それは、重回帰分析の係数は、他の変数を一定としたときのある説明変数が応答変数に与える影響の強さ、なので、単回帰ごとの結果と重回帰の結果は異なります。 そのことを確認するために、研究開発費と広告宣伝費の散布図を描いてみましょう。\n\nggplot(df) + aes(x = log_広告宣伝費, y = log_研究開発費) + geom_point() + mystyle\n\n\n\n\n研究開発費と広告宣伝費の間には、やや強い相関があるようです。相関係数は、0.6306058となります。\nこの関係を前提として，単回帰分析の結果から重回帰分析の結果を導出してみます。 この方法を回帰解剖(regression anatomy)といいます。\nまず，売上高の対数を広告宣伝費の対数で回帰した結果から回帰誤差を得ます。回帰残差を取り出すには、residuals()関数を使います。 この回帰誤差は，売上高の変動のうち，広告宣伝費とは関係ない部分といえます。\n\nres &lt;- lm(log_売上高 ~ log_広告宣伝費, data = df)\nresid_sale &lt;- residuals(res)\n\n売上高の自然対数を広告宣伝費の自然対数で回帰した残差をresid_saleに代入しました。 次に，広告宣伝費を研究開発費で回帰します。\n\nres_adv = lm(log_研究開発費 ~ log_広告宣伝費 , data = df)\ncoef(res_adv)\n\n   (Intercept) log_広告宣伝費 \n     3.6582599      0.5639725 \n\n\nこの結果の残差は、研究開発費の対数の変動のうち、広告宣伝費の対数が説明できていない部分です。 つまり広告宣伝費のうち、研究開発費とは関係のない部分となります。 回帰残差を取り出すには、residuals()関数を使います。\n\nresid_adv &lt;- residuals(res_adv)\nplot(resid_adv)\n\n\n\n\n売上高の変動のうち広告宣伝費とは関係ない部分である残差resid_saleを，研究開発費の変動の内広告宣伝費とは関係のない部分である残差resid_advで回帰します。\n\nres_ee &lt;- lm(resid_sale ~ resid_adv)\nround(coef(res_ee), digits = 3)\n\n(Intercept)   resid_adv \n      0.000       0.402 \n\n\nこのresid_advの回帰係数をみると，0.402となっており，前に計算した重回帰分析の研究開発費の自然対数の回帰係数と一致しております。\nつまり，重回帰分析の係数とは，複数の説明変数の中で，他の説明変数とは関係の無い部分が，応答変数と他の説明変数との間の関係のない部分に与える影響の強さを表しているということです。\nここでいうと，重回帰分析における研究開発費の回帰係数の意味するところは，研究開発費の変動のうち広告宣伝費とは関係ない部分が，応答変数の変動のうち広告宣伝費とは関係の無い部分に与える影響，を意味しています。"
  },
  {
    "objectID": "Empoli_Chap10.html#決定係数",
    "href": "Empoli_Chap10.html#決定係数",
    "title": "10  回帰分析の基礎",
    "section": "10.6 決定係数",
    "text": "10.6 決定係数\n重回帰分析の結果を見ると、R^2という値が表示されています。 これは、決定係数と呼ばれる値で、回帰モデルの当てはまりの良さを表す指標の1つです。\n決定係数について，以下の点くらいは覚えておくとよいでしょう。\n\n決定係数は、0から1の値をとります。\n決定係数は、説明変数の数が増えると必ず増加するので，重回帰分析では修正決定係数を使うことが多いです。\n決定係数が1に近いほど、回帰モデルがデータによく当てはまっていることを表しますが，どれだけ高い数値だと良いかの目安はなく、研究分野やリサーチデザインによっても異なります。\n決定係数は検定統計量ではないため，すべての回帰係数がゼロであるという帰無仮説を検定するF統計量でモデルの有意性を判断します。\n決定係数以外にも，赤池情報量規準やベイズ情報量規準などの指標もありますが，今回は後者の2つは扱いません。"
  },
  {
    "objectID": "Empoli_Chap11.html#単回帰による統計的推定",
    "href": "Empoli_Chap11.html#単回帰による統計的推定",
    "title": "11  回帰分析による統計的推定",
    "section": "11.1 単回帰による統計的推定",
    "text": "11.1 単回帰による統計的推定\n\n11.1.1 単回帰モデル\n売上高と広告宣伝費の関係を考えるため、前章では散布図(scatter diagram)を使って、2変数の関係を見てみました。  次のような売上高を広告宣伝費で説明するモデルを考えてみます。\n\n\n\n\ngraph LR\nA[広告宣伝費] --&gt; B[売上高]\n\n\n\n\n\nこの因果関係を明らかにするため、売上高を応答変数Y、広告宣伝費を説明変数Xとして、次のようなモデルを構築します。\n\nY_i = \\beta _0 + \\beta_1 X_i\n\nここで\\beta_0と\\beta_1は定数です。 したがって、X_iの値が決まれば、応答変数Yの値は一意に決まります。 このようなモデルを決定的モデル(deterministic model)と呼びます。\nただ現実には、広告宣伝費が同じでも売上高が異なることがあります。 そこで売上高の水準が広告宣伝費だけで決まるのではなく、広告宣伝費では説明しきれない要因があることをモデルで表すために、確率変数である誤差項(error term)を回帰モデルに加えたものを考えます。\n\nY_i = \\beta _0 + \\beta_1 X_i + \\varepsilon_i\n\n現実のデータで，1つの説明変数が応答変数を完全に説明できる(つまりモデル上にすべてのデータが載っている)ことはほとんどないため、確率変数である誤差項を含めたモデルを確率モデル(probabilistic model)と呼びます。 本書では単回帰モデルとは、\\varepsilon_iが正規分布に従うと仮定したモデルを指します。 図で書くと，次のようなモデルです。\n\n\n\n\n\nこの回帰モデルが意味をもつためには、誤差項\\varepsilon_iが平均0で分散\\sigma^2の正規分布に従うという仮定が必要です。\n\n\n\n図11.1\n\n\n\n\n11.1.2 信頼区間と仮説検定"
  },
  {
    "objectID": "Empoli_Chap11.html#重回帰分析による統計的推定",
    "href": "Empoli_Chap11.html#重回帰分析による統計的推定",
    "title": "11  回帰分析による統計的推定",
    "section": "11.2 重回帰分析による統計的推定",
    "text": "11.2 重回帰分析による統計的推定\n\n11.2.1 重回帰モデル\n重回帰でも単回帰でも統計的推定に変わりはありません。 重回帰モデルを以下のように表します。\n\nY_i = \\beta _0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots + \\beta_p x_{ik} + \\varepsilon_i\n\nこの回帰係数\\betaの推定値bを求めることが統計的推定です。\n企業の売上高は、前年度の広告宣伝費と研究開発費で説明できる、つまり前年度の広告宣伝費と研究開発費が高いほど、売上高が高くなるのかどうかを考えてみます。\n\n\\text{売上高}_t = \\beta_0 + \\beta_1 \\text{広告宣伝費}_{t-1} + \\beta_2 \\text{研究開発費}_{t-1} + \\varepsilon_t\n\nではこの回帰モデルを推定するためのデータを読み込むため、tidyverseのreadrパッケージのread_csv()関数を使って、作業ディレクトリのdataフォルダの中に保存されているadv_2023.csvを読み込みます。\n\ndf &lt;- read_csv(\"data/adv_2023.csv\")\n\n重回帰モデルを推定するには、基本関数のlm()を使います。 重回帰モデルの場合、複数の説明変数があるため+でつなげていきます。\n\nres &lt;- lm(売上高 ~ lag(研究開発費) + lag(広告宣伝費), data = df)\ncoef(res)\n\n    (Intercept) lag(研究開発費) lag(広告宣伝費) \n   1.004955e+05    1.716521e+01    6.913074e+00 \n\n\n上記の推定結果から、\n\n\\text{売上高} = 0.00000 + 0.1716 \\text{研究開発費}_{t-1} + 6.8131 \\text{広告宣伝費}_{t-1}\n であることが分かりました。\n\n\n11.2.2 信頼区間と仮説検定\n先ほどの回帰係数の推定結果は，1サンプルからの結果であり，サンプルの数を増やせば推定値の分布ができるのは，単回帰分析と同じなので， ここでも同じ方法で信頼区間を求めることが出来ます。 単回帰分析の場合，切片と回帰係数の2つが推定するパラメータなので，自由度がn-2のt分布を利用しました。 説明変数がk個ある重回帰分析の推定で利用するt分布の自由度は，n-k-1になります。 100(1-\\alpha)％信頼区間は，\n\nb_m - t _{n-k-1, \\frac{\\alpha}{2}} SE(b_m) \\leq \\beta_m \\leq b_m + t_{n-k-1, \\frac{\\alpha}{2}} SE(b_m)"
  },
  {
    "objectID": "Empoli_Chap15.html#ロジスティック関数",
    "href": "Empoli_Chap15.html#ロジスティック関数",
    "title": "14  ロジスティック回帰分析",
    "section": "14.1 ロジスティック関数",
    "text": "14.1 ロジスティック関数\n「当たったか、外れたか」、「ある会計基準を選択したか、否か」、「ある商品を購入したか、否か」など、結果が二値で表されるような変数を二値変数(binary variable)といい、二値変数を応答変数として回帰分析したいとき、ロジスティック回帰分析が便利です。\n事象Aと事象Bのどちらかが起こるとき、事象Aが起こる確率をpとすると、事象Bが起こる確率は1-pとなります。 pは確率を表しているので，0から1の間の値をとります。 この事象Aが起こる確率と事象Aが起こらない確率の比をオッズ(odds)といいます。\n\n\\frac{p}{1-p}\n\nこのオッズは，0から\\inftyの間の値をとります。 たとえば事象Aが起こる確率が10％と見積もられる場合，オッズは0.1/0.9 = 0.111となります。 さらにこのオッズを対数変換して，pの関数f(p)としたものをロジット関数と言います。 こうすることで，pは0から1の値をとるとき，f(p)は-\\inftyから\\inftyの値をとるようになります。\n\nf(p) = \\log \\left( \\frac{p}{1-p} \\right) = \\log p - \\log (1-p)\n\n図で書くとこうなります。\n\n\n\n\n\nロジット関数\n\n\n\n\n次に，ロジット関数f(p)の逆関数を考えます。 対数関数の逆関数は指数関数になるので，先のロジット関数の両辺の指数をとると，次のようになります。\n\n\\exp(f(p)) = \\frac{p}{1-p}\n\nこの式をpについて解くと，次のようになります。\n\n\\begin{aligned}\np &= \\frac{\\exp(f(p))}{1 + \\exp(f(p))} \\\\\n  &= \\frac{\\frac{\\exp(f(p))}{\\exp(f(p))}}{\\frac{1 + \\exp(f(p))}{\\exp(f(p))}} \\\\\n  &= \\frac{1}{\\frac{1}{\\exp(f(p))}+1} \\\\\n  &= \\frac{1}{1 + \\exp(-f(p))}\n\\end{aligned}\n\nロジット関数f(p)の逆関数をf^{-1}(x)とすると，f^{-1}(x)は-\\inftyから\\inftyの値をとるとき，pは0から1の値をとるようになります。 これからの分析に必要な関数の形がでてきました。 この関数f^{-1}(x)を標準ロジスティック関数と言います。\n\nf^{-1}(x) = \\frac{\\exp(x)}{1 + \\exp(x)} = \\frac{1}{1 + \\exp(-x)}\n\n標準ロジスティクス関数は次のような形をしています。\n\n\n\n\n\n標準ロジスティック関数\n\n\n\n\n標準ロジスティクス関数の定義域は-\\inftyから\\inftyですが，xが0のとき，f^{-1}(x)は0.5となります。\n応答変数が二値変数となる場合の分析手法で最もよく利用されているものが，ロジスティック回帰分析です。 手元の応答変数データは0と1の2種類しかなく、このようなデータを生み出す確率モデルにはベルヌーイ分布が適しています。 ベルヌーイ分布は、確率pで1、確率1-pで0をとる確率分布です。 この確率pを先ほど導出したロジスティック関数(logistic function)で表します。\n\n\\text{logistic}(x) = \\frac{\\exp(x)}{1 + \\exp(x)} = \\frac{1}{1 + \\exp(-x)}\n\nこのロジスティック関数を使って、確率pを次のように表すことができます。\n\n\\Pr(y_i = 1)  = \\text{logistic}(b_0 + b_1x_i) =  \\frac{1}{1 + \\exp(-\\beta_0 - \\beta_1 x_i)}\n\nこの式は、x_iが与えられたときにy_iが1となる確率を表しています。 この式を変形すると、次のようになります。\n\n\\log \\left( \\frac{\\Pr(y_i = 1)}{1 - \\Pr(y_i = 1)} \\right) = \\beta_0 + \\beta_1 x_i\n\nようやく回帰分析の式になりました。\n\n14.1.1 最尤法\nつぎに，この\\betaを推定する方法を考えます。 この回帰モデルは非線形であるため，モデルと観測値の誤差を最小にする，という最小二乗法を使ってパラメータを推定することはできません。 そこで，最尤法(most likelifood method)を使ってパラメータを推定します。 最尤法とは，観測値が得られる確率を最大にするようなパラメータを推定する方法で，一定の条件のもとで優れた推定量を与えることが知られています。\n最尤法について考える前に，まずロジスティック回帰のモデルの背後にある線形モデルについて考えてみます。 観察される応答変数y_iは0か1という二値変数となりますが，その背後には，線形関係があると考えることができます。 つまりある閾値y^*を設定して，y_iがy^*より大きいときは1，y^*より小さいときは0となると考えることができます。\n\ny_i =\n\\begin{cases}\n1 & \\text{if } \\beta_0 + \\beta_1 x_i + \\epsilon_i &gt; y^* \\\\\n0 & \\text{if } \\beta_0 + \\beta_1 x_i + \\epsilon_i \\leq y^*\n\\end{cases}"
  },
  {
    "objectID": "index.html#教科書について",
    "href": "index.html#教科書について",
    "title": "プレゼミ",
    "section": "教科書について",
    "text": "教科書について\nプレゼミのメインテキストは浅野・矢内 (2020)「Rによる計量政治学」オーム社です。 このウェブ資料も、このテキストをベースに作成されています。 サブテキストであるウィラワン・勝又 (2023)「Rによるマーケティング・データ分析」新世社、の一部の内容も含まれています。 重要参考図書として、久保克行 (2021)「経営学のための統計学・データ分析」東洋経済、も用意されています。 基本的に松浦が自分の勉強用に作成したノートのため、誤りや不備が含まれている可能性が高いです。ミスなどを見つけ次第、松浦まで報告してくれると助かります。 また、このノートは、浅野・矢内 (2020)やウィラワン・勝又 (2023)の内容を網羅しているわけではないので、このノートを使う場合は教科書を手元において、学習することをおすすめします。\nなぜ会計学を専門とする松浦のプレゼミで、メインの教科書が「Rによる計量政治学」なのかというと、このテキストが社会科学の一分野である政治学という経営学部生にとっても関連のある興味深い題材を用いて、計量経済学の基礎から応用までをRで実装するための知識を習得できるものだからです。 とりわけ第1部の第2章「研究テーマの選び方」と第3章「理論と仮説」は、卒業論文を書く際にも非常に重要となる内容ですので、全経営学部生によんでもらいたい内容です。 第4章「Rの使い方」と第5章「Rによるデータ操作」は、本書の学習に必要な必要最小限の内容ですので、他の教科書やウェブサイトを参考にして、より詳細な内容を学習したほうが良いですが、この内容を理解し、使えるようになれば、MS Excelを使わずにRだけで分析できるようになるでしょう。\n第6章から第15章までが、統計学から計量経済学の内容となります。 おおよそ、代表的な統計量の計算や、グラフを使ったデータの理解、標本(sample)を用いた母集団(population)の推定や仮説検定、複数の統計量の関係性の理解、因果関係を分析する手法の1つである回帰分析の基礎と応用、2値選択の問題を推定するためのロジスティック関数の使い方などを学習します。\nここまでの内容の学習にプレゼミ15回のうちおおよそ11回を使います。 12回〜14回の3回は多変量解析手法として因子分析やクラスター分析、機械学習を用いた判別モデルとして決定木分析を学習します。 最後の講義となる第15回目では、今まで修得した知識を使って、データ分析を行った結果を発表してもらいます。\n2年生終了時点で、これらの内容を修得していれば、卒業論文の分析に必要な知識はほぼ習得できていると考えて良いでしょう。あとは関心のある研究テーマを選ぶために、面白そうな専門演習(ゼミ)に入って、Rと統計学・計量経済学を使った実証研究を楽しんでくれれば、プレゼミの目標が達成されます。"
  },
  {
    "objectID": "index.html#プレゼミの形式について",
    "href": "index.html#プレゼミの形式について",
    "title": "プレゼミ",
    "section": "プレゼミの形式について",
    "text": "プレゼミの形式について\nこのプレゼミは、基本的には反転授業の形式をとります。 つまり、授業は家で受けて、大学で宿題をやる、という形式です。\nまず、講義を受ける前に教科書の該当章とこのノートを読んでおきます。 その上で、大学に来て宿題をやります。 そして宿題の内容を発表し、議論します。\n宿題の内容は、講義中に指示します。"
  },
  {
    "objectID": "index.html#プレゼミのスケジュール",
    "href": "index.html#プレゼミのスケジュール",
    "title": "Rによる計量政治学ノート",
    "section": "プレゼミのスケジュール",
    "text": "プレゼミのスケジュール\nプレゼミのスケジュールはおおよそ以下の通りです。\n\n第1回 プレゼミの概要とメンバー紹介\n第2回 実証会計学、研究テーマの選び方・理論と仮説\n第3回 Rの使い方とRによるデータ操作\n第5回 記述統計とデータの可視化・視覚化\n第6回 統計的推定と統計的仮説検定\n第7回 変数間の関連性\n第8回 回帰分析の基礎と統計的推定\n第9回 回帰分析の応用\n第10回 交差項の使い方\n第11回 ロジスティック関数\n第12回 質問紙の作成と測定尺度\n第13回 因子分析\n第14回 クラスター分析・決定木(時間があれば)\n第15回 成果報告会 (報告者は6名程度を想定)"
  },
  {
    "objectID": "index.html#補足-1.",
    "href": "index.html#補足-1.",
    "title": "プレゼミ",
    "section": "補足 1.",
    "text": "補足 1.\n第3回目のプレゼミでRの導入について説明しますが、早いうちにこのノートに書かれている内容や、紹介しているウェブサイトを参考にして、自分のPCにRをインストールするか、あるいはPosit Cloudというブラウザ上でRを使えるサービスに登録しておいてください。"
  },
  {
    "objectID": "index.html#補足-2.",
    "href": "index.html#補足-2.",
    "title": "プレゼミ",
    "section": "補足 2.",
    "text": "補足 2.\n本ノートは、Posit社(以前はRstudio社)が開発したQuartoというソフトウェアを使って作成されています。Quartoとは、RMarkdownの記法で書かれたテキストファイルを、knitrというソフトウェアを介して、HTMLやPDF、MS Word、EPUBなどのファイルを作成するためのソフトウェアです。\n最大の特徴は、MS ExcelとMS Wordのようにデータを分析する場所と文章を書く場所が別々ではなく、一つの画面の中でデータ分析とレポート・論文執筆を同時に行える、というものです。\nまた、Rだけでなく、PythonやJuliaといった他のプログラミング言語も文章内に埋め込むことができるため、データ分析と文章執筆を統合させる環境として非常に優れています。 プレゼミでも、Quartoを使って最終レポートの作成を行う予定です。 Quartoは今も開発が進んでいる新しいレポート作成ソフトウェアなので、情報が少ないことが難点ですが、公式サイトと私たちのRを見れば大抵のことは分かります。"
  },
  {
    "objectID": "Empoli_Chap01.html#研究テーマの選び方",
    "href": "Empoli_Chap01.html#研究テーマの選び方",
    "title": "1  計量会計学？",
    "section": "1.3 研究テーマの選び方",
    "text": "1.3 研究テーマの選び方\nプレゼミの達成目標は、経営事象に関する問題を発見し、その問題がなぜ生じているのか、どうすれば解決できるのかを考えることができるようになることです。 そこで、まずは研究課題の種類について学びます。 問いの立て方には大きく分けて3つのタイプがあります。\n\n実証的問題\n規範的問題\n分析的問題\n\nこの3種類の問題について説明します。\n\n「よい研究テーマ」の選び方を理解すること\n\n「よい研究テーマ」の探し方を理解したらよい研究テーマが見付かるわけではないで、自分が面白い！と思えるような、興味引かれるテーマを見つけることが重要です。"
  },
  {
    "objectID": "Empoli_Chap01.html#リサーチクエスチョンの種類",
    "href": "Empoli_Chap01.html#リサーチクエスチョンの種類",
    "title": "1  計量会計学？",
    "section": "1.4 リサーチ・クエスチョンの種類",
    "text": "1.4 リサーチ・クエスチョンの種類\nリサーチ・クエスチョン(research question)とは、研究対象となる会計に関する、抽象度の高い問いのことです。 リサーチ・クエスチョンが決まれば、その問いに答えるために、何をするべきなのかが決まるため、非常に重要な要素となります。 たとえば、\n\n会計情報の質が高いと、投資家の意思決定がよりよいものになるのか？\n大きな監査法人は、財務報告の質を高めているのか？\nCSR活動に積極的な会社は、納税も積極的か？\nのれんは償却するべきか？\nIFRS採用企業と非採用企業の違いはあるのか？\nコロナ禍における利益圧縮活動は行われたのか？\n\nこれらのリサーチ・クエスチョンを3つに分類してみましょう。\n\n1.4.1 実証的問題\n実証的問題では、事実を調べることが目的となります。 たとえば、「のれんの非償却はM&Aを促進させるのか」という問いに対しては、のれんの非償却を行っている企業と、行っていない企業のM&Aの実施率を比較することで、その問いに答えることができます。\n実証的問題を扱う会計研究でも、定量的な研究だけでなく、インタビューによる定性的な研究もあります。参与観察研究はあまり見ません。 事実に注目する研究となるため、主観的な要素はできるだけ排して、観察されたデータや発言といった客観的なデータを用いることが多いです。 このプレゼミでは、主として経営学分野における実証的問題を扱います。\n\n\n1.4.2 規範的問題\nいわゆる「べき論」を扱う問題で、日本の会計研究では今でも盛んに行われている研究です。 たとえば、「のれんは償却すべきか」という問いに対しては、のれんの償却を行うことで、どのようなメリットがあるのか、どのようなデメリットがあるのかを考え、そのメリットとデメリットを比較することで、その問いに答えることができます。 ただ、この場合でも、「誰にとっての」メリットを重視するべきなのか、という問題がでますが、そこは研究者の価値判断によって決まることになり、研究者の主観が大きく反映されることになります。\nしたがって教科書でも、規範的問題を実証的問題に変換する方法を考え、規範的問題を直接あつかう研究課題は取りあげません。\n\n\n1.4.3 分析的問題\n分析的問題は、まだ起こっていない、観察されていない現象を扱います。 そもそも起こっていない現象なのでデータも取りようがありません。 そこで、分析的問題では、モデル(model)を用いて、現象の起こりうるメカニズムを考えます。\n基本的には、関心のある問題を抽象化して数式で表現し、前提条件と仮定を設定し、その問題を解くことで得られた結果を解釈することで、その問いに答えることができます。 たとえば、税務会計や監査といった情報が入手困難な領域において、ゲーム理論や契約理論、最適化理論を用いた分析が行われることが多いような気がしますが、そこまで詳しくないでし、難しいので、ここでは扱いません。\nしたがって、このプレゼミでは、各自がたてた実証的問題について考えていきます。"
  },
  {
    "objectID": "Empoli_Chap01.html#よい研究テーマの見つけ方",
    "href": "Empoli_Chap01.html#よい研究テーマの見つけ方",
    "title": "1  計量会計学？",
    "section": "1.5 「よい研究テーマ」の見つけ方",
    "text": "1.5 「よい研究テーマ」の見つけ方\n政治学のMonroe (2000, pp.8–10)によると、\n\n明快さ\n検証可能性\n理論的重要性\n実用性\n独創性\n\nがよい研究テーマに必要な要素らしいです。\n詳しくは教科書を読むとして、会計学や経営学でもほぼ同じですが、卒業論文においては、理論的重要性と独創性はあればよいですが、必ずしも必要ではありません。 なぜなら、理論的重要性を理解し、論文で示すことは、研究で用いる推論の背後にある理論や仕組みを完全に理解する必要がありますし、独創性を主張するためには、膨大な先行研究を読み、自分の主張が他の人とどう違うのか、どの点が新しいのかを明らかにする必要があり、とても時間がかかるからです。\nしたがって、明快な推論で導き出された仮説を、客観的なデータを用いて、適切な手法で分析し、その結果を解釈し、経営実務にどういう影響があるのか、を主張できれば、卒業論文としては申し分ないレベルです。\nとりわけ、このプレゼミでは、検証可能性を重視します。 そのレポート・論文を読めば、他の人でも同じ分析を行うことが可能であり、誰でも追試が行えることが重要です。 データの集め方や変数の作り方、データ分析のプロセスが明確にしめされており、それを自分でもすぐに再現することが重要です。そのためにRは非常に有効なツールとなります。\n\n1.5.1 規範的問題から実証的問題への変換\n「べき論」は研究者の価値判断が大きく反映され、その研究者が主張する価値は主観的なものになるため検証ができません。 そこで規範的問題を実証的問題になるように問い方を変える方法を考えます。\n\n1つめの方法は、参照枠組みを変える方法です。 「会計は投資意思決定に役立つべきである」という問いは規範的問題で、それは「会計は株主のためのものである」という価値判断が含まれています。このままでは検証できないので、「会計は投資意思決定に役に立っているのか？」に変えることで、検証可能な問いになります。\n\n2つめの方法は、規範的問題の前提条件に注目する方法です。 「会計は投資意思決定の役立つべきである」という規範的記述の背後には、\n\n会計は投資家のためのものである\n投資家が会計(情報)を使えば儲かる。\n投資家の投資が活発になれば、経済は活性化する。\n\nという前提条件があると考えられます。 これを実証的な問題にするには、\n\n会計(情報)の主な利用者は投資家なのか？\n会計情報を使えば儲かるのか？\n投資の役に立つ会計情報を提供することで、経済は活性化するのか？\n\nのように、規範的問題の背後にある前提条件を検証可能な問いに変えることで、実証的な問題になります。\n\n\n1.5.2 パズルを探す\nパズル(puzzle)とは、ある現象を説明するために、既存の理論では説明できない現象のことです。 たとえば、配当パズル(dividend puzzle)とは、配当がなぜ存在するのか、という問題です。 配当は、株主に対する利益配分の一つであり、株主にとっては配当が高いほうがよいはずです。しかし、実際には、配当が高いほど株価が低くなるという現象が観察されます。 このような現象を説明するために、既存の理論では説明できないので、パズルと呼ばれ、研究題材としては非常に魅力的です。\n\n\n1.5.3 研究論文の構成\n論文の構成\n\nイントロダクション\n先行研究\n理論\n仮説\n対抗仮説\n作業化\n証拠\n結論"
  },
  {
    "objectID": "Empoli_Chap07.html#統計的検定の諸問題",
    "href": "Empoli_Chap07.html#統計的検定の諸問題",
    "title": "7  統計的推定",
    "section": "7.4 統計的検定の諸問題",
    "text": "7.4 統計的検定の諸問題\n\n7.4.1 仮説検定における2種類の「誤り」と検出力\n\n第1種の過誤(type 1 error) : 帰無仮説が正しいのに，帰無仮説を棄却してしまう誤り。偽陽性(False Positive)とも呼ばれる。\n第2種の過誤(type 2 error) : 帰無仮説が正しくないのに，帰無仮説を棄却しない誤り。偽陰性（False Negative）とも呼ばれる。\n\n第1種の過誤の例として，よく挙げられる犯罪容疑者の例で説明すると，容疑者が無実なのに，容疑者を有罪としてしまう(えん罪)誤りを第1種の過誤といい，容疑者が犯罪者なのに，容疑者を無罪としてしまう誤りを第2種の過誤といいます。\n第1種の過誤(えん罪)を小さくしたいとします。 この確率を$$で表し，実はこれが有意水準の大きさとなります。 有意水準5％というのは，ある検定統計量の標本分布の平均から離れた5％の面積に入る統計量をかけ離れた値とするかを(研究者が勝手に)決めたものです。 両側検定なら，標本平均から離れた左右の2.5％の面積に入る統計量をかけ離れた値とし，ここに計算した統計量が含まれるとき，帰無仮説を棄却します。\n第1種の過誤と減らすために有意水準を小さくすると，だい2種の過誤が大きくなります。 当然ですが，えん罪を減らそうとしてほとんどのケースを無罪とすると，犯罪者を逃がすことになる，というロジックと同じです。\n帰無仮説が正しいとした場合の正規分布を青色で，真の分布を赤色で示し，有意水準が両側で5％，つまり片側が2.5％となる図を書くとこんな感じです。\n\n# 正規分布の確率密度関数\ndnorm_with_mean_sd &lt;- function(x, mean = 0, sd = 1) {\n  sqrt(1/(2*pi*sd^2))*exp(-((x - mean)^2)/(2*sd^2))\n}\n\n# パラメータの設定\nmu1 &lt;- 0   # 帰無仮説の平均\nsd1 &lt;- 1   # 帰無仮説の標準偏差\nmu2 &lt;- 1.5 # 対立仮説の平均\nsd2 &lt;- 1   # 対立仮説の標準偏差\nalpha = 0.025\n\n# サンプルデータを生成\nx &lt;- seq(-5, 5, by = 0.01)\ndf &lt;- data.frame(x = x,\n                 dnorm1 = dnorm_with_mean_sd(x, mean = mu1, sd = sd1),\n                 dnorm2 = dnorm_with_mean_sd(x, mean = mu2, sd = sd2))\n\n# ggplotを使って描画\ng &lt;- ggplot(df, aes(x = x)) +\n  geom_line(aes(y = dnorm1), color = \"blue\") +\n  geom_line(aes(y = dnorm2), color = \"red\")\ng &lt;- g + geom_area(\n  data = subset(df, x &gt; qnorm(1-alpha, mu1, sd1)),\n            aes(y = dnorm1), fill = \"blue\", alpha = 0.2)\ng &lt;- g + geom_area(\n  data = subset(df, x &lt; qnorm(alpha, mu1, sd1)),\n  aes(y = dnorm1), fill = \"blue\", alpha = 0.2)\ng &lt;- g + geom_area(\n  data = subset(df, x &gt; qnorm(alpha, mu1, sd1) & x &lt; qnorm(1-alpha, mu1, sd1)),\n            aes(y = dnorm2), fill = \"red\", alpha = 0.2) +\n  theme_minimal() +\n  labs(x = \"Value\", y = \"Density\",\n       title = \"両側検定における第1種の過誤と第2種の過誤\")\ng &lt;- g + geom_vline(xintercept = qnorm(1-alpha), linetype=\"dotted\")\ng &lt;- g + geom_vline(xintercept = mu1, color = \"darkblue\")\ng &lt;- g + geom_vline(xintercept = mu2, color = \"darkred\")\n\ng &lt;- g + annotate(\"text\", x = mu1 + 2.5, y = max(df$dnorm1) / 6,\n           label = \"第1種の過誤\", color = \"darkblue\", family = \"HiraKakuProN-W3\") +\n  annotate(\"text\", x = mu2 - 0.5, y = max(df$dnorm2) / 6,\n           label = \"第2種の過誤\", color = \"darkred\", family = \"HiraKakuProN-W3\")\n\ng &lt;- g + annotate(\"text\", x = mu1 - 2, y = max(df$dnorm1)-0.1,\n                  label = \"帰無仮説下の分布\", color = \"blue\", family = \"HiraKakuProN-W3\" ) +\n  annotate(\"text\", x = mu2 + 1.5, y = max(df$dnorm2) - 0.1,\n           label = \"真の分布\", color = \"red\", family = \"HiraKakuProN-W3\") + mystyle\nprint(g)\n\n\n\n\n帰無仮説が正しいときに帰無仮説を棄却する確率である第1種の過誤\\alphaを小さくすると，こうなります。\n\n\n\n\n\n片側検定の場合なら，こんな感じです。"
  },
  {
    "objectID": "Empoli_Chap08.html#統計的検定の諸問題",
    "href": "Empoli_Chap08.html#統計的検定の諸問題",
    "title": "8  統計的仮説検定",
    "section": "8.2 統計的検定の諸問題",
    "text": "8.2 統計的検定の諸問題\n\n8.2.1 仮説検定における2種類の「誤り」と検出力\n\n第1種の過誤(type 1 error) : 帰無仮説が正しいのに，帰無仮説を棄却してしまう誤り。偽陽性(False Positive)とも呼ばれる。\n第2種の過誤(type 2 error) : 帰無仮説が正しくないのに，帰無仮説を棄却しない誤り。偽陰性（False Negative）とも呼ばれる。\n\n第1種の過誤の例として，よく挙げられる犯罪容疑者の例で説明すると，容疑者が無実なのに，容疑者を有罪としてしまう(えん罪)誤りを第1種の過誤といい，容疑者が犯罪者なのに，容疑者を無罪としてしまう誤りを第2種の過誤といいます。\n第1種の過誤(えん罪)を小さくしたいとします。 この確率を$$で表し，実はこれが有意水準の大きさとなります。 有意水準5％というのは，ある検定統計量の標本分布の平均から離れた5％の面積に入る統計量をかけ離れた値とするかを(研究者が勝手に)決めたものです。 両側検定なら，標本平均から離れた左右の2.5％の面積に入る統計量をかけ離れた値とし，ここに計算した統計量が含まれるとき，帰無仮説を棄却します。\n第1種の過誤と減らすために有意水準を小さくすると，だい2種の過誤が大きくなります。 当然ですが，えん罪を減らそうとしてほとんどのケースを無罪とすると，犯罪者を逃がすことになる，というロジックと同じです。\n帰無仮説が正しいとした場合の正規分布を青色で，真の分布を赤色で示し，有意水準が両側で5％，つまり片側が2.5％となる図を書くとこんな感じです。\n\n# 正規分布の確率密度関数\ndnorm_with_mean_sd &lt;- function(x, mean = 0, sd = 1) {\n  sqrt(1/(2*pi*sd^2))*exp(-((x - mean)^2)/(2*sd^2))\n}\n\n# パラメータの設定\nmu1 &lt;- 0   # 帰無仮説の平均\nsd1 &lt;- 1   # 帰無仮説の標準偏差\nmu2 &lt;- 1.5 # 対立仮説の平均\nsd2 &lt;- 1   # 対立仮説の標準偏差\nalpha = 0.025\n\n# サンプルデータを生成\nx &lt;- seq(-5, 5, by = 0.01)\ndf &lt;- data.frame(x = x,\n                 dnorm1 = dnorm_with_mean_sd(x, mean = mu1, sd = sd1),\n                 dnorm2 = dnorm_with_mean_sd(x, mean = mu2, sd = sd2))\n\n# ggplotを使って描画\ng &lt;- ggplot(df, aes(x = x)) +\n  geom_line(aes(y = dnorm1), color = \"blue\") +\n  geom_line(aes(y = dnorm2), color = \"red\")\ng &lt;- g + geom_area(\n  data = subset(df, x &gt; qnorm(1-alpha, mu1, sd1)),\n            aes(y = dnorm1), fill = \"blue\", alpha = 0.2)\ng &lt;- g + geom_area(\n  data = subset(df, x &lt; qnorm(alpha, mu1, sd1)),\n  aes(y = dnorm1), fill = \"blue\", alpha = 0.2)\ng &lt;- g + geom_area(\n  data = subset(df, x &gt; qnorm(alpha, mu1, sd1) & x &lt; qnorm(1-alpha, mu1, sd1)),\n            aes(y = dnorm2), fill = \"red\", alpha = 0.2) +\n  theme_minimal() +\n  labs(x = \"Value\", y = \"Density\",\n       title = \"両側検定における第1種の過誤と第2種の過誤\")\ng &lt;- g + geom_vline(xintercept = qnorm(1-alpha), linetype=\"dotted\")\ng &lt;- g + geom_vline(xintercept = mu1, color = \"darkblue\")\ng &lt;- g + geom_vline(xintercept = mu2, color = \"darkred\")\n\ng &lt;- g + annotate(\"text\", x = mu1 + 2.5, y = max(df$dnorm1) / 6,\n           label = \"第1種の過誤\", color = \"darkblue\", family = \"HiraKakuProN-W3\") +\n  annotate(\"text\", x = mu2 - 0.5, y = max(df$dnorm2) / 6,\n           label = \"第2種の過誤\", color = \"darkred\", family = \"HiraKakuProN-W3\")\n\ng &lt;- g + annotate(\"text\", x = mu1 - 2, y = max(df$dnorm1)-0.1,\n                  label = \"帰無仮説下の分布\", color = \"blue\", family = \"HiraKakuProN-W3\" ) +\n  annotate(\"text\", x = mu2 + 1.5, y = max(df$dnorm2) - 0.1,\n           label = \"真の分布\", color = \"red\", family = \"HiraKakuProN-W3\") + mystyle\nprint(g)\n\n\n\n\n帰無仮説が正しいときに帰無仮説を棄却する確率である第1種の過誤\\alphaを小さくすると，こうなります。\n\n\n\n\n\n片側検定の場合なら，こんな感じです。"
  },
  {
    "objectID": "Empoli_Chap15.html#ロジスティック回帰分析の手順",
    "href": "Empoli_Chap15.html#ロジスティック回帰分析の手順",
    "title": "14  ロジスティック回帰分析",
    "section": "14.2 ロジスティック回帰分析の手順",
    "text": "14.2 ロジスティック回帰分析の手順\n回帰分析とほぼ同じ手順です。 実際にRでロジスティック回帰分析を行う場合は，lm()関数ではなくglm()関数を使うだけで，ほぼ同じように分析できます。"
  },
  {
    "objectID": "Empoli_Chap01.html#他の経営学領域",
    "href": "Empoli_Chap01.html#他の経営学領域",
    "title": "1  計量会計学？",
    "section": "1.3 他の経営学領域",
    "text": "1.3 他の経営学領域\n誤解を恐れずに、会計学者の松浦が他の経営学領域について、ざっくりと説明してみます。 立命館大学経営学部経営学科には、\n\n会計・ファイナンスコース\n戦略コース\n組織コース\nマーケティングコース\n\nの4コースがあります。これをもとに、経営学領域をざっくりと分類してみます。\n\n1.3.1 会計・ファイナンスコース\n会計学を大きく2つに分類すると、\n\n財務会計\n管理会計\n\nに分かれます。これは企業外への情報提供を目的しているのか、それとも会社内部の経営管理を目的としているのか、によって分類しています。 情報提供を主目的とする財務会計は、制度会計とも呼ばれ、会社が共通して利用する会計基準に従って情報生産をする会計システムを研究対象としています。 これに対し、経営管理を主目的とする管理会計は、会社ごとに独自の会計システムを構築し、会社の経営管理に役立てることを目的としています。 したがって、財務会計情報は公表されているものが多く、代表的な情報源として有価証券報告書がありますが、管理会計情報は非公開のものが多く、データが入手困難です。\n\n\n1.3.2 戦略コース\n戦略コースは、企業や経営者が選択できる行動のメニューについて考えることを目的としています。\n\n\n1.3.3 組織コース\n組織コースは、組織を研究対象とするコースで、大きくマクロ組織論とミクロ組織論に分かれます。 マクロ組織論では、組織の構造や組織の環境との関係を研究対象とする一方で、ミクロ組織論では、組織内の個人の行動や組織内の人間関係を研究対象とします。とりわけミクロ組織論では、組織内の人に焦点を当てた研究を行うため、アンケート調査や実験による検証が多く、心理学に基づく定量的な研究も多く行われています。\n\n\n1.3.4 マーケティング・コース\nマーケティングコースでは、企業が顧客に提供する商品やサービスについて研究するマーケティング研究と、その商品やサービスを消費する顧客に焦点を当てた消費者行動論に分かれます。 とりわけ消費者行動論では、心理学に基づく定量的な研究が多く行われています。また実証産業組織論という経済学の一分野でも消費者行動研究は行われています。あるいはマーケティング・サイエンスという統計学の一分野としても消費者行動研究は行われています。"
  },
  {
    "objectID": "index.html#補足-3.",
    "href": "index.html#補足-3.",
    "title": "プレゼミ",
    "section": "補足 3.",
    "text": "補足 3.\n以下の説明は、インターネットに接続しなくてもRが使えるようにしたいかどうか、で2パターンに分かれます。\n\nパターン1：自分のPCにRなどをインストールする人向け\nパターン2：ブラウザ上でRを使う人向け\n\n\nパターン1：自分のPCにRなどをインストールする人向け\n\nRとRstudio\nプレゼミが始まる前に、RとRstduioを自分PCにインストールしてください。 以下のウェブサイトが超参考になります。 自分のPCのOS(だいたいWindowsかMacOSか)に応じて、次の矢内先生の資料を見ながらインストールしてください。\n矢内先生のウェブサイト\n\n\nVisual Studio Codeの使い方\nPosit Cloudを使わずに、自分のPCでRを使うことを選択した人は、以下の作業に進みますが、まずは矢内先生のウェブサイトなどを参考に、RとRstudioをインストールはインストールしておいてください。\n教科書では、Posit社のRstudioの説明をしていますが、RstudioはR専用のIDE（統合開発環境）で、R以外の言語を書くことはできませんし、少々重たいです。 そこでここでは、Microsoft社のVisual Studio Codeを使ってRを書く方法を説明します。\nマイクロソフト社のウェブサイトから、自分のPCのOSに合わせて、Visual Studio Codeをインストールしてください。\nまずGoogle等で「Visual Studio Code」と検索して、オフィシャルサイトにアクセスします。\n\n\n\nVisual Studio Codeのオフィシャルサイト\n\n\nそして、「Visual Studio Codeをダウンロードする」をクリックすると、次のページにいきます。\n\n\n\nVisual Studio Codeのダウンロードページ\n\n\nここから自分に合ったOSを選んで、ダウンロードしてください。 詳しい人なら、下の小さな項目から、適切なものをえらんでください。 MacBookでM2チップを使っている人は、MacのApple siliconのzipをダウンロードして、Zipファイルを展開してインストールしてください。\n\n\nQuarto\n次に、RstudioやVisual Studio Codeで、レポートや論文を書くためのパッケージであるQuartoをインストールします。 QuartoはRstudioを作ったPosit社が開発している文書作成システムなので、Rとの相性もばっちりです。\nまずGoogle等で「Quarto」と検索して、オフィシャルサイトにアクセスします。\n\n\n\nQuartoのオフィシャルサイト\n\n\nそして、「Get Started」をクリックすると、次のページにいきます。\n\n\n\nQuartoのダウンロードページ\n\n\nここから自分に合ったOSを選んで、ダウンロードしてください。\nここまでで、\n\nR (本体)\nRstudio (R用IDE)\nVisual Studio Code (R以外の言語も書けるIDE)\nQuarto (レポートや論文を書くためのパッケージ)\n\nのインストールが完了しました。 次に、Visual Studio CodeでRのソースコードを書くための準備をします。\n\n\n\nVS Codeの準備\nVisual Studio Code(以下、VS Code)の準備をします。 VS Codeを開くと、次のような画面が表示されます。 VS Codeは、機能を拡張するために、拡張パッケージをインストールすることができます。 VS Codeを起動して、左のメニューの中の、四角が4つ並んだアイコンをクリックしてください。\n\n\n\nVS Codeの初期画面\n\n\nVS Codeの左のメニュー上部に拡張パッケージの検索画面が表示されます。 そこに拡張パッケージの名前を入れて、必要なものをインストールしていきます。 以下の拡張パッケージは、Rの分析をするために必要あるいは推奨されるものです。\n\nJapanese Language Pack for Visual Studio Code : VS Codeの日本語化\nR : とりあえず入れておく\nQuarto : Quartoを使うために必要\n\nとりあえずこの3つを入れておけば、このプレゼミでは十分です。\n\n\n\nVS Codeの拡張パッケージ\n\n\n\n\nフォルダを開く\nVS Codeでは、分析に使うCSVファイルや、分析のためのRファイル、レポートや論文を書くためのQuartoファイルを、一つのフォルダにまとめておくと便利です。 分かりやすい場所にフォルダを作成し、好きな名前をつけてください。\nVS Codeの上部メニューの中の「ファイル」をクリックして、「フォルダーを開く」をクリックして、先ほど作成したフォルダを選択してください。 すると、左のメニューにフォルダの中身が表示されます。まだ何も入っていなければ、何も表示されません。\nVS Codeではフォルダを指定して開いておくと、そこが作業フォルダとなり、Rは常にそのフォルダの中を参照するようになります。"
  },
  {
    "objectID": "index.html#パターン2ブラウザ上でrを使う人向け",
    "href": "index.html#パターン2ブラウザ上でrを使う人向け",
    "title": "プレゼミ",
    "section": "パターン2：ブラウザ上でRを使う人向け",
    "text": "パターン2：ブラウザ上でRを使う人向け\n自分のPCにいろいろインストールしなくてもR/Rstudioをブラウザで利用することもできます。 Posit Cloudを使ってウェブ上でRstudioを使えるようにしてください。 Posit Cloudは、Rstudioを作ったPosit社が運営している無料のサービスです。安心してアカウントを作成してください。\nPosit Cloud\nアカウントを作成し、ログインすれば、Rstudioをブラウザ上で使うことができます。"
  },
  {
    "objectID": "index.html#プレゼミでの使用ソフトウェアについて",
    "href": "index.html#プレゼミでの使用ソフトウェアについて",
    "title": "Rによる計量政治学ノート",
    "section": "プレゼミでの使用ソフトウェアについて",
    "text": "プレゼミでの使用ソフトウェアについて\nこのウェブ資料は、Posit社(以前はRstudio社)が開発したQuartoというソフトウェアを使って作成されています。Quartoとは、RMarkdownの記法で書かれたテキストファイルを、knitrというソフトウェアを介して、HTMLやPDF、MS Word、EPUBなどのファイルを作成するためのソフトウェアです。\n最大の特徴は、MS ExcelとMS Wordのようにデータを分析する場所と文章を書く場所が別々ではなく、一つの画面の中でデータ分析とレポート・論文執筆を同時に行える、というものです。\nまた、Rだけでなく、PythonやJuliaといった他のプログラミング言語も文章内に埋め込むことができるため、データ分析と文章執筆を統合させる環境として非常に優れています。\nプレゼミでも、Quartoを使って最終レポートの作成を行う予定です。 Quartoは今も開発が進んでいる新しいレポート作成ソフトウェアなので、情報が少ないことが難点ですが、公式サイトと私たちのRを見れば大抵のことは分かります。"
  },
  {
    "objectID": "index.html#事前準備",
    "href": "index.html#事前準備",
    "title": "プレゼミ",
    "section": "事前準備",
    "text": "事前準備\nプレゼミが始まるまでに準備しておいてほしいことは、プログラミング言語Rのセットアップです。 具体的には、RとRstudioが使えるようにしておくことが必要です。\nRとRstudioを使う方法は2つあります。\n\nパターン1：自分のPCにRなどをインストールする\nパターン2：ブラウザ上でR/Rstudioを使う\n\n\nパターン1：自分のPCにRなどをインストールする人向け\n自分のPCにRをセットアップするメリットには、\n\nインターネットに接続していなくてもRを使える\n処理速度が速い\nデータの保存場所が自分のPCになるので、データの管理がしやすい\n\nといったものがあります。逆にデメリットとして、\n\nインストールに時間と手間がかかる\n自分のPCにインストールするので、PCの容量を圧迫する\nディレクトリの管理が必要になる\n\nといったものがあります。 ただ、今後もRを使っていくことを考えると、自分のPCにRをインストールしておくことをおすすめしますが、やはり学生が持っているコンピュータの環境が様々なので、トラブルも起こりやすいです。 ただ、以下の手順に従ってインストールすれば、大抵の場合は問題なくインストールできると思います。\n\nRとRstudio\nRとRstduioを自分PCにインストールする際に、以下のウェブサイトが超参考になります。 自分のPCのOS(だいたいWindowsかMacOSか)に応じて、次の矢内先生の資料を見ながらインストールしてください。\n矢内先生のウェブサイト\n\n\nVisual Studio Codeの使い方\n教科書では、Rstudioの説明をしていますが、RstudioはR専用のIDE（統合開発環境）で、R以外の言語を書くことはできませんし、少々重たいです。 そこでここでは、Microsoft社のVisual Studio Codeを使ってRを書く方法を説明します。これは完全に趣味の世界なので、興味が無ければRstudioを使ってください。\nマイクロソフト社のウェブサイトから、自分のPCのOSに合わせて、Visual Studio Codeをインストールしてください。\nまずGoogle等で「Visual Studio Code」と検索して、オフィシャルサイトにアクセスします。\n\n\n\nVisual Studio Codeのオフィシャルサイト\n\n\nそして、「Visual Studio Codeをダウンロードする」をクリックすると、次のページにいきます。\n\n\n\nVisual Studio Codeのダウンロードページ\n\n\nここから自分に合ったOSを選んで、ダウンロードしてください。 詳しい人なら、下の小さな項目から、適切なものをえらんでください。 MacBookでM2チップを使っている人は、MacのApple siliconのzipをダウンロードして、Zipファイルを展開してインストールしてください。\n\n\nQuarto\n次に、RstudioやVisual Studio Codeで、レポートや論文を書くためのパッケージであるQuartoをインストールします。 QuartoはRstudioを作ったPosit社が開発している文書作成システムなので、Rとの相性もばっちりです。\nまずGoogle等で「Quarto」と検索して、オフィシャルサイトにアクセスします。\n\n\n\nQuartoのオフィシャルサイト\n\n\nそして、「Get Started」をクリックすると、次のページにいきます。\n\n\n\nQuartoのダウンロードページ\n\n\nここから自分に合ったOSを選んで、ダウンロードしてください。 インストールが完了すれば、RstudioやVisual Studio Codeで、レポートや論文を書くことができるようになります。\nここまでで、\n\nR (本体)\nRstudio (R用IDE)\nVisual Studio Code (R以外の言語も書けるIDE)\nQuarto (レポートや論文を書くためのパッケージ)\n\nのインストールが完了しました。\n\n\nVS Codeの準備\n次に、Visual Studio Code(以下、VS Code)でRのソースコードを書くための準備をします。 VS Codeを開くと、次のような画面が表示されます。 VS Codeは、機能を拡張するために、拡張パッケージをインストールすることができます。 VS Codeを起動して、左のメニューの中の、四角が4つ並んだアイコンをクリックしてください。\n\n\n\nVS Codeの初期画面\n\n\nVS Codeの左のメニュー上部に拡張パッケージの検索画面が表示されます。 そこに拡張パッケージの名前を入れて、必要なものをインストールしていきます。 以下の拡張パッケージは、Rの分析をするために必要あるいは推奨されるものです。\n\nJapanese Language Pack for Visual Studio Code : VS Codeの日本語化\nR : とりあえず入れておく\nQuarto : Quartoを使うために必要\n\nとりあえずこの3つを入れておけば、このプレゼミでは十分です。\n\n\n\nVS Codeの拡張パッケージ\n\n\n\n\nフォルダを開く\nVS Codeでは、分析に使うCSVファイルや、分析のためのRファイル、レポートや論文を書くためのQuartoファイルを、一つのフォルダにまとめておくと便利です。 分かりやすい場所にフォルダを作成し、好きな名前をつけてください。\nVS Codeの上部メニューの中の「ファイル」をクリックして、「フォルダーを開く」をクリックして、先ほど作成したフォルダを選択してください。 すると、左のメニューにフォルダの中身が表示されます。まだ何も入っていなければ、何も表示されません。\nVS Codeではフォルダを指定して開いておくと、そこが作業フォルダとなり、Rは常にそのフォルダの中を参照するようになります。\n\n\n\nパターン2：ブラウザ上でRを使う人向け\n自分のPCにいろいろインストールしなくてもR/Rstudioをブラウザで利用することもできます。 Posit Cloudを使ってウェブ上でRstudioを使えるようにしてください。 Posit Cloudは、Rstudioを作ったPosit社が運営している無料のサービスです。安心してアカウントを作成してください。\nPosit Cloud\nアカウントを作成し、ログインすれば、Rstudioをブラウザ上で使うことができます。"
  },
  {
    "objectID": "index.html#教科書参考書について",
    "href": "index.html#教科書参考書について",
    "title": "Rによる計量政治学ノート",
    "section": "教科書・参考書について",
    "text": "教科書・参考書について\nプレゼミのメインテキストは浅野・矢内 (2020)「Rによる計量政治学」オーム社です。 このウェブ資料も、このテキストをベースに作成されています。 サブテキストであるウィラワン・勝又 (2023)「Rによるマーケティング・データ分析」新世社、の一部の内容も含まれています。 重要参考図書として、久保克行 (2021)「経営学のための統計学・データ分析」東洋経済、もオススメです。 この資料は基本的に松浦が自分の勉強用に作成したノートのため、誤りや不備が含まれている可能性が高いです。ミスなどを見つけ次第、松浦まで報告してくれると助かります。 またこのノートは、浅野・矢内 (2020)やウィラワン・勝又 (2023)の内容を網羅しているわけではないので、このノートを使う場合は教科書を手元において、学習することをおすすめします。"
  },
  {
    "objectID": "index.html#教科書選定の理由-.unnumbered",
    "href": "index.html#教科書選定の理由-.unnumbered",
    "title": "プレゼミ",
    "section": "教科書選定の理由 *{.unnumbered}",
    "text": "教科書選定の理由 *{.unnumbered}\nなぜ会計学を専門とする松浦のプレゼミで、メインの教科書が「Rによる計量政治学」なのかというと、このテキストが社会科学の一分野である政治学という経営学部生にとっても関連のある興味深い題材を用いて、計量経済学の基礎から応用までをRで実装するための知識を習得できるものだからです。 とりわけ第1部の第2章「研究テーマの選び方」と第3章「理論と仮説」は、卒業論文を書く際にも非常に重要となる内容ですので、全経営学部生によんでもらいたい内容です。\n第4章「Rの使い方」と第5章「Rによるデータ操作」は、本書の学習に必要な必要最小限の内容ですので、他の教科書やウェブサイトを参考にして、より詳細な内容を学習したほうが良いですが、この内容を理解し、使えるようになれば、MS Excelを使わずにRだけで分析できるようになるでしょう。\n第6章から第15章までが、統計学から計量経済学の内容となります。 おおよそ、代表的な統計量の計算や、グラフを使ったデータの理解、標本(sample)を用いた母集団(population)の推定や仮説検定、複数の統計量の関係性の理解、因果関係を分析する手法の1つである回帰分析の基礎と応用、2値選択の問題を推定するためのロジスティック関数の使い方などを学習します。\nここまでの内容の学習にプレゼミ15回のうち、第2回目から第11回目のおおよそ10回分を使います。 12回〜14回の3回は多変量解析手法として因子分析やクラスター分析、機械学習を用いた判別モデルとして決定木分析を学習します。 最後の講義となる第15回目では、今まで修得した知識を使って、データ分析を行った結果を発表してもらいます。\n2年生終了時点で、これらの内容を修得していれば、卒業論文の分析に必要な知識はほぼ習得できていると考えて良いでしょう。あとは関心のある研究テーマを選ぶために、面白そうな専門演習(ゼミ)に入って、Rと統計学・計量経済学を使った実証研究を楽しんでくれれば、プレゼミの目標が達成されます。"
  },
  {
    "objectID": "index.html#プレゼミの運営方法について",
    "href": "index.html#プレゼミの運営方法について",
    "title": "Rによる計量政治学ノート",
    "section": "プレゼミの運営方法について",
    "text": "プレゼミの運営方法について\n最初に触れたように、基本的にこのプレゼミは反転授業の形式をとります。 つまり、授業は家で受けて、宿題を大学でやる、という形式です。\n具体的には、講義を受ける前に自宅で行う準備として、このウェブサイトと教科書・参考書の該当箇所を読んでおきます。そこで「ここは分かったけど、ここは分からなかった」というところをメモしておきます。 「分からなかった」という点について、具体的にどこが分からなかったのかを明確にすることが重要です。\nその上で、大学にでは、分からなかったところを全員で共有し、分からなかった論点を潰していきます。 そのうえで宿題をやります。授業中に与えられるデータを使って、具体的に分析をやってみて、その結果を講義で発表してもらいます。 宿題の内容は、講義中に指示します。"
  },
  {
    "objectID": "index.html#教科書選定の理由",
    "href": "index.html#教科書選定の理由",
    "title": "Rによる計量政治学ノート",
    "section": "教科書選定の理由",
    "text": "教科書選定の理由\nなぜ会計学を専門とする松浦のプレゼミで、メインの教科書が「Rによる計量政治学」なのかというと、このテキストが社会科学の一分野である政治学という経営学部生にとっても関連のある興味深い題材を用いて、計量経済学の基礎から応用までをRで実装するための知識を習得できるものだからです。 とりわけ第1部の第2章「研究テーマの選び方」と第3章「理論と仮説」は、卒業論文を書く際にも非常に重要となる内容ですので、全経営学部生によんでもらいたい内容です。\n第4章「Rの使い方」と第5章「Rによるデータ操作」は、本書の学習に必要な必要最小限の内容ですので、他の教科書やウェブサイトを参考にして、より詳細な内容を学習したほうが良いですが、この内容を理解し、使えるようになれば、MS Excelを使わずにRだけで分析できるようになるでしょう。\n第6章から第15章までが、統計学から計量経済学の内容となります。 おおよそ、代表的な統計量の計算や、グラフを使ったデータの理解、標本(sample)を用いた母集団(population)の推定や仮説検定、複数の統計量の関係性の理解、因果関係を分析する手法の1つである回帰分析の基礎と応用、2値選択の問題を推定するためのロジスティック関数の使い方などを学習します。\nここまでの内容の学習にプレゼミ15回のうち、第2回目から第11回目のおおよそ10回分を使います。 12回〜14回の3回は多変量解析手法として因子分析やクラスター分析、機械学習を用いた判別モデルとして決定木分析を学習します。 最後の講義となる第15回目では、今まで修得した知識を使って、データ分析を行った結果を発表してもらいます。\n2年生終了時点で、これらの内容を修得していれば、卒業論文の分析に必要な知識はほぼ習得できていると考えて良いでしょう。あとは関心のある研究テーマを選ぶために、面白そうな専門演習(ゼミ)に入って、Rと統計学・計量経済学を使った実証研究を楽しんでくれれば、プレゼミの目標が達成されます。"
  },
  {
    "objectID": "index.html#事前課題",
    "href": "index.html#事前課題",
    "title": "Rによる計量政治学ノート",
    "section": "事前課題",
    "text": "事前課題\n\nR/Rstudioをインストールする、あるいはPosit Cloudにアカウントを作成してログインする\n教科書「Rによる計量政治学」を入手しておく\nできれば参考書「経営学のための統計学・データ分析」も入手しておく"
  },
  {
    "objectID": "index.html#プレゼミの準備",
    "href": "index.html#プレゼミの準備",
    "title": "Rによる計量政治学ノート",
    "section": "プレゼミの準備",
    "text": "プレゼミの準備\nプレゼミが始まるまでに準備しておいてほしいことは、プログラミング言語Rのセットアップです。 具体的には、RとRstudioが使えるようにしておくことが必要です。\nRとRstudioを使う方法は2つあります。\n\nパターン1：自分のPCにRなどをインストールする\nパターン2：ブラウザ上でR/Rstudioを使う\n\n\nパターン1：自分のPCにRなどをインストールする人向け\n自分のPCにRをセットアップするメリットには、\n\nインターネットに接続していなくてもRを使える\n処理速度が速い\nデータの保存場所が自分のPCになるので、データの管理がしやすい\n\nといったものがあります。逆にデメリットとして、\n\nインストールに時間と手間がかかる\n自分のPCにインストールするので、PCの容量を圧迫する\nディレクトリの管理が必要になる\n\nといったものがあります。 ただ、今後もRを使っていくことを考えると、自分のPCにRをインストールしておくことをおすすめしますが、やはり学生が持っているコンピュータの環境が様々なので、トラブルも起こりやすいです。 ただ、以下の手順に従ってインストールすれば、大抵の場合は問題なくインストールできると思います。\n\nRとRstudio\nRとRstduioを自分PCにインストールする際に、以下のウェブサイトが超参考になります。 自分のPCのOS(だいたいWindowsかMacOSか)に応じて、次の矢内先生の資料を見ながらインストールしてください。\n矢内先生のウェブサイト\n\n\nVisual Studio Codeの使い方\n教科書では、Rstudioの説明をしていますが、RstudioはR専用のIDE（統合開発環境）で、R以外の言語を書くことはできませんし、少々重たいです。 そこでここでは、Microsoft社のVisual Studio Codeを使ってRを書く方法を説明します。これは完全に趣味の世界なので、興味が無ければRstudioを使ってください。\nマイクロソフト社のウェブサイトから、自分のPCのOSに合わせて、Visual Studio Codeをインストールしてください。\nまずGoogle等で「Visual Studio Code」と検索して、オフィシャルサイトにアクセスします。\n\n\n\nVisual Studio Codeのオフィシャルサイト\n\n\nそして、「Visual Studio Codeをダウンロードする」をクリックすると、次のページにいきます。\n\n\n\nVisual Studio Codeのダウンロードページ\n\n\nここから自分に合ったOSを選んで、ダウンロードしてください。 詳しい人なら、下の小さな項目から、適切なものをえらんでください。 MacBookでM2チップを使っている人は、MacのApple siliconのzipをダウンロードして、Zipファイルを展開してインストールしてください。\n\n\nQuarto\n次に、RstudioやVisual Studio Codeで、レポートや論文を書くためのパッケージであるQuartoをインストールします。 QuartoはRstudioを作ったPosit社が開発している文書作成システムなので、Rとの相性もばっちりです。\nまずGoogle等で「Quarto」と検索して、オフィシャルサイトにアクセスします。\n\n\n\nQuartoのオフィシャルサイト\n\n\nそして、「Get Started」をクリックすると、次のページにいきます。\n\n\n\nQuartoのダウンロードページ\n\n\nここから自分に合ったOSを選んで、ダウンロードしてください。 インストールが完了すれば、RstudioやVisual Studio Codeで、レポートや論文を書くことができるようになります。\nここまでで、\n\nR (本体)\nRstudio (R用IDE)\nVisual Studio Code (R以外の言語も書けるIDE)\nQuarto (レポートや論文を書くためのパッケージ)\n\nのインストールが完了しました。\n\n\nVS Codeの準備\n次に、Visual Studio Code(以下、VS Code)でRのソースコードを書くための準備をします。 VS Codeを開くと、次のような画面が表示されます。 VS Codeは、機能を拡張するために、拡張パッケージをインストールすることができます。 VS Codeを起動して、左のメニューの中の、四角が4つ並んだアイコンをクリックしてください。\n\n\n\nVS Codeの初期画面\n\n\nVS Codeの左のメニュー上部に拡張パッケージの検索画面が表示されます。 そこに拡張パッケージの名前を入れて、必要なものをインストールしていきます。 以下の拡張パッケージは、Rの分析をするために必要あるいは推奨されるものです。\n\nJapanese Language Pack for Visual Studio Code : VS Codeの日本語化\nR : とりあえず入れておく\nQuarto : Quartoを使うために必要\n\nとりあえずこの3つを入れておけば、このプレゼミでは十分です。\n\n\n\nVS Codeの拡張パッケージ\n\n\n\n\nフォルダを開く\nVS Codeでは、分析に使うCSVファイルや、分析のためのRファイル、レポートや論文を書くためのQuartoファイルを、一つのフォルダにまとめておくと便利です。 分かりやすい場所にフォルダを作成し、好きな名前をつけてください。\nVS Codeの上部メニューの中の「ファイル」をクリックして、「フォルダーを開く」をクリックして、先ほど作成したフォルダを選択してください。 すると、左のメニューにフォルダの中身が表示されます。まだ何も入っていなければ、何も表示されません。\nVS Codeではフォルダを指定して開いておくと、そこが作業フォルダとなり、Rは常にそのフォルダの中を参照するようになります。\n\n\n\nパターン2：ブラウザ上でRを使う人向け\n自分のPCにいろいろインストールしなくてもR/Rstudioをブラウザで利用することもできます。 Posit Cloudを使ってウェブ上でRstudioを使えるようにしてください。 Posit Cloudは、Rstudioを作ったPosit社が運営している無料のサービスです。安心してアカウントを作成してください。\nPosit Cloud\nアカウントを作成し、ログインすれば、Rstudioをブラウザ上で使うことができます。"
  },
  {
    "objectID": "Empoli_Chap01.html#学術雑誌",
    "href": "Empoli_Chap01.html#学術雑誌",
    "title": "1  計量会計学？",
    "section": "1.4 学術雑誌",
    "text": "1.4 学術雑誌\n学術研究が掲載された研究雑誌(これをジャーナルといいます)は数多くありますが、そのうち査読(referree)制度を採用しているものを査読付き学術雑誌(referreed journal)といいます。 この査読付き学術雑誌に論文を掲載させるには、査読委員による査読を通過する必要があります。この査読システムにより、研究者の研究成果の質を保証するとともに、研究者の研究成果を評価する指標としても機能しています。\n国際的に評価の高い研究雑誌に掲載された論文は、掲載率数％という非常に厳しい査読を通過した高品質な経営学研究であり、最先端の社会科学の知識が詰まったものといえます。英語で書かれていますが、ChatGPTとかDeepLを駆使して、ぜひ読んでみてください。\n会計研究だと、先ほど紹介した\n\nThe Accounting Review (TAR)\nJournal of Accounting and Economics (JAE)\nJournal of Accounting Research (JAR)\nReview of Accounting Studies (RAST)\nContemporary Accounting Research (CAR)\n\nが五大誌ですが、それ以外にも読むべき雑誌として、\n\nEuropean Accounting Review (EAR)\nJournal of Accounting and Public Policy (JAPP)\nJournal of Accounting, Auditing and Finance (JAAF)\nAccounting Horizons (AH)\nJournal of Business, Finance and Accounting (JBFA)\nJournal of American Taxation Association (JATA)\nJournal of Management Accounting Research (JMAR)\nManagement Accounting Research (MAR)\n\nなどがあります。 ファイナンス研究だと、\n\nJournal of Finance (JF)\nJournal of Financial Economics (JFE)\nReview of Financial Studies (RFS)\nJournal of Corporate Finance (JCF)\nJournal of Banking and Finance (JBF)\n\nあたりでしょうか。 マーケティング研究だと、\n\nJournal of Marketing (JM)\nJournal of Marketing Research (JMR)\nJournal of Consumer Research (JCR)\nMarketing Science (MS)\n\n組織・戦略研究だと、\n\nAcademy of Management Journal (AMJ)\nAcademy of Management Review (AMR)\nAdministrative Science Quarterly (ASQ)\nOrganization Science (OS)\nManagement Science (MS)\nStrategic Management Journal (SMJ)\n\nがあります。 これらの各領域におけるトップジャーナルを見てみると、多くの実証研究が行われていることが分かります。\n日本の査読付き学術雑誌には、(松浦が知っている限りでは)、以下のようなものがあります。\n会計学\n\n会計プログレス\n現代ディスクロージャー研究\n管理会計学\n原価計算研究\n\nファイナンス\n\n現代ファイナンス\n経営財務研究\n\nマーケティング\n\n流通研究\nマーケティング・ジャーナル\n\n組織・戦略\n\n組織科学\n経営行動科学\n日本経営学会誌"
  },
  {
    "objectID": "Empoli_Chap01.html#sec_01",
    "href": "Empoli_Chap01.html#sec_01",
    "title": "1  計量会計学？",
    "section": "1.1 会計を計量する？",
    "text": "1.1 会計を計量する？\nここでは、教科書「Rによる計量政治学」の内容を「会計学」に置き換えて考えてみます。 「計量会計学」という言葉は一般的ではなく、会計学の世界では「実証的会計研究」とか「実証会計学」いう言葉が使われています。\n社会科学において、社会で生じる様々な現象（たとえば、経営現象や会計実務）を、数値化して分析することを計量化(quantification)と呼びます。 計量化されたデータを用いて、社会現象を説明しようとするアプローチを計量分析(quantitative analysis)と呼びます。 計量分析の手法は、統計学や計量経済学などの数理的な手法を用いて、社会現象を説明しようとするものです。\n会計とは経営活動から生み出される価値の変化を貨幣的に計測・記録し、その情報を整理し、集約することで、最終成果物として報告書(たとえば貸借対照表など)を作成し、それを利害関係者に報告することで、投資意思決定に役立つ情報を提供したり、利害関係者間の利害調整を行うことを目的とした一連のプロセスを意味します。 つまり会計そのものが、経営現象を計量化することを目的としているため、その最終成果物である財務諸表は、経営現象を計量化したデータの集合体と言えます。 この会計という経営実務を研究対象とした学問を会計学(accounting)といいます。"
  },
  {
    "objectID": "Empoli_Chap01.html#sec_02",
    "href": "Empoli_Chap01.html#sec_02",
    "title": "1  計量会計学？",
    "section": "1.2 会計学の領域",
    "text": "1.2 会計学の領域\n会計学には様々な研究分野があります。 会計の歴史を研究対象とする会計史(accounting history)、会計の計算構造を研究対象とする計算構造研究(accounting structure)、簿記そのものを研究対象とする簿記論(bookkeeping)、そして、会計の実務を説明し予想するための理論の構築を目指す事実解明的な会計研究(positive accounting research)などがあります。\nとりわけ事実解明的な会計研究のうち、公表された情報を計量分析の手法を用いて分析する会計研究を、実証会計学(archival based empirical accounting)とか、単に実証会計と呼びます。 実証会計以外の事実解明的な研究には、実験により生成されたデータを分析する実験会計研究(experimental accounting)、データを必要とせず、数理モデルを用いて行われる分析会計研究(analytical accounting)などがあります。\n国際的に評価の高い会計学の学術誌である、The Accounting Review(TAR)、Journal of Accounting and Economics(JAE)、Journal of Accounting Research(JAR)、Review of Accounting Studies(RAST)、Contemporary Accounting Research(CAR)の五大誌に掲載されている論文の大部分が、会計情報を用いた計量分析となっています。 ただこの5誌はすべて北米の研究機関や大学が発行している雑誌ですので、実証、実験、分析的な会計研究がメインストリームの扱いとなりますが、ヨーロッパでは、 Accounting, Organisation snd Society(AOS)、European Accounting Research(EAR)、British Accounting Research(BAR)、Critical Accounting Research(CAR)といった、定性的研究も重要視し、経済学ではなく社会学をベースとした研究が主流？となっている雑誌もあります。しかし松浦は社会学について語れる知識がないので、やはり沈黙します。\n会計研究の世界では、1960年頃までは規範的研究(normative research)という「〇〇するべき」という主張をする研究が主流でした。たとえば企業が保有する株式を時価評価すべきかとか、ある特徴をもつリース資産を購入したものとして扱うべきか、といったものです。\nしかし、1968年にJournal of Accounting Researchに掲載されたBall and Brown (1968) An Empirical Evaluation of Accounting Income Numbersを皮切りに、実際に会計情報は投資家の役に立っているのかをデータを使って確かめる、という、いわゆる実証研究が行われるようになり、今日まで会計研究の主要分野となっています。\n実証的会計研究を行うために必要な知識・技術として、\n\n会計基準・会計理論\nミクロ経済学（ゲーム理論、契約理論、情報の経済学）\n計量経済学\nファイナンス理論（コーポレート・ファイナンス）\nプログラミング\n\nが挙げられます。\n同じ事実解明型研究の中でも、証拠では無く論理による主張を目指す分析的会計研究で必要な知識・技術として、\n\n会計基準・会計理論\nミクロ経済学（ゲーム理論、契約理論、情報の経済学）\n最適化理論\n差分方程式\n\nが挙げられます。 そもそも分析的会計研究は、会計現象を抽象化し、数学でその現象を表現するモデルを作り、そのモデルを解くことで得られる均衡解を比較静学することで様々なインプリケーションを得るため、実際に発生していない問題も研究することできる利点があります。 その反面、要求されるモデルを作るセンスや、解けるモデルを構築するための数学レベルも高く、また研究に要する時間も長いため、実証的会計研究に比べて論文が少ないです。 しかし、理論と実証は研究の両輪をなすものであり、どちらも重要であることに違いはないので、完全に理解することはできなくても、目を通す努力は必要でしょう。\nただやはり難しい数式が出てくる会計研究は松浦には完全に理解することはできないので、ここでは実証的会計研究について考えていきます。ヴィトゲンシュタインの言葉を借りれば、語り得ないものは語らないということで、分析的会計研究は沈黙するべきです。"
  },
  {
    "objectID": "Empoli_Chap01.html#sec_03",
    "href": "Empoli_Chap01.html#sec_03",
    "title": "1  計量会計学？",
    "section": "1.3 他の経営学領域",
    "text": "1.3 他の経営学領域\n誤解を恐れずに、会計学者の松浦が他の経営学領域について、ざっくりと説明してみます。 立命館大学経営学部経営学科には、\n\n会計・ファイナンスコース\n戦略コース\n組織コース\nマーケティングコース\n\nの4コースがあります。これをもとに、経営学領域をざっくりと分類してみます。\n\n1.3.1 会計・ファイナンスコース\n会計学を大きく2つに分類すると、\n\n財務会計\n管理会計\n\nに分かれます。これは企業外への情報提供を目的しているのか、それとも会社内部の経営管理を目的としているのか、によって分類しています。 情報提供を主目的とする財務会計は、制度会計とも呼ばれ、会社が共通して利用する会計基準に従って情報生産をする会計システムを研究対象としています。 これに対し、経営管理を主目的とする管理会計は、会社ごとに独自の会計システムを構築し、会社の経営管理に役立てることを目的としています。 したがって、財務会計情報は公表されているものが多く、代表的な情報源として有価証券報告書がありますが、管理会計情報は非公開のものが多く、データが入手困難です。\n\n\n1.3.2 戦略コース\n戦略コースは、企業や経営者が選択できる行動のメニューについて考えることを目的としています。\n\n\n1.3.3 組織コース\n組織コースは、組織を研究対象とするコースで、大きくマクロ組織論とミクロ組織論に分かれます。 マクロ組織論では、組織の構造や組織の環境との関係を研究対象とする一方で、ミクロ組織論では、組織内の個人の行動や組織内の人間関係を研究対象とします。とりわけミクロ組織論では、組織内の人に焦点を当てた研究を行うため、アンケート調査や実験による検証が多く、心理学に基づく定量的な研究も多く行われています。\n\n\n1.3.4 マーケティング・コース\nマーケティングコースでは、企業が顧客に提供する商品やサービスについて研究するマーケティング研究と、その商品やサービスを消費する顧客に焦点を当てた消費者行動論に分かれます。 とりわけ消費者行動論では、心理学に基づく定量的な研究が多く行われています。また実証産業組織論という経済学の一分野でも消費者行動研究は行われています。あるいはマーケティング・サイエンスという統計学の一分野としても消費者行動研究は行われています。"
  },
  {
    "objectID": "Empoli_Chap01.html#sec_04",
    "href": "Empoli_Chap01.html#sec_04",
    "title": "1  計量会計学？",
    "section": "1.4 学術雑誌",
    "text": "1.4 学術雑誌\n学術研究が掲載された研究雑誌(これをジャーナルといいます)は数多くありますが、そのうち査読(referree)制度を採用しているものを査読付き学術雑誌(referreed journal)といいます。 この査読付き学術雑誌に論文を掲載させるには、査読委員による査読を通過する必要があります。この査読システムにより、研究者の研究成果の質を保証するとともに、研究者の研究成果を評価する指標としても機能しています。\n国際的に評価の高い研究雑誌に掲載された論文は、掲載率数％という非常に厳しい査読を通過した高品質な経営学研究であり、最先端の社会科学の知識が詰まったものといえます。英語で書かれていますが、ChatGPTとかDeepLを駆使して、ぜひ読んでみてください。\n会計研究だと、先ほど紹介した\n\nThe Accounting Review (TAR)\nJournal of Accounting and Economics (JAE)\nJournal of Accounting Research (JAR)\nReview of Accounting Studies (RAST)\nContemporary Accounting Research (CAR)\n\nが五大誌ですが、それ以外にも読むべき雑誌として、\n\nEuropean Accounting Review (EAR)\nJournal of Accounting and Public Policy (JAPP)\nJournal of Accounting, Auditing and Finance (JAAF)\nAccounting Horizons (AH)\nJournal of Business, Finance and Accounting (JBFA)\nJournal of American Taxation Association (JATA)\nJournal of Management Accounting Research (JMAR)\nManagement Accounting Research (MAR)\n\nなどがあります。 ファイナンス研究だと、\n\nJournal of Finance (JF)\nJournal of Financial Economics (JFE)\nReview of Financial Studies (RFS)\nJournal of Corporate Finance (JCF)\nJournal of Banking and Finance (JBF)\n\nあたりでしょうか。 マーケティング研究だと、\n\nJournal of Marketing (JM)\nJournal of Marketing Research (JMR)\nJournal of Consumer Research (JCR)\nMarketing Science (MS)\n\n組織・戦略研究だと、\n\nAcademy of Management Journal (AMJ)\nAcademy of Management Review (AMR)\nAdministrative Science Quarterly (ASQ)\nOrganization Science (OS)\nManagement Science (MS)\nStrategic Management Journal (SMJ)\n\nがあります。 これらの各領域におけるトップジャーナルを見てみると、多くの実証研究が行われていることが分かります。\n日本の査読付き学術雑誌には、(松浦が知っている限りでは)、以下のようなものがあります。\n会計学\n\n会計プログレス\n現代ディスクロージャー研究\n管理会計学\n原価計算研究\n\nファイナンス\n\n現代ファイナンス\n経営財務研究\n\nマーケティング\n\n流通研究\nマーケティング・ジャーナル\n\n組織・戦略\n\n組織科学\n経営行動科学\n日本経営学会誌"
  },
  {
    "objectID": "Empoli_Chap01.html#sec-01",
    "href": "Empoli_Chap01.html#sec-01",
    "title": "1  定量研究とは",
    "section": "1.1 会計を計量する？",
    "text": "1.1 会計を計量する？\nここでは、教科書「Rによる計量政治学」の内容を「会計学」に置き換えて考えてみます。 「計量会計学」という言葉は一般的ではなく、会計学の世界では「実証的会計研究」とか「実証会計学」いう言葉が使われています。\n社会科学において、社会で生じる様々な現象（たとえば、経営現象や会計実務）を、数値化して分析することを計量化(quantification)と呼びます。 計量化されたデータを用いて、社会現象を説明しようとするアプローチを計量分析(quantitative analysis)と呼びます。 計量分析の手法は、統計学や計量経済学などの数理的な手法を用いて、社会現象を説明しようとするものです。\n会計とは経営活動から生み出される価値の変化を貨幣的に計測・記録し、その情報を整理し、集約することで、最終成果物として報告書(たとえば貸借対照表など)を作成し、それを利害関係者に報告することで、投資意思決定に役立つ情報を提供したり、利害関係者間の利害調整を行うことを目的とした一連のプロセスを意味します。 つまり会計そのものが、経営現象を計量化することを目的としているため、その最終成果物である財務諸表は、経営現象を計量化したデータの集合体と言えます。 この会計という経営実務を研究対象とした学問を会計学(accounting)といいます。"
  },
  {
    "objectID": "Empoli_Chap01.html#sec-02",
    "href": "Empoli_Chap01.html#sec-02",
    "title": "1  定量研究とは",
    "section": "1.2 会計学の領域",
    "text": "1.2 会計学の領域\n会計学には様々な研究分野があります。 会計の歴史を研究対象とする会計史(accounting history)、会計の計算構造を研究対象とする計算構造研究(accounting structure)、簿記そのものを研究対象とする簿記論(bookkeeping)、そして、会計の実務を説明し予想するための理論の構築を目指す事実解明的な会計研究(positive accounting research)などがあります。\nとりわけ事実解明的な会計研究のうち、公表された情報を計量分析の手法を用いて分析する会計研究を、実証会計学(archival based empirical accounting)とか、単に実証会計と呼びます。 実証会計以外の事実解明的な研究には、実験により生成されたデータを分析する実験会計研究(experimental accounting)、データを必要とせず、数理モデルを用いて行われる分析会計研究(analytical accounting)などがあります。\n国際的に評価の高い会計学の学術誌である、The Accounting Review(TAR)、Journal of Accounting and Economics(JAE)、Journal of Accounting Research(JAR)、Review of Accounting Studies(RAST)、Contemporary Accounting Research(CAR)の五大誌に掲載されている論文の大部分が、会計情報を用いた計量分析となっています。 ただこの5誌はすべて北米の研究機関や大学が発行している雑誌ですので、実証、実験、分析的な会計研究がメインストリームの扱いとなりますが、ヨーロッパでは、 Accounting, Organisation snd Society(AOS)、European Accounting Research(EAR)、British Accounting Research(BAR)、Critical Accounting Research(CAR)といった、定性的研究も重要視し、経済学ではなく社会学をベースとした研究が主流？となっている雑誌もあります。しかし松浦は社会学について語れる知識がないので、やはり沈黙します。\n会計研究の世界では、1960年頃までは規範的研究(normative research)という「〇〇するべき」という主張をする研究が主流でした。たとえば企業が保有する株式を時価評価すべきかとか、ある特徴をもつリース資産を購入したものとして扱うべきか、といったものです。\nしかし、1968年にJournal of Accounting Researchに掲載されたBall and Brown (1968) An Empirical Evaluation of Accounting Income Numbersを皮切りに、実際に会計情報は投資家の役に立っているのかをデータを使って確かめる、という、いわゆる実証研究が行われるようになり、今日まで会計研究の主要分野となっています。\n実証的会計研究を行うために必要な知識・技術として、\n\n会計基準・会計理論\nミクロ経済学（ゲーム理論、契約理論、情報の経済学）\n計量経済学\nファイナンス理論（コーポレート・ファイナンス）\nプログラミング\n\nが挙げられます。\n同じ事実解明型研究の中でも、証拠では無く論理による主張を目指す分析的会計研究で必要な知識・技術として、\n\n会計基準・会計理論\nミクロ経済学（ゲーム理論、契約理論、情報の経済学）\n最適化理論\n差分方程式\n\nが挙げられます。 そもそも分析的会計研究は、会計現象を抽象化し、数学でその現象を表現するモデルを作り、そのモデルを解くことで得られる均衡解を比較静学することで様々なインプリケーションを得るため、実際に発生していない問題も研究することできる利点があります。 その反面、要求されるモデルを作るセンスや、解けるモデルを構築するための数学レベルも高く、また研究に要する時間も長いため、実証的会計研究に比べて論文が少ないです。 しかし、理論と実証は研究の両輪をなすものであり、どちらも重要であることに違いはないので、完全に理解することはできなくても、目を通す努力は必要でしょう。\nただやはり難しい数式が出てくる会計研究は松浦には完全に理解することはできないので、ここでは実証的会計研究について考えていきます。ヴィトゲンシュタインの言葉を借りれば、語り得ないものは語らないということで、分析的会計研究は沈黙するべきです。"
  },
  {
    "objectID": "Empoli_Chap01.html#sec-03",
    "href": "Empoli_Chap01.html#sec-03",
    "title": "1  研究、仮説、実証会計",
    "section": "1.3 他の経営学領域",
    "text": "1.3 他の経営学領域\n誤解を恐れずに、会計学者の松浦が他の経営学領域について、ざっくりと説明してみます。 立命館大学経営学部経営学科には、\n\n会計・ファイナンスコース\n戦略コース\n組織コース\nマーケティングコース\n\nの4コースがあります。これをもとに、経営学領域をざっくりと分類してみます。\n\n1.3.1 会計・ファイナンスコース\n会計学を大きく2つに分類すると、\n\n財務会計\n管理会計\n\nに分かれます。これは企業外への情報提供を目的しているのか、それとも会社内部の経営管理を目的としているのか、によって分類しています。 情報提供を主目的とする財務会計は、制度会計とも呼ばれ、会社が共通して利用する会計基準に従って情報生産をする会計システムを研究対象としています。 これに対し、経営管理を主目的とする管理会計は、会社ごとに独自の会計システムを構築し、会社の経営管理に役立てることを目的としています。 したがって、財務会計情報は公表されているものが多く、代表的な情報源として有価証券報告書がありますが、管理会計情報は非公開のものが多く、データが入手困難です。\n\n\n1.3.2 戦略コース\n戦略コースは、企業や経営者が選択できる行動のメニューについて考えることを目的としています。\n\n\n1.3.3 組織コース\n組織コースは、組織を研究対象とするコースで、大きくマクロ組織論とミクロ組織論に分かれます。 マクロ組織論では、組織の構造や組織の環境との関係を研究対象とする一方で、ミクロ組織論では、組織内の個人の行動や組織内の人間関係を研究対象とします。とりわけミクロ組織論では、組織内の人に焦点を当てた研究を行うため、アンケート調査や実験による検証が多く、心理学に基づく定量的な研究も多く行われています。\n\n\n1.3.4 マーケティング・コース\nマーケティングコースでは、企業が顧客に提供する商品やサービスについて研究するマーケティング研究と、その商品やサービスを消費する顧客に焦点を当てた消費者行動論に分かれます。 とりわけ消費者行動論では、心理学に基づく定量的な研究が多く行われています。また実証産業組織論という経済学の一分野でも消費者行動研究は行われています。あるいはマーケティング・サイエンスという統計学の一分野としても消費者行動研究は行われています。"
  },
  {
    "objectID": "Empoli_Chap01.html#sec-04",
    "href": "Empoli_Chap01.html#sec-04",
    "title": "1  研究、仮説、実証会計",
    "section": "1.4 学術雑誌",
    "text": "1.4 学術雑誌\n学術研究が掲載された研究雑誌(これをジャーナルといいます)は数多くありますが、そのうち査読(referree)制度を採用しているものを査読付き学術雑誌(referreed journal)といいます。 この査読付き学術雑誌に論文を掲載させるには、査読委員による査読を通過する必要があります。この査読システムにより、研究者の研究成果の質を保証するとともに、研究者の研究成果を評価する指標としても機能しています。\n国際的に評価の高い研究雑誌に掲載された論文は、掲載率数％という非常に厳しい査読を通過した高品質な経営学研究であり、最先端の社会科学の知識が詰まったものといえます。英語で書かれていますが、ChatGPTとかDeepLを駆使して、ぜひ読んでみてください。\n会計研究だと、先ほど紹介した\n\nThe Accounting Review (TAR)\nJournal of Accounting and Economics (JAE)\nJournal of Accounting Research (JAR)\nReview of Accounting Studies (RAST)\nContemporary Accounting Research (CAR)\n\nが五大誌ですが、それ以外にも読むべき雑誌として、\n\nEuropean Accounting Review (EAR)\nJournal of Accounting and Public Policy (JAPP)\nJournal of Accounting, Auditing and Finance (JAAF)\nAccounting Horizons (AH)\nJournal of Business, Finance and Accounting (JBFA)\nJournal of American Taxation Association (JATA)\nJournal of Management Accounting Research (JMAR)\nManagement Accounting Research (MAR)\n\nなどがあります。 ファイナンス研究だと、\n\nJournal of Finance (JF)\nJournal of Financial Economics (JFE)\nReview of Financial Studies (RFS)\nJournal of Corporate Finance (JCF)\nJournal of Banking and Finance (JBF)\n\nあたりでしょうか。 マーケティング研究だと、\n\nJournal of Marketing (JM)\nJournal of Marketing Research (JMR)\nJournal of Consumer Research (JCR)\nMarketing Science (MS)\n\n組織・戦略研究だと、\n\nAcademy of Management Journal (AMJ)\nAcademy of Management Review (AMR)\nAdministrative Science Quarterly (ASQ)\nOrganization Science (OS)\nManagement Science (MS)\nStrategic Management Journal (SMJ)\n\nがあります。 これらの各領域におけるトップジャーナルを見てみると、多くの実証研究が行われていることが分かります。\n日本の査読付き学術雑誌には、(松浦が知っている限りでは)、以下のようなものがあります。\n会計学\n\n会計プログレス\n現代ディスクロージャー研究\n管理会計学\n原価計算研究\n\nファイナンス\n\n現代ファイナンス\n経営財務研究\n\nマーケティング\n\n流通研究\nマーケティング・ジャーナル\n\n組織・戦略\n\n組織科学\n経営行動科学\n日本経営学会誌"
  },
  {
    "objectID": "Empoli_Chap01.html#sec-05",
    "href": "Empoli_Chap01.html#sec-05",
    "title": "1  研究、仮説、実証会計",
    "section": "1.5 本日の課題",
    "text": "1.5 本日の課題"
  },
  {
    "objectID": "presemi2023_02.html#sec-01",
    "href": "presemi2023_02.html#sec-01",
    "title": "1  研究、仮説、実証会計",
    "section": "1.1 実証研究・実証会計",
    "text": "1.1 実証研究・実証会計\nここでは、教科書「Rによる計量政治学」の内容を「会計学」に置き換えて考えてみます。 「計量会計学」という言葉は一般的ではなく、会計学の世界では「実証的会計研究」とか「実証会計学」いう言葉が使われています。\n社会科学において、社会で生じる様々な現象（たとえば、経営現象や会計実務）を、数値化して分析することを計量化(quantification)と呼びます。 計量化されたデータを用いて、社会現象を説明しようとするアプローチを計量分析(quantitative analysis)と呼びます。 計量分析の手法は、統計学や計量経済学などの数理的な手法を用いて、社会現象を説明しようとするものです。\n会計とは経営活動から生み出される価値の変化を貨幣的に計測・記録し、その情報を整理し、集約することで、最終成果物として報告書(たとえば貸借対照表など)を作成し、それを利害関係者に報告することで、投資意思決定に役立つ情報を提供したり、利害関係者間の利害調整を行うことを目的とした一連のプロセスを意味します。 つまり会計そのものが、経営現象を計量化することを目的としているため、その最終成果物である財務諸表は、経営現象を計量化したデータの集合体と言えます。 この会計という経営実務を研究対象とした学問を会計学(accounting)といいます。\n\n1.1.1 会計学の領域\n会計学には様々な研究分野があります。 会計の歴史を研究対象とする会計史(accounting history)、会計の計算構造を研究対象とする計算構造研究(accounting structure)、簿記そのものを研究対象とする簿記論(bookkeeping)、そして、会計の実務を説明し予想するための理論の構築を目指す事実解明的な会計研究(positive accounting research)などがあります。\nとりわけ事実解明的な会計研究のうち、公表された情報を計量分析の手法を用いて分析する会計研究を、実証会計学(archival based empirical accounting)とか、単に実証会計と呼びます。 実証会計以外の事実解明的な研究には、実験により生成されたデータを分析する実験会計研究(experimental accounting)、データを必要とせず、数理モデルを用いて行われる分析会計研究(analytical accounting)などがあります。\n国際的に評価の高い会計学の学術誌である、The Accounting Review(TAR)、Journal of Accounting and Economics(JAE)、Journal of Accounting Research(JAR)、Review of Accounting Studies(RAST)、Contemporary Accounting Research(CAR)の五大誌に掲載されている論文の大部分が、会計情報を用いた計量分析となっています。 ただこの5誌はすべて北米の研究機関や大学が発行している雑誌ですので、実証、実験、分析的な会計研究がメインストリームの扱いとなりますが、ヨーロッパでは、 Accounting, Organisation snd Society(AOS)、European Accounting Research(EAR)、British Accounting Research(BAR)、Critical Accounting Research(CAR)といった、定性的研究も重要視し、経済学ではなく社会学をベースとした研究が主流？となっている雑誌もあります。しかし松浦は社会学について語れる知識がないので、やはり沈黙します。\n会計研究の世界では、1960年頃までは規範的研究(normative research)という「〇〇するべき」という主張をする研究が主流でした。たとえば企業が保有する株式を時価評価すべきかとか、ある特徴をもつリース資産を購入したものとして扱うべきか、といったものです。 しかし、1968年にJournal of Accounting Researchに掲載されたBall and Brown (1968) An Empirical Evaluation of Accounting Income Numbersを皮切りに、実際に会計情報は投資家の役に立っているのかをデータを使って確かめる、という、いわゆる実証研究が行われるようになり、今日まで会計研究の主要分野となっています。\n実証的会計研究を行うために必要な知識・技術として、\n\n会計基準・会計理論\nミクロ経済学（ゲーム理論、契約理論、情報の経済学）\n計量経済学\nファイナンス理論（コーポレート・ファイナンス）\nプログラミング\n\nが挙げられます。\n同じ事実解明型研究の中でも、証拠では無く論理による主張を目指す分析的会計研究で必要な知識・技術として、\n\n会計基準・会計理論\nミクロ経済学（ゲーム理論、契約理論、情報の経済学）\n最適化理論\n差分方程式\n\nが挙げられます。 そもそも分析的会計研究は、会計現象を抽象化し、数学でその現象を表現するモデルを作り、そのモデルを解くことで得られる均衡解を比較静学することで様々なインプリケーションを得るため、実際に発生していない問題も研究することできる利点があります。 その反面、要求されるモデルを作るセンスや、解けるモデルを構築するための数学レベルも高く、また研究に要する時間も長いため、実証的会計研究に比べて論文が少ないです。 しかし、理論と実証は研究の両輪をなすものであり、どちらも重要であることに違いはないので、完全に理解することはできなくても、目を通す努力は必要でしょう。\nただやはり難しい数式が出てくる会計研究は松浦には完全に理解することはできないので、ここでは実証的会計研究について考えていきます。ヴィトゲンシュタインの言葉を借りれば、語り得ないものは語らないということで、分析的会計研究は沈黙するべきです。\n\n\n1.1.2 他の経営学領域\n誤解を恐れずに、会計学者の松浦が他の経営学領域について、ざっくりと説明してみます。 立命館大学経営学部経営学科には、\n\n会計・ファイナンスコース\n戦略コース\n組織コース\nマーケティングコース\n\nの4コースがあります。これをもとに、経営学領域をざっくりと分類してみます。\n\n\n1.1.3 会計・ファイナンスコース\n会計学を大きく2つに分類すると、\n\n財務会計\n管理会計\n\nに分かれます。これは企業外への情報提供を目的しているのか、それとも会社内部の経営管理を目的としているのか、によって分類しています。 情報提供を主目的とする財務会計は、制度会計とも呼ばれ、会社が共通して利用する会計基準に従って情報生産をする会計システムを研究対象としています。 これに対し、経営管理を主目的とする管理会計は、会社ごとに独自の会計システムを構築し、会社の経営管理に役立てることを目的としています。 したがって、財務会計情報は公表されているものが多く、代表的な情報源として有価証券報告書がありますが、管理会計情報は非公開のものが多く、データが入手困難です。\nファイナンスを大きく2つに分類すると，\n\nコーポレート・ファイナンス\n投資論\n\nに分けられると思います(たぶん)。 コーポレート・ファイナンスは、企業が資金を調達する際の意思決定を研究対象とし，投資論は投資家が資産を選択する際の意思決定を研究対象とします。\n\n1.1.3.1 戦略コース\n戦略コースは、企業や経営者が選択できる行動のメニューについて考えることを目的としています。 ただ戦略論という研究領域はあるのでしょうが，その分野の先生が主戦場とする学会や学術雑誌が分からないので，うまく説明できません。\n\n\n1.1.3.2 組織コース\n組織コースは、組織を研究対象とするコースです。大きく\n\nマクロ組織論\nミクロ組織論\n\nに分けられます。 マクロ組織論では、組織の構造や組織の環境との関係を研究対象とする一方で、ミクロ組織論では、組織内の個人の行動や組織内の人間関係を研究対象とします。とりわけミクロ組織論では、組織内の人に焦点を当てた研究を行うため、アンケート調査や実験による検証が多く、心理学に基づく定量的な研究も多く行われています。\n\n\n1.1.3.3 マーケティング・コース\nマーケティングは，顧客目線か企業目線かで2つに分けられます。\n\nマーケティング\n消費者行動論\n\n前者が企業が顧客に提供する商品やサービスについて研究する一方で，後者はその商品やサービスを消費する顧客に焦点を当てた研究を行います。 とりわけ，「消費」という現象を研究対象にする学問は多く，マーケティング以外にも，心理学，経済学，統計学といった分野で消費行動を研究しています。 心理学における消費行動論とマーケティングにおける消費行動論は非常に近い関係にあります。 また経済学とりわけ実証産業組織論における消費行動論は，消費をモデル化し，データをシミュレーション等で解析することで，消費行動のメカニズムを解明しようとするものです。 統計学における消費行動研究は「マーケティング・サイエンス」とも呼ばれており，高度な統計学やシミュレーションを用いて消費行動を分析し，消費のパターンを解明しようとするものです。\n\n\n\n1.1.4 学術雑誌\n学術研究が掲載された研究雑誌(これをジャーナルといいます)は数多くありますが、そのうち査読(referree)制度を採用しているものを査読付き学術雑誌(referreed journal)といいます。査読者は匿名で論文の審査を行い，ジャーナルに掲載しても良い論文かどうかを判断し，その結果を査読レポートとして雑誌編集長に報告します。\nこの査読付き学術雑誌に論文を掲載させるには、雑誌編集長の審査を通過し，その後割り当てられた査読委員による査読を突破する必要があります。 投稿された論文のレベルが低い場合，編集長の判断で即リジェクトされます(これをデスク・リジェクトといいます。かなり辛い結果です)。 レベルが一定以上であると編集長が判断した論文だけが査読委員に割り当てられ，2名程度の査読委員が，「そのまま掲載可」，「少し修正すれば掲載可」，「かなり修正すれば掲載可」，「掲載不可」という判断をします。 この査読システムにより、研究者の研究成果の質を保証するとともに、研究者の研究成果を評価する指標としても機能しています。 しかし，この査読の時間が結構長く，投稿してから雑誌に掲載されるまで1年〜3年程度かかることもざらです。\n国際的に評価の高い研究雑誌に掲載された論文は、掲載率数％という非常に厳しい査読を通過した高品質な経営学研究であり、最先端の社会科学の知識が詰まったものといえます。英語で書かれていますが、ChatGPTとかDeepLを駆使して、ぜひ読んでみてください。\n会計研究だと、先ほど紹介した\n\nThe Accounting Review (TAR)\nJournal of Accounting and Economics (JAE)\nJournal of Accounting Research (JAR)\nReview of Accounting Studies (RAST)\nContemporary Accounting Research (CAR)\n\nが五大誌ですが、それ以外にも読むべき雑誌として、\n\nEuropean Accounting Review (EAR)\nJournal of Accounting and Public Policy (JAPP)\nJournal of Accounting, Auditing and Finance (JAAF)\nAccounting Horizons (AH)\nJournal of Business, Finance and Accounting (JBFA)\nJournal of American Taxation Association (JATA)\nJournal of Management Accounting Research (JMAR)\nManagement Accounting Research (MAR)\n\nなどがあります。 ファイナンス研究だと、\n\nJournal of Finance (JF)\nJournal of Financial Economics (JFE)\nReview of Financial Studies (RFS)\nJournal of Corporate Finance (JCF)\nJournal of Banking and Finance (JBF)\n\nあたりでしょうか。 マーケティング研究だと、\n\nJournal of Marketing (JM)\nJournal of Marketing Research (JMR)\nJournal of Consumer Research (JCR)\nMarketing Science (MS)\n\n組織・戦略研究だと、\n\nAcademy of Management Journal (AMJ)\nAcademy of Management Review (AMR)\nAdministrative Science Quarterly (ASQ)\nOrganization Science (OS)\nManagement Science (MS)\nStrategic Management Journal (SMJ)\n\nがあります。 これらの各領域におけるトップジャーナルを見てみると、多くの実証研究が行われていることが分かります。\n日本の査読付き学術雑誌には、(松浦が知っている限りでは)、以下のようなものがあります。\n会計学\n\n会計プログレス\n現代ディスクロージャー研究\n管理会計学\n原価計算研究\n\nファイナンス\n\n現代ファイナンス\n経営財務研究\n\nマーケティング\n\n流通研究\nマーケティング・ジャーナル\n\n組織・戦略\n\n組織科学\n経営行動科学\n日本経営学会誌"
  },
  {
    "objectID": "presemi2023_02.html#研究テーマの選び方",
    "href": "presemi2023_02.html#研究テーマの選び方",
    "title": "1  研究、仮説、実証会計",
    "section": "1.2 研究テーマの選び方",
    "text": "1.2 研究テーマの選び方\nプレゼミの達成目標は、経営事象に関する問題を発見し、その問題がなぜ生じているのか、どうすれば解決できるのかを考えることができるようになることです。 そこで、まずは研究課題の種類について学びます。 問いの立て方には大きく分けて3つのタイプがあります。\n\n実証的問題\n規範的問題\n分析的問題\n\nこの3種類の問題について説明します。 「よい研究テーマ」の探し方を理解したらよい研究テーマが見付かるわけではないで、自分が面白い！と思えるような、興味引かれるテーマを見つけることが重要です。\n\n1.2.1 リサーチ・クエスチョンの種類\nリサーチ・クエスチョン(research question)とは、研究対象となる会計に関する、抽象度の高い問いのことです。 リサーチ・クエスチョンが決まれば、その問いに答えるために、何をするべきなのかが決まるため、非常に重要な要素となります。 たとえば、\n\n会計情報の質が高いと、投資家の意思決定がよりよいものになるのか？\n大きな監査法人は、財務報告の質を高めているのか？\nCSR活動に積極的な会社は、納税も積極的か？\nステルス値上げと値上げに購買意欲に与える影響は同じか？\n女性管理職を増加させることは，企業業績に良い影響を与えるのか？\n\nこれらのリサーチ・クエスチョンを3つに分類してみましょう。\n\n1.2.1.1 実証的問題\n実証的問題では、事実を調べることが目的となります。 たとえば、「のれんの非償却はM&Aを促進させるのか」という問いに対しては、のれんの非償却を行っている企業と、行っていない企業のM&Aの実施率を比較することで、その問いに答えることができます。\n実証的問題を扱う会計研究でも、定量的な研究だけでなく、インタビューによる定性的な研究もあります。参与観察研究はあまり見ません。 事実に注目する研究となるため、主観的な要素はできるだけ排して、観察されたデータや発言といった客観的なデータを用いることが多いです。 このプレゼミでは、主として経営学分野における実証的問題を扱います。\n\n\n1.2.1.2 規範的問題\nいわゆる「べき論」を扱う問題で、日本の会計研究では今でも盛んに行われている研究です。 たとえば、「のれんは償却すべきか」という問いに対しては、のれんの償却を行うことで、どのようなメリットがあるのか、どのようなデメリットがあるのかを考え、そのメリットとデメリットを比較することで、その問いに答えることができます。 ただ、この場合でも、「誰にとっての」メリットを重視するべきなのか、という問題がでますが、そこは研究者の価値判断によって決まることになり、研究者の主観が大きく反映されることになります。\nしたがって教科書でも、規範的問題を実証的問題に変換する方法を考え、規範的問題を直接あつかう研究課題は取りあげません。\n\n\n1.2.1.3 分析的問題\n分析的問題は、まだ起こっていない、観察されていない現象を扱います。 そもそも起こっていない現象なのでデータも取りようがありません。 そこで、分析的問題では、モデル(model)を用いて、現象の起こりうるメカニズムを考えます。\n基本的には、関心のある問題を抽象化して数式で表現し、前提条件と仮定を設定し、その問題を解くことで得られた結果を解釈することで、その問いに答えることができます。 たとえば、税務会計や監査といった情報が入手困難な領域において、ゲーム理論や契約理論、最適化理論を用いた分析が行われることが多いような気がしますが、そこまで詳しくないでし、難しいので、ここでは扱いません。\nしたがって、このプレゼミでは、各自がたてた実証的問題について考えていきます。\n\n\n\n1.2.2 「よい研究テーマ」の見つけ方\n政治学のMonroe (2000, pp.8–10)によると、\n\n明快さ\n検証可能性\n理論的重要性\n実用性\n独創性\n\nがよい研究テーマに必要な要素らしいです。\n詳しくは教科書を読むとして、会計学や経営学でもほぼ同じですが、卒業論文においては、理論的重要性と独創性はあればよいですが、必ずしも必要ではありません。 なぜなら、理論的重要性を理解し、論文で示すことは、研究で用いる推論の背後にある理論や仕組みを完全に理解する必要がありますし、独創性を主張するためには、膨大な先行研究を読み、自分の主張が他の人とどう違うのか、どの点が新しいのかを明らかにする必要があり、とても時間がかかるからです。\nしたがって、明快な推論で導き出された仮説を、客観的なデータを用いて、適切な手法で分析し、その結果を解釈し、経営実務にどういう影響があるのか、を主張できれば、卒業論文としては申し分ないレベルです。\nとりわけ、このプレゼミでは、検証可能性を重視します。 そのレポート・論文を読めば、他の人でも同じ分析を行うことが可能であり、誰でも追試が行えることが重要です。 データの集め方や変数の作り方、データ分析のプロセスが明確にしめされており、それを自分でもすぐに再現することが重要です。そのためにRは非常に有効なツールとなります。\n\n1.2.2.1 規範的問題から実証的問題への変換\n「べき論」は研究者の価値判断が大きく反映され、その研究者が主張する価値は主観的なものになるため検証ができません。 そこで規範的問題を実証的問題になるように問い方を変える方法を考えます。\n\n1つめの方法は、参照枠組みを変える方法です。 「会計は投資意思決定に役立つべきである」という問いは規範的問題で、それは「会計は株主のためのものである」という価値判断が含まれています。このままでは検証できないので、「会計は投資意思決定に役に立っているのか？」に変えることで、検証可能な問いになります。\n\n2つめの方法は、規範的問題の前提条件に注目する方法です。 「会計は投資意思決定の役立つべきである」という規範的記述の背後には、\n\n会計は投資家のためのものである\n投資家が会計(情報)を使えば儲かる。\n投資家の投資が活発になれば、経済は活性化する。\n\nという前提条件があると考えられます。 これを実証的な問題にするには、\n\n会計(情報)の主な利用者は投資家なのか？\n会計情報を使えば儲かるのか？\n投資の役に立つ会計情報を提供することで、経済は活性化するのか？\n\nのように、規範的問題の背後にある前提条件を検証可能な問いに変えることで、実証的な問題になります。\n\n\n1.2.2.2 パズルを探す\nパズル(puzzle)とは、ある現象を説明するために、既存の理論では説明できない現象のことです。 たとえば、配当パズル(dividend puzzle)とは、配当がなぜ存在するのか、という問題です。 配当は、株主に対する利益配分の一つであり、株主にとっては配当が高いほうがよいはずです。しかし、実際には、配当が高いほど株価が低くなるという現象が観察されます。 このような現象を説明するために、既存の理論では説明できないので、パズルと呼ばれ、研究題材としては非常に魅力的です。\n\n\n1.2.2.3 研究論文の構成\n実証研究の論文構成は、ほぼ以下のような構成となっています。\n\nイントロダクション\n先行研究\n理論\n仮説\n対抗仮説\n作業化\n証拠\n結論\n\nこのうち、1-4は、研究の背景を説明する部分であり、5-7は、研究の主要な部分であり、8は、研究のまとめです。"
  },
  {
    "objectID": "presemi2023_02.html#リサーチクエスチョンの種類",
    "href": "presemi2023_02.html#リサーチクエスチョンの種類",
    "title": "2  研究、仮説、実証会計",
    "section": "2.3 リサーチ・クエスチョンの種類",
    "text": "2.3 リサーチ・クエスチョンの種類\nリサーチ・クエスチョン(research question)とは、研究対象となる会計に関する、抽象度の高い問いのことです。 リサーチ・クエスチョンが決まれば、その問いに答えるために、何をするべきなのかが決まるため、非常に重要な要素となります。 たとえば、\n\n会計情報の質が高いと、投資家の意思決定がよりよいものになるのか？\n大きな監査法人は、財務報告の質を高めているのか？\nCSR活動に積極的な会社は、納税も積極的か？\nのれんは償却するべきか？\nIFRS採用企業と非採用企業の違いはあるのか？\nコロナ禍における利益圧縮活動は行われたのか？\n\nこれらのリサーチ・クエスチョンを3つに分類してみましょう。\n\n2.3.1 実証的問題\n実証的問題では、事実を調べることが目的となります。 たとえば、「のれんの非償却はM&Aを促進させるのか」という問いに対しては、のれんの非償却を行っている企業と、行っていない企業のM&Aの実施率を比較することで、その問いに答えることができます。\n実証的問題を扱う会計研究でも、定量的な研究だけでなく、インタビューによる定性的な研究もあります。参与観察研究はあまり見ません。 事実に注目する研究となるため、主観的な要素はできるだけ排して、観察されたデータや発言といった客観的なデータを用いることが多いです。 このプレゼミでは、主として経営学分野における実証的問題を扱います。\n\n\n2.3.2 規範的問題\nいわゆる「べき論」を扱う問題で、日本の会計研究では今でも盛んに行われている研究です。 たとえば、「のれんは償却すべきか」という問いに対しては、のれんの償却を行うことで、どのようなメリットがあるのか、どのようなデメリットがあるのかを考え、そのメリットとデメリットを比較することで、その問いに答えることができます。 ただ、この場合でも、「誰にとっての」メリットを重視するべきなのか、という問題がでますが、そこは研究者の価値判断によって決まることになり、研究者の主観が大きく反映されることになります。\nしたがって教科書でも、規範的問題を実証的問題に変換する方法を考え、規範的問題を直接あつかう研究課題は取りあげません。\n\n\n2.3.3 分析的問題\n分析的問題は、まだ起こっていない、観察されていない現象を扱います。 そもそも起こっていない現象なのでデータも取りようがありません。 そこで、分析的問題では、モデル(model)を用いて、現象の起こりうるメカニズムを考えます。\n基本的には、関心のある問題を抽象化して数式で表現し、前提条件と仮定を設定し、その問題を解くことで得られた結果を解釈することで、その問いに答えることができます。 たとえば、税務会計や監査といった情報が入手困難な領域において、ゲーム理論や契約理論、最適化理論を用いた分析が行われることが多いような気がしますが、そこまで詳しくないでし、難しいので、ここでは扱いません。\nしたがって、このプレゼミでは、各自がたてた実証的問題について考えていきます。"
  },
  {
    "objectID": "presemi2023_02.html#よい研究テーマの見つけ方",
    "href": "presemi2023_02.html#よい研究テーマの見つけ方",
    "title": "2  研究、仮説、実証会計",
    "section": "2.4 「よい研究テーマ」の見つけ方",
    "text": "2.4 「よい研究テーマ」の見つけ方\n政治学のMonroe (2000, pp.8–10)によると、\n\n明快さ\n検証可能性\n理論的重要性\n実用性\n独創性\n\nがよい研究テーマに必要な要素らしいです。\n詳しくは教科書を読むとして、会計学や経営学でもほぼ同じですが、卒業論文においては、理論的重要性と独創性はあればよいですが、必ずしも必要ではありません。 なぜなら、理論的重要性を理解し、論文で示すことは、研究で用いる推論の背後にある理論や仕組みを完全に理解する必要がありますし、独創性を主張するためには、膨大な先行研究を読み、自分の主張が他の人とどう違うのか、どの点が新しいのかを明らかにする必要があり、とても時間がかかるからです。\nしたがって、明快な推論で導き出された仮説を、客観的なデータを用いて、適切な手法で分析し、その結果を解釈し、経営実務にどういう影響があるのか、を主張できれば、卒業論文としては申し分ないレベルです。\nとりわけ、このプレゼミでは、検証可能性を重視します。 そのレポート・論文を読めば、他の人でも同じ分析を行うことが可能であり、誰でも追試が行えることが重要です。 データの集め方や変数の作り方、データ分析のプロセスが明確にしめされており、それを自分でもすぐに再現することが重要です。そのためにRは非常に有効なツールとなります。\n\n2.4.1 規範的問題から実証的問題への変換\n「べき論」は研究者の価値判断が大きく反映され、その研究者が主張する価値は主観的なものになるため検証ができません。 そこで規範的問題を実証的問題になるように問い方を変える方法を考えます。\n\n1つめの方法は、参照枠組みを変える方法です。 「会計は投資意思決定に役立つべきである」という問いは規範的問題で、それは「会計は株主のためのものである」という価値判断が含まれています。このままでは検証できないので、「会計は投資意思決定に役に立っているのか？」に変えることで、検証可能な問いになります。\n\n2つめの方法は、規範的問題の前提条件に注目する方法です。 「会計は投資意思決定の役立つべきである」という規範的記述の背後には、\n\n会計は投資家のためのものである\n投資家が会計(情報)を使えば儲かる。\n投資家の投資が活発になれば、経済は活性化する。\n\nという前提条件があると考えられます。 これを実証的な問題にするには、\n\n会計(情報)の主な利用者は投資家なのか？\n会計情報を使えば儲かるのか？\n投資の役に立つ会計情報を提供することで、経済は活性化するのか？\n\nのように、規範的問題の背後にある前提条件を検証可能な問いに変えることで、実証的な問題になります。\n\n\n2.4.2 パズルを探す\nパズル(puzzle)とは、ある現象を説明するために、既存の理論では説明できない現象のことです。 たとえば、配当パズル(dividend puzzle)とは、配当がなぜ存在するのか、という問題です。 配当は、株主に対する利益配分の一つであり、株主にとっては配当が高いほうがよいはずです。しかし、実際には、配当が高いほど株価が低くなるという現象が観察されます。 このような現象を説明するために、既存の理論では説明できないので、パズルと呼ばれ、研究題材としては非常に魅力的です。\n\n\n2.4.3 研究論文の構成\n実証研究の論文構成は、ほぼ以下のような構成となっています。\n\nイントロダクション\n先行研究\n理論\n仮説\n対抗仮説\n作業化\n証拠\n結論\n\nこのうち、1-4は、研究の背景を説明する部分であり、5-7は、研究の主要な部分であり、8は、研究のまとめです。"
  },
  {
    "objectID": "presemi2023_02.html#sec-05",
    "href": "presemi2023_02.html#sec-05",
    "title": "1  研究、仮説、実証会計",
    "section": "1.5 本日の課題",
    "text": "1.5 本日の課題"
  },
  {
    "objectID": "presemi2023_02.html",
    "href": "presemi2023_02.html",
    "title": "2  研究、仮説、実証会計",
    "section": "",
    "text": "3 理論と仮説\n第2回講義の到達目標は、\nです。 第1回講義の到達度検証のための課題は、以下の通りです。\nたとえば、監査研究の一例を挙げてみると、次のような図になります。"
  },
  {
    "objectID": "presemi2023_02.html#よい理論とは",
    "href": "presemi2023_02.html#よい理論とは",
    "title": "2  研究、仮説、実証会計",
    "section": "3.1 「よい理論」とは？",
    "text": "3.1 「よい理論」とは？\n実証研究のリサーチ・デザイン(research design)のプロセスは次のような手順になります。\n\nパズルを見つける（簡単には見付からないです）\nパズルを説明するための複数の前提条件を使って理論を作る。（前提条件を自分で考えるのは難しすぎるので、先行研究を参考にすることが多いです。理論はパズルを説明するための仮説の集合体です。）\n理論から作業仮説(working hypothesis, hypothesis)を引き出す。\n作業仮説を検証するためのデータを集める。\nデータを使って作業仮説を検証し、理論の妥当性を確かめる。\n\n理想的にはこうなるでしょうが、現実にはこんなにうまくいきませんが、この講義では3〜5のプロセスを重視します。というのも、1と2のステップはかなり難しいので、現実には、\n\n興味のある経営現象を見つけて調べる。\n経営現象の発生を説明するための理論を見つけるために、先行研究を漁る。\n先行研究を参考にして作業仮説を作る。\n\nという風に行われることが多い（と思います。たぶん）\n\n3.1.1 因果法則の3つの条件\n因果関係(causality)と相関関係(correlation)の違いを理解しておきましょう。\n因果関係は、近年の社会科学領域の研究で最も注目されているキーワードでしょう。 もともと因果関係を特定し、推定する研究は数多く行われてきましたが、近年になって発達した計量経済学や実験経済学の手法を使って、より厳密に因果関係を特定しようとする研究が増え、因果関係を適切に特定することの重要性が認識されるようになりました。\n例えば、こんな本が近年出版されています。\n\n\n\n\n\n\n因果推論入門：基礎から現代的アプローチまで\n\n\n\n\n\n\n\n統計的因果推論の理論と実装\n\n\n\n\n\n\n\n効果検証入門\n\n\n\n\n\n因果関係とは、原因(causal)と結果(outcome)の関係のことです。正確に言うと、ある要因Xを操作するとき、別の要因Yが変化することです(Imbens and Rubin, 2015, p.4)。\n因果関係を考える際には、「効果をもたらした原因」(causal of effect)と「原因のもたらす効果」(effect of cause)の両方を考える必要があります。 例えば、ある企業が従業員の給料を上げたとします。 このとき、従業員の給料が上がったことが「効果をもたらした原因」であり、従業員の給料が上がったことによって、従業員のモチベーションが上がったことが「原因のもたらす効果」です。 定量的な研究では、「原因のもたらす効果」を分析することが多いです。\n因果関係があると考えるためには、3つの条件を確かめる必要があります。\n\n原因が結果より先に起こる。\n原因と結果が共変する。\n原因以外の重要な要因が変化しない。\n\nこの因果関係を記述するものを理論といいます。\n\n\n3.1.2 理論とは\n理論とは「原因と結果について一般的な論述」で、「〇〇であるとき、△△が起こる」というようなものです。推論といってもよいです。 原因と結果の関係を「説明変数X」(explanatory variable)と「応答変数Y」(response variable)の関係として表現します。\n\nX \\Longrightarrow Y\n\n推論を作る際には，どれだけ説得力があり納得できる仮定を設定するかが重要となります。仮定のない推論など役に立たないからです。 経営学は独自の理論をもたない学問とも言われ，とりわけ会計学における事実解明的研究(positive research)では，心理学や経済学で蓄積された理論を借用することが多いです（松浦は経済学に基づく推論を行っています）。\n\n\n3.1.3 良い理論とは？\n良い理論・推論が持つべき性質は次のようなものです。\n\n反証可能であること\n観察可能な予測が多いこと\n具体的であること\nシンプルであること\n\n以下ではそれぞれについて簡単に説明します。\n\n反証可能であること\n「反証可能性」(falsifiability)という科学で最も重要な特性の1つを確保する必要があります 1 。\nつまり，論文を読んだ人ならだれでも，「この理論は間違っている」ということを示すことができるようにする必要があります。 反証可能性がない主張は占いと変わりません。\n\n\n観察可能な予測が多いこと\n結果として発生する現象が観察可能である予測を行う必要があることを示しています。 当然ですが，自分の主張を証拠を用いて説得力を高めようとしているのですから，その予測が当たっているのかどうかを確認できる必要があります。\n\n\n具体的であること\n「業績が悪くなる」のようにあいまいな表現ではなく，「昨年度と比べて利益が減少する」とか「累積リターンがマイナスになる」といったように，具体的な予測を行う必要があります。「リスク」とか「パフォーマンス」とか「悪くなる」とか「加速する」といったあいまいな言葉は常に定義してから使うようにしましょう。\n\n\nシンプルであること\n理論はシンプルでなければなりません。 理解しやすく，使える範囲が広く，反証可能性が高い理論は，シンプルになっていきます。\n基本的には，先行研究で使われている理論を援用することが多い経営学・会計学では，先行研究で用いられた理論や推論に無駄がないかどうか，よりシンプルにいえないかどうか，を考えることが多いです。\n理論をシンプルにするには，前提となる条件を少なくする必要があります。 観察された経営現象をそのまま記述しようとすると非常に長く，複雑な文章になるでしょう。 それでは何が本質的に重要か分からないので，経営現象を抽象化・単純化することで，本質以外のものをそぎ落とし，理論をシンプルにすることがで，経営現象への理解がより深まります(オッカムの剃刀)。"
  },
  {
    "objectID": "presemi2023_02.html#仮説と仮説検証",
    "href": "presemi2023_02.html#仮説と仮説検証",
    "title": "1  研究、仮説、実証会計",
    "section": "1.4 仮説と仮説検証",
    "text": "1.4 仮説と仮説検証\n\n1.4.1 仮説とは\n科学的には，「理論」と「仮説」とは同じものです。 反証されずに生き残った理論を仮説(hypothesis)と呼びます。 たとえば、ニュートンの万有引力の法則は，現在でも仮説として使われています。\nこの「仮説」をより具体的にしたものを「作業仮説」(working hypothesis)と呼びます。\n\n作業仮説とは，自分が使える特定の変数についての記述\n「もしこの仮説が正しければ・・・のはず」\n理論より作業仮説の方が具体的である\n仮説から引き出される観察可能な予測について述べる\n\n\n\n1.4.2 作業仮説\nたとえば「監査の質が高いほど，財務報告の質が高くなる」という理論から，作業仮説を引き出してみましょう。 この文章の中で，\n\n監査の質\n高い\n財務報告の質\n高い\n\nという4つの用語を，測定可能な尺度にして，その高低を定義する必要があります。\nたとえば，監査の質を「監査報酬額」で測定して，財務報告の質を利益操作の程度で測定するとします。利益操作の程度を異常アクルーアルで代理すると\n\n監査報酬が、同業他社平均より高い企業ほど，異常アクルーアルの絶対値が小さい\n\nという作業仮説を立てることができます。\n理論から作業仮説を導出することは、構成概念から代理変数を導出すること深く関連しています。 この作業のコツをつかむには、良質な論文を読んで、自分でまとめてみて、他人に聞いてもらい、議論することが重要です。 そうして、自分の理論を作り上げていくのです。"
  },
  {
    "objectID": "presemi2023_02.html#footnotes",
    "href": "presemi2023_02.html#footnotes",
    "title": "1  研究、仮説、実証会計",
    "section": "",
    "text": "「反証不可能な理論は科学ではない」といったのは，科学哲学者カール・ポパー(Karl Popper)です。 Popper (1959) The Logic of Scientific Discovery, London: Hutchinson.（邦訳：ポパー（1971）『科学的発見の論理 上下巻』，恒星社厚生閣）↩︎"
  },
  {
    "objectID": "index.html#自己紹介タイム",
    "href": "index.html#自己紹介タイム",
    "title": "Rによる計量政治学ノート",
    "section": "自己紹介タイム",
    "text": "自己紹介タイム\n総勢25名の松浦プレゼミ1期生による自己紹介を行います。 1人1分で，自分の名前と出身都道府県，好きなもの(何でもOK)を発表してください。"
  },
  {
    "objectID": "presemi2023_02.html#理論と仮説",
    "href": "presemi2023_02.html#理論と仮説",
    "title": "1  研究、仮説、実証会計",
    "section": "1.3 理論と仮説",
    "text": "1.3 理論と仮説\n第2回講義の到達目標は、\n\nリサーチ・クエスチョンを設定することができる。\n作業仮説を作る。\n作業仮説を検証するためのデータを集めることができる。\n代理変数の妥当性を検討することができる。\n\nです。 第1回講義の到達度検証のための課題は、以下の通りです。\n\n構成概念を定義し、因果関係を示す理論を説明できる。\n作業仮説を作り、構成概念を検証するための代理変数を構築する。\n構成概念の代理変数として複数の候補を挙げる。\nKinny’s Bosを作成する。\n\n\n\n\nLibby’s Box\n\n\nたとえば、監査研究の一例を挙げてみると、次のような図になります。\n\n\n\n監査と財務報告の質\n\n\n\n1.3.1 「よい理論」とは？\n実証研究のリサーチ・デザイン(research design)のプロセスは次のような手順になります。\n\nパズルを見つける（簡単には見付からないです）\nパズルを説明するための複数の前提条件を使って理論を作る。（前提条件を自分で考えるのは難しすぎるので、先行研究を参考にすることが多いです。理論はパズルを説明するための仮説の集合体です。）\n理論から作業仮説(working hypothesis, hypothesis)を引き出す。\n作業仮説を検証するためのデータを集める。\nデータを使って作業仮説を検証し、理論の妥当性を確かめる。\n\n理想的にはこうなるでしょうが、現実にはこんなにうまくいきませんが、この講義では3〜5のプロセスを重視します。というのも、1と2のステップはかなり難しいので、現実には、\n\n興味のある経営現象を見つけて調べる。\n経営現象の発生を説明するための理論を見つけるために、先行研究を漁る。\n先行研究を参考にして作業仮説を作る。\n\nという風に行われることが多い（と思います。たぶん）\n\n\n1.3.2 因果法則の3つの条件\n因果関係(causality)と相関関係(correlation)の違いを理解しておきましょう。\n因果関係は、近年の社会科学領域の研究で最も注目されているキーワードでしょう。 もともと因果関係を特定し、推定する研究は数多く行われてきましたが、近年になって発達した計量経済学や実験経済学の手法を使って、より厳密に因果関係を特定しようとする研究が増え、因果関係を適切に特定することの重要性が認識されるようになりました。\n例えば、こんな本が近年出版されています。\n\n\n\n\n\n\n因果推論入門：基礎から現代的アプローチまで\n\n\n\n\n\n\n\n統計的因果推論の理論と実装\n\n\n\n\n\n\n\n効果検証入門\n\n\n\n\n\n因果関係とは、原因(causal)と結果(outcome)の関係のことです。正確に言うと、ある要因Xを操作するとき、別の要因Yが変化することです(Imbens and Rubin, 2015, p.4)。\n因果関係を考える際には、「効果をもたらした原因」(causal of effect)と「原因のもたらす効果」(effect of cause)の両方を考える必要があります。 例えば、ある企業が従業員の給料を上げたとします。 このとき、従業員の給料が上がったことが「効果をもたらした原因」であり、従業員の給料が上がったことによって、従業員のモチベーションが上がったことが「原因のもたらす効果」です。 定量的な研究では、「原因のもたらす効果」を分析することが多いです。\n因果関係があると考えるためには、3つの条件を確かめる必要があります。\n\n原因が結果より先に起こる。\n原因と結果が共変する。\n原因以外の重要な要因が変化しない。\n\nこの因果関係を記述するものを理論といいます。\n\n\n1.3.3 理論とは\n理論とは「原因と結果について一般的な論述」で、「〇〇であるとき、△△が起こる」というようなものです。推論といってもよいです。 原因と結果の関係を「説明変数X」(explanatory variable)と「応答変数Y」(response variable)の関係として表現します。\n\nX \\Longrightarrow Y\n\n推論を作る際には，どれだけ説得力があり納得できる仮定を設定するかが重要となります。仮定のない推論など役に立たないからです。 経営学は独自の理論をもたない学問とも言われ，とりわけ会計学における事実解明的研究(positive research)では，心理学や経済学で蓄積された理論を借用することが多いです（松浦は経済学に基づく推論を行っています）。\n\n\n1.3.4 良い理論とは？\n良い理論・推論が持つべき性質は次のようなものです。\n\n反証可能であること\n観察可能な予測が多いこと\n具体的であること\nシンプルであること\n\n以下ではそれぞれについて簡単に説明します。\n\n反証可能であること\n「反証可能性」(falsifiability)という科学で最も重要な特性の1つを確保する必要があります 1 。\nつまり，論文を読んだ人ならだれでも，「この理論は間違っている」ということを示すことができるようにする必要があります。 反証可能性がない主張は占いと変わりません。\n\n\n観察可能な予測が多いこと\n結果として発生する現象が観察可能である予測を行う必要があることを示しています。 当然ですが，自分の主張を証拠を用いて説得力を高めようとしているのですから，その予測が当たっているのかどうかを確認できる必要があります。\n\n\n具体的であること\n「業績が悪くなる」のようにあいまいな表現ではなく，「昨年度と比べて利益が減少する」とか「累積リターンがマイナスになる」といったように，具体的な予測を行う必要があります。「リスク」とか「パフォーマンス」とか「悪くなる」とか「加速する」といったあいまいな言葉は常に定義してから使うようにしましょう。\n\n\nシンプルであること\n理論はシンプルでなければなりません。 理解しやすく，使える範囲が広く，反証可能性が高い理論は，シンプルになっていきます。\n基本的には，先行研究で使われている理論を援用することが多い経営学・会計学では，先行研究で用いられた理論や推論に無駄がないかどうか，よりシンプルにいえないかどうか，を考えることが多いです。\n理論をシンプルにするには，前提となる条件を少なくする必要があります。 観察された経営現象をそのまま記述しようとすると非常に長く，複雑な文章になるでしょう。 それでは何が本質的に重要か分からないので，経営現象を抽象化・単純化することで，本質以外のものをそぎ落とし，理論をシンプルにすることがで，経営現象への理解がより深まります(オッカムの剃刀)。"
  },
  {
    "objectID": "index.html#本書の構成",
    "href": "index.html#本書の構成",
    "title": "Rによる計量政治学ノート",
    "section": "本書の構成",
    "text": "本書の構成\n本書の目次は以下の通りです。\n\nはじめに\n\n第1部　リサーチデザイン\n\n第1章 計量政治学とは\n第2章 研究テーマの選び方\n第3章 理論と仮説\n\n第2部 Rを使った計量分析の方法\n\n第4章 Rの使い方\n第5章 Rによるデータ操作\n第6章 記述統計とデータの可視化・視覚化\n第7章 統計的推定\n第8章 統計的仮説検定\n第9章 変数間の関連性\n第10章 回帰分析の基礎\n第11章 回帰分析による統計的推定\n第12章 回帰分析の前提と妥当性の診断\n第13章 回帰分析の応用\n第14章 交差項の使い方\n第15章 ロジスティック関数\n\nとなっています。 第1部は研究の基礎となる内容ですので、全員がしっかりと理解しておく必要があります。 第2部はRを使った計量分析の方法を学習します。"
  },
  {
    "objectID": "index.html#使用ソフトウェアについて",
    "href": "index.html#使用ソフトウェアについて",
    "title": "Rによる計量政治学ノート",
    "section": "使用ソフトウェアについて",
    "text": "使用ソフトウェアについて\nこのウェブ資料は、Posit社(以前はRstudio社)が開発したQuartoというソフトウェアを使って作成されています。Quartoとは、RMarkdownの記法で書かれたテキストファイルを、knitrというソフトウェアを介して、HTMLやPDF、MS Word、EPUBなどのファイルを作成するためのソフトウェアです。\n最大の特徴は、MS ExcelとMS Wordのようにデータを分析する場所と文章を書く場所が別々ではなく、一つの画面の中でデータ分析とレポート・論文執筆を同時に行える、というものです。\nまた、Rだけでなく、PythonやJuliaといった他のプログラミング言語も文章内に埋め込むことができるため、データ分析と文章執筆を統合させる環境として非常に優れています。\nプレゼミでも、Quartoを使って最終レポートの作成を行う予定です。 Quartoは今も開発が進んでいる新しいレポート作成ソフトウェアなので、情報が少ないことが難点ですが、公式サイトと私たちのRを見れば大抵のことは分かります。"
  },
  {
    "objectID": "Empoli_Chap13.html#ダミー変数の利用",
    "href": "Empoli_Chap13.html#ダミー変数の利用",
    "title": "12  回帰分析の応用",
    "section": "12.1 ダミー変数の利用",
    "text": "12.1 ダミー変数の利用\n\n12.1.1 ダミー変数\nダミー変数(dummy variable)とは，二値変数(binary variable)とか指示変数(indicator variable)とも呼ばれ，カテゴリーに属しているかどうかを表す1か0の値をとる変数のことです。\n\n\\begin{aligned}\nX = \\begin{cases}\n1 & \\text{if カテゴリーに属している}\\\\\n0 & \\text{if カテゴリーに属していない}\n\\end{cases}\n\\end{aligned}\n\n会計研究では，コントロール変数として頻出の業種ダミーや年度ダミーに加えて，監査の質の代理変数となる四大監査法人ダミーや，会計基準選択で用いられるIFRSダミーといったものなど，非常に多くのダミー変数が用いられています。\n回帰分析にダミー変数を使う場合に気をつける点として， カテゴリの数がk個のカテゴリー変数は，k-1個のダミー変数を回帰分析に組み込むという点です。\n例えば，すべての企業が製造業か非製造業のどちらかに属する，とします。 そして，製造業に属するかどうかを表すダミー変数maniと，非製造業に属するかどうかを表すダミー変数nomaniを作ります。 つまり，製造業であればmani = 1，非製造業であればmani = 0製造業ダミー変数と，非製造であればnomani = 1，製造業であればnomani = 0をとる非製造業ダミー変数ができます。\nここで，製造業ダミーが1の値をとるとき，非製造業ダミーは必ず0をとり，逆に非製造業ダミーが1の値を取るとき，製造業ダミーはかならず0の値を取ります。つまりこの2つのダミー変数は相関係数が-1となり，同じ情報をもっている変数となります。 このような完全な負の関係にある2つの変数を回帰分析に組み込むと，多重共線性が発生します。\n確認してみましょう。 研究開発費のデータを読み込みます。\n\ndf &lt;- read_csv(\"data/RD_2022.csv\")\nnames(df)\n\n [1] \"会社コード\"                     \"企業名\"                        \n [3] \"決算期\"                         \"決算種別\"                      \n [5] \"連結基準\"                       \"決算月数\"                      \n [7] \"上場コード\"                     \"日経業種コード\"                \n [9] \"現金預金\"                       \"資産合計\"                      \n[11] \"資本金\"                         \"資本剰余金\"                    \n[13] \"利益剰余金\"                     \"自己株式\"                      \n[15] \"売上高\"                         \"経常利益\"                      \n[17] \"法人税等\"                       \"法人税等調整額\"                \n[19] \"親会社株主に帰属する当期純利益\" \"研究開発費IFRS\"                \n[21] \"研究開発費\"                     \"開発費・試験研究費\"            \n[23] \"現金及び現金同等物の期末残高\"  \n\n\nこのデータフレームに含まれる日経業種コードは，6ケタの整数をもつデータで，最初の1ケタが製造業か非製造業，つぎの2ケタが日経産業中分類，つぎの3ケタが日経産業小分類を表します。 ここでは，最初の1ケタが1なら製造業，2なら非製造業を表す日経産業大分類を用いて，製造業ダミー変数と非製造業ダミー変数を作ります。\n\ndf$dai &lt;- substr(df$日経業種コード,1,1) # 大分類\ntable(df$dai) # 大分類の頻度\n\n\n    1     2 \n27551 30272 \n\n\nこの大分類を用いてダミー変数を作ります。\n\ndf &lt;- df %&gt;%\n  mutate(\n    製造業ダミー = ifelse(dai == 1, 1, 0),\n    非製造業ダミー = ifelse(dai == 2, 1, 0)\n  )\ntable(df$製造業ダミー, df$非製造業ダミー)\n\n   \n        0     1\n  0     0 30272\n  1 27551     0\n\n\n上の表より，製造業ダミーと非製造業ダミーは完全に負の関係にあることが分かります。\n次に，研究開発費が翌期の売上高に与える影響を分析する回帰式に，製造業ダミーと非製造業ダミーの2つのダミー変数を組み込んでみます。\n\nres &lt;- lm(売上高 ~ lag(研究開発費) + 製造業ダミー + 非製造業ダミー, data = df)\nsummary(res)\n\n\nCall:\nlm(formula = 売上高 ~ lag(研究開発費) + 製造業ダミー + \n    非製造業ダミー, data = df)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-21499834   -118247    -57215    -10030  13666084 \n\nCoefficients: (1 not defined because of singularities)\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      2.332e+05  5.790e+03   40.28   &lt;2e-16 ***\nlag(研究開発費)  1.945e+01  7.086e-02  274.45   &lt;2e-16 ***\n製造業ダミー    -1.643e+05  6.918e+03  -23.75   &lt;2e-16 ***\n非製造業ダミー          NA         NA      NA       NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 597800 on 36278 degrees of freedom\n  ( 21542 個の観測値が欠損のため削除されました )\nMultiple R-squared:  0.6749,    Adjusted R-squared:  0.6749 \nF-statistic: 3.766e+04 on 2 and 36278 DF,  p-value: &lt; 2.2e-16\n\n\n上の分析結果をみると，1 not defined because of singularitiesというメッセージがあり，非製造業ダミーがNAになっていることが分かります。 これは製造業ダミーと非製造業ダミーの相関が高すぎることにより，Rが自動で変数を落としているのです。\n\n\n12.1.2 ダミー変数を使った回帰分析"
  },
  {
    "objectID": "Empoli_Chap13.html#変数変換",
    "href": "Empoli_Chap13.html#変数変換",
    "title": "12  回帰分析の応用",
    "section": "12.2 変数変換",
    "text": "12.2 変数変換\n回帰分析を実行するときに，変数をそのまま使うのでは無く，変数を変換して使う場合が多いです。 決算書の財務データは「百万円」か「千円」の単位で記録されているので，百万円でそろえる必要がありますし，外貨で保有する資産などは円換算する必要があります。\n売上高や利益額は同じ企業の過去の値と比較するのであれば問題ないですが，規模が異なる企業の売上高や利益を比較しても意味はないので，ROEや総資産回転率といった財務比率に直すことも多いです。\n\n12.2.1 線形変換\n確率変数Xがアフィン変換(affine transformation)をする場合を考えます。\n\n\\begin{aligned}\nY =  a + bX\n\\end{aligned}\n\nによって確率変数Xが確率変数Yに変換されたとします。 ここでaとbはパラメータです。 つまりアフィン変換とは確率変数を定数倍して定数を足す，という変換です。 このとき，次の関係が成立します。\nまず期待値については，\n\n\\begin{aligned}\n\\mathbb{E}[Y] &= \\mathbb{E}[a + bX] \\nonumber \\\\\n       &= \\mathbb{E}[a] + \\mathbb{E}[bX] \\nonumber\\\\\n       &= a + b \\mathbb{E}[X]\n\\end{aligned}\n となり，分散については， \n\\begin{aligned}\n\\mathbb{V}[Y]\n        &= \\mathbb{E}[(Y - \\mathbb{E}[Y])^2]      \\nonumber \\\\\n        &= \\mathbb{E}[(a + bX - (a+b\\mathbb{E}[X]))^2] \\nonumber\\\\\n        &= \\mathbb{E}[(bX - b \\mathbb{E}[X])^2]   \\nonumber\\\\\n        &= \\mathbb{E}[b^2 (X - \\mathbb{E}[X])^2]  \\nonumber\\\\\n        &= b^2 \\mathbb{E}[ (X - \\mathbb{E}[X])^2] \\nonumber\\\\\n        &= b^2 \\mathbb{V}[X]\n\\end{aligned}\n\nとなり，標準偏差については，\n\n\\begin{aligned}\n\\sigma _Y = \\sqrt{\\mathbb{V}[Y]} = |b| \\sqrt{\\mathbb{V}[X]}\n\\end{aligned}\n\nとなることが分かっています。\n\n\n\n\n\n\nアフィン変換\n\n\n\nある工事が完了する日数とその確率が次のように予測されているとします。\n\n\n\n日数X\n1\n2\n3\n4\n5\n\n\n\n\n確率p(x)\n5\\%\n20\\%\n35\\%\n30\\%\n10\\%\n\n\n\nこのとき\n\n\\begin{aligned}\n\\mathbb{E}[X] &\\equiv \\sum _k p_k x_k \\text{より} & \\mathbb{E}[X] &= 3.2\\\\\n\\mathbb{V} [X] &\\equiv \\sum _k p_k (x_k - \\mathbb{E}[X])^2 \\text{より} & \\mathbb{V} [X] &= 1.06\n\\end{aligned}\n\nこの工事では，固定費として100万円，変動費として1日あたり10万円の費用がかかるとすると，総費用は，\n\n\\begin{aligned}\nY = 100  + 10 X\n\\end{aligned}\n\nとして表される。 このとき，総費用の期待値および分散は，\n\n\\begin{aligned}\n\\mathbb{E}[Y] &= 100 + 10 \\mathbb{E}[X] = 100 + 10 \\times 3.2 = 132\\\\\n\\mathbb{V}[Y] &= 10^2 \\mathbb{V}[X] = 100  \\times 1.06 = 106\n\\end{aligned}\n\nとなる。\n\n\nより一般的に，k個の確率変数X_i, i = 1, \\dots ,kの一次結合Y = c_0 + c_1 X_1 + \\cdots + c_k X_kで表される確率変数Yにおいて，次の関係が成立する。 ここで，c_0,c_1, \\dots, c_kはパラメータで，定数です。\n\n\\begin{aligned}\n\\mathbb{E}[Y] &= c_0 + c_1 \\mu _1 + \\cdots c_k \\mu_k\\\\\n\\mathbb{V} [Y] &= c_1^2 \\sigma_1^2 + \\cdots +  c_k^2 \\sigma _k^2 + \\sum _{i\\not = j}^k \\sum_{j \\not = i}^k c_i c_j \\sigma _{ij}\n\\end{aligned}\n\nここで，\\mu _i = \\mathbb{E}[X_i]，\\sigma _i^2 = \\mathbb{V}[X_i]，\\sigma _{ij} = \\mathbb{COV}[X_i,X_j]である。\n例えば，k=2のケースでは，\n\n\\begin{align}\n\\mathbb{E}[Y]   &= c_0 + c_1 \\mu _1 + c_2 \\mu_2\\\\\n\\mathbb{V} [Y] &= c_1^2 \\sigma_1^2 + c_2^2 \\sigma _2^2 + 2 c_1 c_2 \\sigma _{12}\n\\end{align}\n\n\n\n\n\n\n\n問題3\n\n\n\nk=3のケースにおける確率変数Yの期待値と分散を求めなさい。\n\n\n\n\n\n\n\n\n例8\n\n\n\nk=2のケースで，Y=0.5X_1 + 0.5 X_2の期待値および分散を求めます。 ただし，\\mu _1 = 0.07，\\sigma _1^2 = 1.48，\\mu_2 = -0.02，\\sigma _2^2 = 1.46とします。\n\n無相関(\\rho _{12} = 0, $[X_1,X_2] =0 $)のケース \n\\begin{aligned}\n  \\mathbb{E}[Y]   &= 0.5 \\times 0.07 + 0.5 \\times - 0.02 = 0.025\\\\\n  \\mathbb{V} [Y] &= 0.5^2 \\times 1.48 + 0.5^2 \\times 1.46 + 2 \\times 0.5 \\times 0.5 \\times 0 = 0.735\n  \\end{aligned}\n\nYの分散は，X_1とX_2の分散よりも小さい。\n負の相関($_{12} = -0.99 [X_1,X_2] = -1.46 $)のケース \n\\begin{aligned}\n  \\mathbb{E}[Y]   &= 0.5 \\times 0.07 + 0.5 \\times - 0.02 = 0.025\\\\\n  \\mathbb{V} [Y] &= 0.5^2 \\times 1.48 + 0.5^2 \\times 1.46 + 2 \\times 0.5 \\times 0.5 \\times -1.46 = 0.005\n  \\end{aligned}\n\nYの分散は，X_1とX_2の分散よりも小さい。\n\nX_1とX_2の共分散は，Yの分散に影響を与える。\n\n\n\n\n12.2.2 中心化\n変数変換の一つに中心化(centering)があります。 これは，説明変数からその平均値を引くことで，説明変数の平均値を0にする変換です。これは一次関数の平行移動に相当する線形変換の一種で，回帰式の切片の解釈を容易にするために使われます。\n平均値として標本平均を用いることが一般的ですが，理論的に考えられる平均値を使うこともあります。 たとえば，男女ダミーの平均は0.5，というような場合です。\nでは中心化をしてみます。 中心化するための自作関数を作成したり， mutate()関数で平均を引くことで中心化された変数を作成したりすることもできますが，ここでは中心化や標準化を行うscale()関数を使ってみます。\n先の回帰分析では，次のようなモデルを推定しました。\n\n\\text{売上高} = \\alpha + \\beta_1 \\text{研究開発費} + \\beta_2 \\text{製造業ダミー} + \\varepsilon\n\nこの回帰式を推定すると，次のようになります。\n\nres01 &lt;- lm(売上高 ~ lag(研究開発費) + 製造業ダミー , data = df)\nsummary(res01)\n\n\nCall:\nlm(formula = 売上高 ~ lag(研究開発費) + 製造業ダミー, \n    data = df)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-21499834   -118247    -57215    -10030  13666084 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      2.332e+05  5.790e+03   40.28   &lt;2e-16 ***\nlag(研究開発費)  1.945e+01  7.086e-02  274.45   &lt;2e-16 ***\n製造業ダミー    -1.643e+05  6.918e+03  -23.75   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 597800 on 36278 degrees of freedom\n  ( 21542 個の観測値が欠損のため削除されました )\nMultiple R-squared:  0.6749,    Adjusted R-squared:  0.6749 \nF-statistic: 3.766e+04 on 2 and 36278 DF,  p-value: &lt; 2.2e-16\n\n\nこの回帰式の切片2.3318761^{5}の意味を考えてみましょう。 この切片は，研究開発費と製造業ダミーが0の場合の売上高の平均値を示しています。つまり非製造業企業で研究開発費がゼロの企業における平均売上高を表しています。\n研究開発費がゼロの企業というのはそれなりに存在しているので，教科書のように父親の身長がゼロのとき，といった非現実的な状況を表しているわけではないですが，非製造業企業だけの平均売上高だけでなく，全体の平均を表すために，変数を中心化(centering)します。\nここでは，標本平均を差し引くことで中心化します。\n\ndf &lt;- df %&gt;%\n  mutate(\n    研究開発費中心化 = scale(研究開発費, center = TRUE, scale = FALSE),\n    売上高中心化 = scale(売上高, center = TRUE, scale = FALSE)\n  )\nres02 &lt;- lm(売上高中心化 ~ lag(研究開発費中心化) + 製造業ダミー , data = df)\nres &lt;- list(res01,res02)\nlibrary(modelsummary)\nmodelsummary(res)\n\n\n\n\n\n (1)\n  (2)\n\n\n\n\n(Intercept)\n233187.611\n159890.665\n\n\n\n(5789.706)\n(5804.886)\n\n\nlag(研究開発費)\n19.447\n\n\n\n\n(0.071)\n\n\n\n製造業ダミー\n-164270.989\n-164270.989\n\n\n\n(6917.606)\n(6917.606)\n\n\nlag(研究開発費中心化)\n\n19.447\n\n\n\n\n(0.071)\n\n\nNum.Obs.\n36281\n36281\n\n\nR2\n0.675\n0.675\n\n\nR2 Adj.\n0.675\n0.675\n\n\nAIC\n1068119.6\n1068119.6\n\n\nBIC\n1068153.6\n1068153.6\n\n\nLog.Lik.\n-534055.790\n-534055.790\n\n\nRMSE\n597821.12\n597821.12\n\n\n\n\n\n\n\n先の中心化前の回帰分析結果と比べて違っているのは，切片(intercept)の値だけです。"
  },
  {
    "objectID": "Empoli_Chap13.html#まとめ",
    "href": "Empoli_Chap13.html#まとめ",
    "title": "12  回帰分析の応用",
    "section": "12.3 まとめ",
    "text": "12.3 まとめ\n\n\\begin{aligned}\n2\\times 2 = 2^2 = 4\\\\\n2\\times 2 \\times 2 = 2^3 = 8\\\\\n2\\times 2 \\times 2 \\times 2 = 2^4 = 16\\\\\n\\end{aligned}\n\n\nlibrary(gapminder)\nlibrary(plotly)\n\ndata(gapminder)\ngg &lt;- ggplot(gapminder) +\n    aes(x = gdpPercap, y = lifeExp, color = continent) +\n    geom_point(aes(size = pop, frame = year, ids = country)) +\n    scale_x_log10()\nggplotly(gg)\n\n\n\n\n\n\nbase &lt;- gapminder %&gt;%\n    plot_ly(x = ~gdpPercap, y = ~lifeExp, size = ~pop, text = ~country, hoberinfo = \"text\") %&gt;%\n    layout(xaxis = list(type = \"log\"))\n\nbase %&gt;%\n    add_markers(color = ~continent, frame = ~year, ids = ~country) %&gt;%\n    animation_opts(frame = 1000, easing = \"elastic\", redraw = FALSE) %&gt;%\n    animation_button(\n        x = 1, xanchor = \"right\",\n        y = 0, yanchor = \"bottom\") %&gt;%\n    animation_slider(\n        currentvalue = list(prefix = \"YEAR: \", font = list(color = \"red\"))\n    )"
  },
  {
    "objectID": "Empoli_Chap14.html#交差項で何が分かるのか",
    "href": "Empoli_Chap14.html#交差項で何が分かるのか",
    "title": "13  交差項の使い方",
    "section": "13.1 交差項で何が分かるのか",
    "text": "13.1 交差項で何が分かるのか\n説明変数Xが応答変数Yに与える影響(直接効果)に対して，別の説明変数Zが与える影響がある場合，XとZの交差項X \\times Zをモデルに組み入れることで，Xの影響がZの値によってどのように変化するかを分析することができます。\n\nY = \\beta_0 + \\beta_1 X + \\beta_2 Z + \\beta_3 X \\times Z + \\varepsilon\n\nこのX \\times Zを交差項(interaction term)とよびます。\n前章で導入したダミー変数との交差項は，ダミー変数の値によって，切片や傾きがどのように変化するかを分析することができましたが，ここでは量的変数と量的変数の交差項のケースを考えます。"
  },
  {
    "objectID": "Empoli_Chap14.html#交差項を入れた回帰分析の注意点",
    "href": "Empoli_Chap14.html#交差項を入れた回帰分析の注意点",
    "title": "13  交差項の使い方",
    "section": "13.2 交差項を入れた回帰分析の注意点",
    "text": "13.2 交差項を入れた回帰分析の注意点\n回帰分析で交差項を入れる場合の注意点は次の4つです。\n\n条件付仮説(たとえば，十分にZが大きいとき，XはYに影響を与える，とか)を検証する場合に，交差項を使う。\n交差項を入れるときは，交差項を構成する変数をそれぞれ回帰モデルに入れる。\n交差項を構成する変数の回帰係数はそのまま解釈できない。\n分析結果として，限界効果と標準誤差を示す。\n\nこれは，数式で確認すれば分かりやすいです。 回帰モデルが\n\nY = \\beta_0 + \\beta_1 X + \\beta_2 Z + \\beta_3 X \\times Z + \\varepsilon\n\nであるとき，Xの影響は，YをXで偏微分することで求められます。\n\n\\frac{\\partial Y}{\\partial X} = \\beta_1 + \\beta_3 Z\n\nこの式から，Zの値によって，Xの影響が変化することが分かります。 そのため，\\beta_1の値だけでは，Xの影響を正確に評価することができません。また，Zの値によって，Xの影響が変化することを示すためには，Zの値を変化させたときの\\beta_1の値を示す必要があります。これを限界効果(marginal effect)とよびます。"
  },
  {
    "objectID": "Empoli_Chap14.html#広告宣伝費を事例とした交差項の分析",
    "href": "Empoli_Chap14.html#広告宣伝費を事例とした交差項の分析",
    "title": "13  交差項の使い方",
    "section": "13.3 広告宣伝費を事例とした交差項の分析",
    "text": "13.3 広告宣伝費を事例とした交差項の分析\n以下の分析で利用するためのデータを読み込みます。 ここでも，tidyverseパッケージ群のread_csv()関数を使います。\n\ndf &lt;- read_csv(\"data/adv_2023.csv\") # データの読み込み\ndf &lt;- df %&gt;%\n  select(-拡販費) %&gt;% # 必要ないデータを除去\n  filter(決算月数 == 12) %&gt;% # 決算月数が12のデータを抽出\n  filter(広告宣伝費 &gt; 0)  # 広告宣伝費が0のデータを除去\nglimpse(df)\n\nRows: 8,632\nColumns: 13\n$ 日経会社コード &lt;chr&gt; \"0000001\", \"0000001\", \"0000003\", \"0000003\", \"0000003\", …\n$ 企業名称       &lt;chr&gt; \"極洋\", \"極洋\", \"日本水産\", \"日本水産\", \"日本水産\", \"日…\n$ 決算期         &lt;chr&gt; \"2006/03\", \"2007/03\", \"2006/03\", \"2007/03\", \"2008/03\", …\n$ 決算種別       &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,…\n$ 連結基準       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ 決算月数       &lt;dbl&gt; 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,…\n$ 業種           &lt;dbl&gt; 235341, 235341, 235341, 235341, 235341, 235341, 235341,…\n$ 資産合計       &lt;dbl&gt; 65049, 66459, 384819, 404173, 396739, 385462, 383924, 4…\n$ 売上高         &lt;dbl&gt; 152899, 157088, 539653, 552871, 533970, 505250, 481574,…\n$ 販管費         &lt;dbl&gt; 13702, 14455, 95566, 98200, 100394, 98413, 99938, 10490…\n$ 広告宣伝費     &lt;dbl&gt; 304, 279, 2699, 2569, 2953, 2568, 2636, 3160, 3009, 288…\n$ 研究開発費     &lt;dbl&gt; 193, 188, 3083, 3377, 3718, 3803, 3994, 4499, 4809, 361…\n$ 設備投資額     &lt;dbl&gt; 897, 1841, 17186, 16031, 19105, 28872, 21121, 18633, 16…\n\n\n以下では，応答変数として売上高，説明変数として広告宣伝費と設備投資額を使います。\n\n13.3.1 記述統計と散布図の表示\n主要変数3つの記述統計をみます。 ここではsummary()関数を使います。\n\ndf3 &lt;- df[, c(\"売上高\", \"広告宣伝費\", \"設備投資額\")]\nsummary(df3)\n\n     売上高           広告宣伝費       設備投資額     \n Min.   :      54   Min.   :     1   Min.   :      1  \n 1st Qu.:   26299   1st Qu.:   250   1st Qu.:    771  \n Median :   84923   Median :  1284   Median :   3078  \n Mean   :  448013   Mean   :  9912   Mean   :  28789  \n 3rd Qu.:  277604   3rd Qu.:  6158   3rd Qu.:  12271  \n Max.   :30225681   Max.   :509653   Max.   :4069225  \n                                     NA's   :540      \n\n\nこれでも良いのですが，skimrパッケージとsummarytoolsパッケージを使うと，より見やすい表を作ることが出来ます。\n\n# install.packages(\"skimr\") # first time only\nlibrary(skimr)\nskim(df3)\n\n\nData summary\n\n\nName\ndf3\n\n\nNumber of rows\n8632\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\n売上高\n0\n1.00\n448013.23\n1522677.66\n54\n26298.75\n84923.0\n277604.00\n30225681\n▇▁▁▁▁\n\n\n広告宣伝費\n0\n1.00\n9911.51\n34054.36\n1\n250.00\n1283.5\n6158.00\n509653\n▇▁▁▁▁\n\n\n設備投資額\n540\n0.94\n28788.64\n156138.90\n1\n771.25\n3078.5\n12270.75\n4069225\n▇▁▁▁▁\n\n\n\n\n\nあるいは，summarytoolsパッケージのdescr()関数を使っても見やすい表を作ることが出来ます。\n\n# install.packages(\"summarytools\") # first time only\nlibrary(summarytools)\ndescr(df3, transpose = TRUE)\n\nDescriptive Statistics  \ndf3  \nN: 8632  \n\n                        Mean      Std.Dev     Min         Q1     Median          Q3           Max\n---------------- ----------- ------------ ------- ---------- ---------- ----------- -------------\n      広告宣伝費     9911.51     34054.36    1.00     250.00    1283.50     6161.00     509653.00\n      設備投資額    28788.64    156138.90    1.00     770.50    3078.50    12280.50    4069225.00\n          売上高   448013.23   1522677.66   54.00   26293.50   84923.00   277652.00   30225681.00\n\nTable: Table continues below\n\n \n\n                         MAD         IQR     CV   Skewness   SE.Skewness   Kurtosis   N.Valid   Pct.Valid\n---------------- ----------- ----------- ------ ---------- ------------- ---------- --------- -----------\n      広告宣伝費     1818.41     5908.00   3.44       8.29          0.03      86.44   8632.00      100.00\n      設備投資額     4215.77    11499.50   5.42      15.22          0.03     285.02   8092.00       93.74\n          売上高   107098.58   251305.25   3.40       9.52          0.03     127.38   8632.00      100.00\n\n\nまた，summarytoolsパッケージのdfSummary()関数を使うと，データフレームの形で表を作ることが出来ます。\n\ndf3 %&gt;%\n  dfSummary(\n    plain.ascii = FALSE,\n    style        = 'grid',\n    graph.magnif = 0.85,\n    varnumbers = FALSE,\n    valid.col    = FALSE) %&gt;%\n    print(method = \"render\")\n\n\nData Frame Summary\ndf3\nDimensions: 8632 x 3\n  Duplicates: 0\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nStats / Values\nFreqs (% of Valid)\nGraph\nMissing\n\n\n\n\n売上高 [numeric]\n\n\n\nMean (sd) : 448013.2 (1522678)\n\n\nmin ≤ med ≤ max:\n\n\n54 ≤ 84923 ≤ 30225681\n\n\nIQR (CV) : 251305.2 (3.4)\n\n\n\n8492 distinct values\n\n0 (0.0%)\n\n\n広告宣伝費 [numeric]\n\n\n\nMean (sd) : 9911.5 (34054.4)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 1283.5 ≤ 509653\n\n\nIQR (CV) : 5908 (3.4)\n\n\n\n4878 distinct values\n\n0 (0.0%)\n\n\n設備投資額 [numeric]\n\n\n\nMean (sd) : 28788.6 (156138.9)\n\n\nmin ≤ med ≤ max:\n\n\n1 ≤ 3078.5 ≤ 4069225\n\n\nIQR (CV) : 11499.5 (5.4)\n\n\n\n5751 distinct values\n\n540 (6.3%)\n\n\n\n\nGenerated by summarytools 1.0.1 (R version 4.2.2)2023-08-25\n\n\n\n好きな方法を使ってください。\n次に，散布図を描きます。\n\ndf3 %&gt;%\n  ggplot(aes(x = 設備投資額, y = 売上高)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(x = \"設備投資額\", y = \"売上高\") + mystyle\n\n\n\n\n設備投資額が多い企業ほど売上高が多いように見えますが，因果関係を明らかにするためにも，広告宣伝費と翌期の売上高の散布図を書いてみます。ついでに両変数を対数変換して，分布を正規分布に近づけておきます。\n\ndf3 %&gt;%\n  ggplot() + aes(x = log(lag(設備投資額)), y = log(売上高)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(x = \"前期対数設備投資額\", y = \"対数売上高\") + mystyle\n\n\n\n\n次に，この設備投資額と売上高の関係に広告宣伝費がどのような影響を与えているのかを調べるために，回帰モデルに交差項を組み込んでいきます。\n\n\n13.3.2 交差項を使った重回帰分析\nここでは，次のような仮説を考えてみます。\n\n広告宣伝費が多い企業ほど，設備投資額が多いと，売上高が増加する。\n\nこの仮説を検証するために，回帰モデルを次のように設定します。\n$$\n\\begin{aligned}\n\\log \\text{売上高} = \\beta_0 &+ \\beta_1 \\log \\text{前期設備投資額} + \\beta_2 \\log \\text{広告宣伝費} \\\\\n\n& + \\beta_3 \\log \\text{前期設備投資額} \\times \\log \\text{広告宣伝費} + \\varepsilon\n\\end{aligned}\n$$\nこれをlm()関数を使って回帰分析を行います。 lm()関すで交差項を含む回帰モデルを作るときは，*を使います。 推定結果をmodelsummaryパッケージを使って表示します。\n\nlibrary(modelsummary)\nres01 &lt;- lm(log(売上高) ~ log(設備投資額) * log(広告宣伝費), data = df3)\nmodelsummary(res01,\n  stars = c(\"*\" = .10, \"**\" = .05, \"***\" = .01),\n  gof_omit = \"AIC|BIC|logLik\",\n  )\n\n\n\n\n\n (1)\n\n\n\n\n(Intercept)\n6.819***\n\n\n\n(0.087)\n\n\nlog(設備投資額)\n0.397***\n\n\n\n(0.012)\n\n\nlog(広告宣伝費)\n-0.012\n\n\n\n(0.013)\n\n\nlog(設備投資額) × log(広告宣伝費)\n0.025***\n\n\n\n(0.001)\n\n\nNum.Obs.\n8092\n\n\nR2\n0.823\n\n\nR2 Adj.\n0.823\n\n\nLog.Lik.\n-9015.976\n\n\nF\n12548.404\n\n\nRMSE\n0.74\n\n\n\n * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n\n\n\n\n\n\n\n\n\nこの結果から，設備投資と売上高の正の関係は，広告宣伝費が大きくなるほど強くなる，ということが分かりました。 この結果の解釈を容易にするために，marginsパッケージを使って限界効果を計算します。\n\n# install.packages(\"margins\") # first time only\nlibrary(margins)\nmargins(res01)\n\n 設備投資額 広告宣伝費\n  0.0001487  0.0001997\n\n\nこの限界効果の推定から，広告宣伝費が増加すると，設備投資と売上高の正の関係が強くなることが分かります。\n\n\n13.3.3 交差項を含む回帰分析結果の解釈と可視化\n上の分析結果から，設備投資額と売上高との関係は，広告宣伝費の規模に応じて変化することが分かりました。 しかし，前述した通り設備投資額が売上高に与える影響の強さは，広告宣伝費に応じて決まるため，設備投資額が1円増えたとき，売上高がいくら増えるのかはこの推定結果からは分かりません。\nそこで，説明変数を中心化することで，推定結果を解釈可能なものにします。 前章と同様に，中心化するために，各説明変数から標本平均を引きます。 ここでは，scale()関数を使って中心化します。\n\ndf3 &lt;- df3 %&gt;%\n  mutate(\n    log広告宣伝費_c = scale(log(広告宣伝費)),\n    log設備投資額_c = scale(log(設備投資額))\n  )\nres02 &lt;- lm(log(売上高) ~ log設備投資額_c * log広告宣伝費_c, data = df3)\nmodelsummary(res02,\n  stars = c(\"*\" = .10, \"**\" = .05, \"***\" = .01),\n  gof_omit = \"AIC|BIC|logLik\",\n  )\n\n\n\n\n\n (1)\n\n\n\n\n(Intercept)\n11.331***\n\n\n\n(0.009)\n\n\nlog設備投資額_c\n1.251***\n\n\n\n(0.011)\n\n\nlog広告宣伝費_c\n0.429***\n\n\n\n(0.011)\n\n\nlog設備投資額_c × log広告宣伝費_c\n0.124***\n\n\n\n(0.007)\n\n\nNum.Obs.\n8092\n\n\nR2\n0.823\n\n\nR2 Adj.\n0.823\n\n\nLog.Lik.\n-9015.976\n\n\nF\n12548.404\n\n\nRMSE\n0.74\n\n\n\n * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n\n\n\n\n\n\n\n\n\n\ndf3 &lt;- df3 %&gt;%\n  mutate(\n    log広告宣伝費 = log(広告宣伝費),\n    log設備投資額 = log(設備投資額),\n    log広告宣伝費_c = log広告宣伝費 - mean(log広告宣伝費),\n    log設備投資額_c = log設備投資額 - mean(log設備投資額)\n  )"
  },
  {
    "objectID": "Empoli_Chap14.html#まとめ",
    "href": "Empoli_Chap14.html#まとめ",
    "title": "13  交差項の使い方",
    "section": "13.4 まとめ",
    "text": "13.4 まとめ"
  },
  {
    "objectID": "Empoli_Chap12.html#回帰分析の前提",
    "href": "Empoli_Chap12.html#回帰分析の前提",
    "title": "12  回帰分析の前提と妥当性の診断",
    "section": "12.1 回帰分析の前提",
    "text": "12.1 回帰分析の前提\n\nSection 12.1.1 モデルが妥当\nSection 12.1.2 加法制と線形性\nSection 12.1.3 誤差の独立性\nSection 12.1.4 誤差が欽一分散\nSection 12.1.5 誤差が正規分布\n\n\n12.1.1 回帰モデルの妥当性\n回帰モデルが妥当であるためには、独立変数から応答変数への因果関係をみるのに有用な推定を行えているのかどうか、ということが重要となります。 この妥当性には、\n\n内的妥当性 (internal validity)\n外的妥当性 (external validity)\n\nの2つがあります。 ここでは、内的妥当性について考えます。 回帰分析が内的妥当性を持つためには、回帰バンズ寝期の\n\n\n12.1.2 加法性と線形性\n線形回帰モデルは、核説明変数の線形関数で表される。\n\ny = \\beta _1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_k x_k\n\n加法性が満たされないモデルには、\n\ny = x_1 \\times x_2 \\times  x_3\n\nのようなモデルがあり、線形関数ではなくなっています。 しかし両辺の対数をとると、\n\n\\log y = \\log x_1 + \\log x_2 + \\log x_3\n\n\n\n12.1.3 誤差の独立性\n\n\n12.1.4 誤差の分散均一性\n\n\n12.1.5 誤差の正規性"
  },
  {
    "objectID": "Empoli_Chap12.html#rによる回帰診断",
    "href": "Empoli_Chap12.html#rによる回帰診断",
    "title": "12  回帰分析の前提と妥当性の診断",
    "section": "12.2 Rによる回帰診断",
    "text": "12.2 Rによる回帰診断\n\n12.2.1 残差プロットによる診断\n\n\n12.2.2 正規QQプロットによる診断"
  },
  {
    "objectID": "Empoli_Chap12.html#まとめ",
    "href": "Empoli_Chap12.html#まとめ",
    "title": "12  回帰分析の前提と妥当性の診断",
    "section": "12.3 まとめ",
    "text": "12.3 まとめ"
  },
  {
    "objectID": "index.html#資料の特徴",
    "href": "index.html#資料の特徴",
    "title": "Rによる計量政治学ノート",
    "section": "資料の特徴",
    "text": "資料の特徴\nこの資料は，第1章から順番に読んでいくことを想定して作成しています。 ただ，前に説明した内容であったとしても，その章の中で理論やプログラムの説明を繰り返すようにしています。 そのため，きちんと前から順番に学習している人にとっては冗長な記述になっています。"
  }
]