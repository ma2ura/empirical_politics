[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "計量会計学ノート",
    "section": "",
    "text": "はじめに\nこの本は、プレゼミのメインテキストである浅野・矢内 (2020)「Rによる計量政治学」の学習用ノートです。 あと、サブテキストであるウィラワン・勝又 (2023)「Rによるマーケティング・データ分析」の一部の内容も含まれています。 基本的に松浦が自分の勉強用に作成したノートのため、誤りや不備が含まれている可能性が高いです。 また、このノートは、浅野・矢内 (2020)やウィラワン・勝又 (2023)の内容を網羅しているわけではないので、このノートを使う場合は教科書を手元において、学習することをおすすめします。\nなぜ会計学を専門とする松浦のプレゼミで、メインの教科書が「Rによる計量政治学」なのかというと、このテキストが社会科学の一分野である政治学という経営学部生にとっても関連のある興味深い題材を用いて、計量経済学の基礎から応用までをRで実装するための知識を習得できるものだからです。\nとりわけ第1部の第2章「研究テーマの選び方」と第3章「理論と仮説」は、卒業論文を書く際にも非常に重要となる内容ですので、全経営学部生によんでもらいたい内容です。 第4章「Rの使い方」と第5章「Rによるデータ操作」は、本書の学習に必要な必要最小限の内容ですので、他の教科書やウェブサイトを参考にして、より詳細な内容を学習したほうが良いですが、この内容を理解し、使えるようになれば、MS Excelを使わずにRだけで分析できるようになるでしょう。\n第6章から第15章までが、統計学から計量経済学の内容となります。 おおよそ、代表的な統計量の計算や、グラフを使ったデータの理解、標本(sample)を用いた母集団(population)の推定や仮説検定、複数の統計量の関係性の理解、因果関係を分析する手法の1つである回帰分析の基礎と応用、2値選択の問題を推定するためのロジスティック関数の使い方などを学習します。\nここまでの内容の学習にプレゼミ15回のうちおおよそ11回を使います。 12回〜15回の4回は多変量解析手法として因子分析やクラスター分析、機械学習を用いた判別モデルとして決定木分析を学習します。 2年生終了時点で、ここまでの内容を修得していれば、卒業論文の分析に必要な知識はほぼ習得できていると考えて良いでしょう。あとは関心のある研究テーマを選ぶために、面白そうな専門演習(ゼミ)に入って、Rと統計学・計量経済学を使った実証研究を楽しんでくれれば、プレゼミの目標が達成されます。\nプレゼミのスケジュールはおおよそ以下の通りです。"
  },
  {
    "objectID": "index.html#補足",
    "href": "index.html#補足",
    "title": "計量会計学ノート",
    "section": "補足",
    "text": "補足\n本ノートは、Posit社(以前はRstudio社)が開発したQuartoというソフトウェアを使って作成されています。Quartoとは、RMarkdownの記法で書かれたテキストファイルを、knitrというソフトウェアを介して、HTMLやPDF、MS Word、EPUBなどのファイルを作成するためのソフトウェアです。\n最大の特徴は、MS ExcelとMS Wordのようにデータを分析する場所と文章を書く場所が別々ではなく、一つの画面の中でデータ分析とレポート・論文執筆を同時に行える、というものです。\nまた、Rだけでなく、PythonやJuliaといった他のプログラミング言語も文章内に埋め込むことができるため、データ分析と文章執筆を統合させる環境として非常に優れています。 プレゼミでも、Quartoを使って最終レポートの作成を行う予定です。 Quartoは今も開発が進んでいる新しいレポート作成ソフトウェアなので、情報が少ないことが難点ですが、公式サイトと私たちのRを見れば大抵のことは分かります。"
  },
  {
    "objectID": "Empoli_Chap01.html#会計を計量する",
    "href": "Empoli_Chap01.html#会計を計量する",
    "title": "1  計量会計学とは",
    "section": "1.1 会計を計量する？",
    "text": "1.1 会計を計量する？\nここでは、教科書「Rによる計量政治学」の内容を「会計学」に置き換えて考えてみます。 「計量会計学」という言葉は一般的ではなく、会計学の世界では「実証的会計研究」とか「実証会計」いう言葉が使われています。\n社会科学において、社会で生じる様々な現象（たとえば、経営現象や会計実務）を、数値化して分析することを計量化(quantification)と呼びます。計量化されたデータを用いて、社会現象を説明しようとするアプローチを計量分析(quantitative analysis)と呼びます。計量分析の手法は、統計学や計量経済学などの数理的な手法を用いて、社会現象を説明しようとするものです。\nざっくりいうと、会計とは経営活動から生み出される価値の変化を貨幣的に計測・記録し、その情報を整理し、集約することで、最終成果物として報告書(たとえば貸借対照表など)を作成し、それを利害関係者に報告することで、投資意思決定に役立つ情報を提供したり、利害関係者間の利害調整を行うことを目的とした一連のプロセスを意味します。 つまり会計そのものが、経営現象を計量化することを目的としていると言えます。\nこの会計を研究対象とした学問を会計学(accounting)といい、会計学の中でも、会計情報といった計量化されたデータを用いた研究を(狭義の)実証的会計研究(archival based empirical accounting research)とか、単に実証会計といいます1 。\n国際的に評価の高い会計学の学術誌である、The Accounting Review(TAR)、Journal of Accounting and Economics(JAE)、Journal of Accounting Research(JAR)、Review of Accounting Studies(RAST)、Contemporary Accounting Research(CAR)の五大誌に掲載されている論文の大部分が、会計情報を用いた計量分析となっています。"
  },
  {
    "objectID": "Empoli_Chap01.html#分析的会計研究と実証的会計研究",
    "href": "Empoli_Chap01.html#分析的会計研究と実証的会計研究",
    "title": "1  計量会計学とは",
    "section": "1.2 分析的会計研究と実証的会計研究",
    "text": "1.2 分析的会計研究と実証的会計研究\n会計研究の世界では、1960年頃までは規範的研究(normative research)という「〇〇するべき」という主張をする研究が主流でした。たとえば企業が保有する株式を時価評価すべきかとか、ある特徴をもつリース資産を購入したものとして扱うべきか、といったものです。\nしかし、1968年にJournal of Accounting Researchに掲載されたBall and Brown (1968) An Empirical Evaluation of Accounting Income Numbersを皮切りに、実際に会計情報は投資家の役に立っているのかをデータを使って確かめる、という、いわゆる実証研究が行われるようになり、今日まで会計研究の主要分野となっています。\n同じ事実解明型研究の中でも、証拠では無く論理による主張を目指す分析的会計研究は、そもそも要求される数学レベルも高く、また研究に要する時間も長いため、実証的会計研究に比べて研究者の数が少ないという特徴がありますが、理論と実証は研究の両輪をなすものであり、どちらも重要であることに違いはありません。 ただやはり難しい数式が出てくる会計研究は松浦には完全に理解することはできないので、ここでは実証的会計研究について考えていきます。ヴィトゲンシュタインの言葉を借りれば、語り得ないものは語らないということで、分析的会計研究は沈黙するべきでしょう。"
  },
  {
    "objectID": "Empoli_Chap01.html#footnotes",
    "href": "Empoli_Chap01.html#footnotes",
    "title": "1  計量会計学とは",
    "section": "",
    "text": "ちなみに(広義の)実証会計学(positive accounting thoery)は、事実解明的研究として、会計実務を説明し予想するための理論の構築を目指す学問を指す会計研究を意味します。いまはどうでも良いことです。\n他にも、数理モデルを用いた会計研究を分析的会計研究(analytical accounting research)、実験経済を用いた会計研究を(experimental accounting research)、行動科学の理論を用いた会計研究を(behavioral accounting research)といい、これらも広くは広義の実証会計となります。\nその他にも、簿記を研究対象とした簿記論、会計計算の仕組みを研究する計算構造研究、会計の歴史を研究する会計史など様々な研究分野があります。↩︎"
  },
  {
    "objectID": "Empoli_Chap02.html#リサーチクエスチョンの種類",
    "href": "Empoli_Chap02.html#リサーチクエスチョンの種類",
    "title": "2  研究テーマの選び方",
    "section": "2.1 リサーチ・クエスチョンの種類",
    "text": "2.1 リサーチ・クエスチョンの種類\nリサーチ・クエスチョン(research question)とは、研究対象となる会計に関する、抽象度の高い問いのことです。 リサーチ・クエスチョンが決まれば、その問いに答えるために、何をするべきなのかが決まるため、非常に重要な要素となります。 たとえば、\n\n会計情報の質が高いと、投資家の意思決定がよりよいものになるのか？\n大きな監査法人は、財務報告の質を高めているのか？\nCSR活動に積極的な会社は、納税も積極的か？\nのれんは償却するべきか？\nIFRS採用企業と非採用企業の違いはあるのか？\nコロナ禍における利益圧縮活動は行われたのか？\n\nこれらのリサーチ・クエスチョンを3つに分類してみましょう。\n\n2.1.1 実証的問題\n実証的問題では、事実を調べることが目的となります。 たとえば、「のれんの非償却はM&Aを促進させるのか」という問いに対しては、のれんの非償却を行っている企業と、行っていない企業のM&Aの実施率を比較することで、その問いに答えることができます。 実証的問題を扱う会計研究でも、定量的な研究だけでなく、インタビューによる定性的な研究もあります。参与観察研究はあまり見ません。 事実に注目する研究となるため、主観的な要素はできるだけ排して、観察されたデータや発言といった客観的なデータを用いることが多いです。\n\n\n2.1.2 規範的問題\nいわゆる「べき論」を扱う問題で、日本の会計研究では今でも盛んに行われている研究です。 たとえば、「のれんは償却すべきか」という問いに対しては、のれんの償却を行うことで、どのようなメリットがあるのか、どのようなデメリットがあるのかを考え、そのメリットとデメリットを比較することで、その問いに答えることができます。 ただ、この場合でも、「誰にとっての」メリットを重視するべきなのか、という問題がでますが、そこは研究者の価値判断によって決まることになり、研究者の主観が大きく反映されることになります。\nしたがって本教科書でも、規範的問題を実証的問題に変換する方法を考えます。\n\n\n2.1.3 分析的問題\n分析的問題は、まだ起こっていない、観察されていない現象を扱います。 そもそも起こっていない現象なのでデータも取りようがありません。 そこで、分析的問題では、モデル(model)を用いて、現象の起こりうるメカニズムを考えます。\n基本的には、関心のある問題を抽象化して数式で表現し、前提条件と仮定を設定し、その問題を解くことで得られた結果を解釈することで、その問いに答えることができます。 たとえば、税務会計や監査といった情報が入手困難な領域において、ゲーム理論や契約理論、最適化理論を用いた分析が行われることが多いような気がしますが、そこまで詳しくないです。"
  },
  {
    "objectID": "Empoli_Chap02.html#よい研究テーマの見つけ方",
    "href": "Empoli_Chap02.html#よい研究テーマの見つけ方",
    "title": "2  研究テーマの選び方",
    "section": "2.2 「よい研究テーマ」の見つけ方",
    "text": "2.2 「よい研究テーマ」の見つけ方\n政治学のMonroe (2000, pp.8–10)によると、\n\n明快さ\n検証可能性\n理論的重要性\n実用性\n独創性\n\nがよい研究テーマに必要な要素らしいです。 詳しくは教科書を読むとして、会計学や経営学でもほぼ同じですが、卒業論文においては、理論的重要性と独創性はあればよいですが、必ずしも必要ではありません。 なぜなら、理論的重要性を理解し、論文で示すことは、研究で用いる推論の背後にある理論や仕組みを完全に理解する必要がありますし、独創性を主張するためには、膨大な先行研究を読み、自分の主張が他の人とどう違うのか、どの点が新しいのかを明らかにする必要があり、とても時間がかかるからです。\nしたがって、明快な推論で導き出された仮説を、客観的なデータを用いて、適切な手法で分析し、その結果を解釈し、経営実務にどういう影響があるのか、を主張できれば、卒業論文としては申し分ないレベルです。\nとりわけ、このプレゼミでは、検証可能性を重視します。 そのレポート・論文を読めば、他の人でも同じ分析を行うことが可能であり、誰でも追試が行えることが重要です。 データの集め方や変数の作り方、データ分析のプロセスが明確にしめされており、それを自分でもすぐに再現することが重要です。そのためにRは非常に有効なツールとなります。\n\n2.2.1 規範的問題から実証的問題への変換\n「べき論」は研究者の価値判断が大きく反映され、その研究者が主張する価値は主観的なものになるため検証ができません。 そこで規範的問題を実証的問題になるように問い方を変える方法を考えます。\n\n2.2.1.1 参照枠組みを変える\n「会計は投資意思決定に役立つべきである」という問いは規範的問題で、それは「会計は株主のためのものである」という価値判断が含まれています。このままでは検証できないので、「会計は投資意思決定に役に立っているのか？」に変えることで、検証可能な問いになります。\n\n\n2.2.1.2 規範的問題の背後にある前提条件に注目する\n「会計は投資意思決定の役立つべきである」という規範的記述の背後には、\n\n会計は投資家のためのものである\n投資家が会計(情報)を使えば儲かる。\n投資家の投資が活発になれば、経済は活性化する。\n\nという前提条件があると考えられます。\nこれを実証的な問題にするには、\n\n会計(情報)の主な利用者は投資家なのか？\n会計情報を使えば儲かるのか？\n投資の役に立つ会計情報を提供することで、経済は活性化するのか？\n\n\n\n\n2.2.2 パズルを探す\nパズル(puzzle)とは、ある現象を説明するために、既存の理論では説明できない現象のことです。たとえば、配当パズル(dividend puzzle)とは、配当がなぜ存在するのか、という問題です。配当は、株主に対する利益配分の一つであり、株主にとっては配当が高いほうがよいはずです。しかし、実際には、配当が高いほど株価が低くなるという現象が観察されます。\n\n\n2.2.3 研究論文の構成\n論文の構成\n\nイントロダクション\n先行研究\n理論\n仮説\n対抗仮説\n作業化\n証拠\n結論"
  },
  {
    "objectID": "Empoli_Chap03.html#よい理論とは",
    "href": "Empoli_Chap03.html#よい理論とは",
    "title": "3  理論と仮説",
    "section": "3.1 「よい理論」とは？",
    "text": "3.1 「よい理論」とは？\n実証研究のリサーチ・デザイン(research design)のプロセスは次のような手順になります。\n\nパズルを見つける（簡単には見付からないです）\nパズルを説明するための複数の前提条件を使って理論を作る。（前提条件を自分で考えるのは難しすぎるので、先行研究を参考にすることが多いです。理論はパズルを説明するための仮説の集合体です。）\n理論から作業仮説(working hypothesis, hypothesis)を引き出す。\n作業仮説を検証するためのデータを集める。\nデータを使って作業仮説を検証し、理論の妥当性を確かめる。\n\n理想的にはこうなるでしょうが、現実にはこんなにうまくいきませんが、この講義では3〜5のプロセスを重視します。というのも、1と2のステップはかなり難しいので、現実には、\n\n興味のある経営現象を見つけて調べる。\n経営現象の発生を説明するための理論を見つけるために、先行研究を漁る。\n先行研究を参考にして作業仮説を作る。\n\nという風に行われることが多い（と思います。たぶん）\n\n3.1.1 因果法則の3つの条件\n因果関係(causality)と相関関係(correlation)の違いを理解しておきましょう。\n因果関係は、近年の社会科学領域の研究で最も注目されているキーワードでしょう。 もともと因果関係を特定し、推定する研究は数多く行われてきましたが、近年になって発達した計量経済学や実験経済学の手法を使って、より厳密に因果関係を特定しようとする研究が増え、因果関係を適切に特定することの重要性が認識されるようになりました。\n例えば、こんな本が近年出版されています。\n\n\n\n\n\n\n因果推論入門：基礎から現代的アプローチまで\n\n\n\n\n\n\n\n統計的因果推論の理論と実装\n\n\n\n\n\n\n\n効果検証入門\n\n\n\n\n\n因果関係とは、原因(causal)と結果(outcome)の関係のことです。正確に言うと、ある要因Xを操作するとき、別の要因Yが変化することです(Imbens and Rubin, 2015, p.4)。\n因果関係を考える際には、「効果をもたらした原因」(causal of effect)と「原因のもたらす効果」(effect of cause)の両方を考える必要があります。 例えば、ある企業が従業員の給料を上げたとします。 このとき、従業員の給料が上がったことが「効果をもたらした原因」であり、従業員の給料が上がったことによって、従業員のモチベーションが上がったことが「原因のもたらす効果」です。 定量的な研究では、「原因のもたらす効果」を分析することが多いです。\n因果関係があると考えるためには、3つの条件を確かめる必要があります。\n\n原因が結果より先に起こる。\n原因と結果が共変する。\n原因以外の重要な要因が変化しない。\n\nこの因果関係を記述するものを理論といいます。\n\n\n3.1.2 理論とは\n理論とは「原因と結果について一般的な論述」で、「〇〇であるとき、△△が起こる」というようなものです。推論といってもよいです。 原因と結果の関係を「説明変数X」(explanatory variable)と「応答変数Y」(response variable)の関係として表現します。\n\nX \\Longrightarrow Y\n\n推論を作る際には，どれだけ説得力があり納得できる仮定を設定するかが重要となります。仮定のない推論など役に立たないからです。 経営学は独自の理論をもたない学問とも言われ，とりわけ会計学における事実解明的研究(positive research)では，心理学や経済学で蓄積された理論を借用することが多いです（松浦は経済学に基づく推論を行っています）。\n\n\n3.1.3 良い理論とは？\n良い理論・推論が持つべき性質は次のようなものです。\n\n反証可能であること\n観察可能な予測が多いこと\n具体的であること\nシンプルであること\n\n以下ではそれぞれについて簡単に説明します。\n\n反証可能であること\n「反証可能性」(falsifiability)という科学で最も重要な特性の1つを確保する必要があります 1 。\nつまり，論文を読んだ人ならだれでも，「この理論は間違っている」ということを示すことができるようにする必要があります。 反証可能性がない主張は占いと変わりません。\n\n\n観察可能な予測が多いこと\n結果として発生する現象が観察可能である予測を行う必要があることを示しています。 当然ですが，自分の主張を証拠を用いて説得力を高めようとしているのですから，その予測が当たっているのかどうかを確認できる必要があります。\n\n\n具体的であること\n「業績が悪くなる」のようにあいまいな表現ではなく，「昨年度と比べて利益が減少する」とか「累積リターンがマイナスになる」といったように，具体的な予測を行う必要があります。「リスク」とか「パフォーマンス」とか「悪くなる」とか「加速する」といったあいまいな言葉は常に定義してから使うようにしましょう。\n\n\nシンプルであること\n理論はシンプルでなければなりません。 理解しやすく，使える範囲が広く，反証可能性が高い理論は，シンプルになっていきます。\n基本的には，先行研究で使われている理論を援用することが多い経営学・会計学では，先行研究で用いられた理論や推論に無駄がないかどうか，よりシンプルにいえないかどうか，を考えることが多いです。\n理論をシンプルにするには，前提となる条件を少なくする必要があります。 観察された経営現象をそのまま記述しようとすると非常に長く，複雑な文章になるでしょう。 それでは何が本質的に重要か分からないので，経営現象を抽象化・単純化することで，本質以外のものをそぎ落とし，理論をシンプルにすることがで，経営現象への理解がより深まります(オッカムの剃刀)。"
  },
  {
    "objectID": "Empoli_Chap03.html#仮説と仮説検証",
    "href": "Empoli_Chap03.html#仮説と仮説検証",
    "title": "3  理論と仮説",
    "section": "3.2 仮説と仮説検証",
    "text": "3.2 仮説と仮説検証\n\n3.2.1 仮説とは\n科学的には，「理論」と「仮説」とは同じものです。 反証されずに生き残った理論を仮説(hypothesis)と呼びます。 たとえば、ニュートンの万有引力の法則は，現在でも仮説として使われています。\nこの「仮説」をより具体的にしたものを「作業仮説」(working hypothesis)と呼びます。\n\n作業仮説とは，自分が使える特定の変数についての記述\n「もしこの仮説が正しければ・・・のはず」\n理論より作業仮説の方が具体的である\n仮説から引き出される観察可能な予測について述べる\n\n\n\n3.2.2 作業仮説\nたとえば「監査の質が高いほど，財務報告の質が高くなる」という理論から，作業仮説を引き出してみましょう。 この文章の中で，\n\n監査の質\n高い\n財務報告の質\n高い\n\nという4つの用語を，測定可能な尺度にして，その高低を定義する必要があります。\nたとえば，監査の質を「監査報酬額」で測定して，財務報告の質を利益操作の程度で測定するとします。利益操作の程度を異常アクルーアルで代理すると\n\n監査報酬が、同業他社平均より高い企業ほど，異常アクルーアルの絶対値が小さい\n\nという作業仮説を立てることができます。"
  },
  {
    "objectID": "Empoli_Chap03.html#footnotes",
    "href": "Empoli_Chap03.html#footnotes",
    "title": "3  理論と仮説",
    "section": "",
    "text": "「反証不可能な理論は科学ではない」といったのは，科学哲学者カール・ポパー(Karl Popper)です。 Popper (1959) The Logic of Scientific Discovery, London: Hutchinson.（邦訳：ポパー（1971）『科学的発見の論理 上下巻』，恒星社厚生閣）↩︎"
  },
  {
    "objectID": "Empoli_Chap04.html#rとrstudio",
    "href": "Empoli_Chap04.html#rとrstudio",
    "title": "4  Rの使い方",
    "section": "4.1 RとRstudio",
    "text": "4.1 RとRstudio\n教科書を見ながらRとRstduioを自分PCにインストールしてください。 以下のウェブサイトが超参考になります。 自分のPCのOSに応じて、資料を見ながらインストールしてください。\n矢内先生のウェブサイト\nあるいは、Posit Cloudを使ってウェブ上でRstudioを使えるようにしてください。"
  },
  {
    "objectID": "Empoli_Chap04.html#visual-studio-codeの使い方",
    "href": "Empoli_Chap04.html#visual-studio-codeの使い方",
    "title": "4  Rの使い方",
    "section": "4.2 Visual Studio Codeの使い方",
    "text": "4.2 Visual Studio Codeの使い方\n教科書では、Posit社のRstudioの説明をしていますが、RstudioはR専用のIDE（統合開発環境）で、R以外の言語を書くことはできませんし、少々重たいです。 そこでここでは、Microsoft社のVisual Studio Codeを使ってRを書く方法を説明します。\nマイクロソフト社のウェブサイトから、自分のPCのOSに合わせて、Visual Studio Codeをインストールしてください。\nまずGoogle等で「Visual Studio Code」と検索して、オフィシャルサイトにアクセスします。\n\n\n\nVisual Studio Codeのオフィシャルサイト\n\n\nそして、「Visual Studio Codeをダウンロードする」をクリックすると、次のページにいきます。\n\n\n\nVisual Studio Codeのダウンロードページ\n\n\nここから自分に合ったOSを選んで、ダウンロードしてください。 詳しい人なら、下の小さな項目から、適切なものをえらんでください。 MacBookでM2チップを使っている人は、MacのApple siliconのzipをダウンロードして、Zipファイルを展開してインストールしてください。\n\n4.2.1 Quarto\n次に、RstudioやVisual Studio Codeで、レポートや論文を書くためのパッケージであるQuartoをインストールします。 QuartoはRstudioを作ったPosit社が開発している文書作成システムなので、Rとの相性もばっちりです。\nまずGoogle等で「Quarto」と検索して、オフィシャルサイトにアクセスします。\n\n\n\nQuartoのオフィシャルサイト\n\n\nそして、「Get Started」をクリックすると、次のページにいきます。\n\n\n\nQuartoのダウンロードページ\n\n\nここから自分に合ったOSを選んで、ダウンロードしてください。\nここまでで、\n\nR (本体)\nRstudio (R用IDE)\nVisual Studio Code (R以外の言語も書けるIDE)\nQuarto (レポートや論文を書くためのパッケージ)\n\nのインストールが完了しました。 次に、Visual Studio CodeでRのソースコードを書くための準備をします。\n\n\n4.2.2 VS Codeの準備\nVisual Studio Code(以下、VS Code)の準備をします。 VS Codeを開くと、次のような画面が表示されます。 VS Codeは、機能を拡張するために、拡張パッケージをインストールすることができます。 VS Codeを起動して、左のメニューの中の、四角が4つ並んだアイコンをクリックしてください。\n\n\n\nVS Codeの初期画面\n\n\nVS Codeの左のメニュー上部に拡張パッケージの検索画面が表示されます。 そこに拡張パッケージの名前を入れて、必要なものをインストールしていきます。 以下の拡張パッケージは、Rの分析をするために必要あるいは推奨されるものです。\n\nJapanese Language Pack for Visual Studio Code : VS Codeの日本語化\nR : とりあえず入れておく\nQuarto : Quartoを使うために必要\n\nとりあえずこの3つを入れておけば、このプレゼミでは十分です。\n\n\n\nVS Codeの拡張パッケージ\n\n\n\n\n4.2.3 フォルダを開く\nVS Codeでは、分析に使うCSVファイルや、分析のためのRファイル、レポートや論文を書くためのQuartoファイルを、一つのフォルダにまとめておくと便利です。 分かりやすい場所にフォルダを作成し、好きな名前をつけてください。\nVS Codeの上部メニューの中の「ファイル」をクリックして、「フォルダーを開く」をクリックして、先ほど作成したフォルダを選択してください。 すると、左のメニューにフォルダの中身が表示されます。まだ何も入っていなければ、何も表示されません。\nVS Codeではフォルダを指定して開いておくと、そこが作業フォルダとなり、Rは常にそのフォルダの中を参照するようになります。\n\n\n4.2.4 Rスクリプトの書き方\nではVS Code上でRのソースコードを書いてみましょう。 新しいファイルを作成するためには、上のメニューから「ファイル」をクリックして、「新しいファイル」をクリックしてください。\nするとメニューが表示されその中に「R Document」を選ぶと、Rのソースコードを書くためのファイルが作成されます。 Rのソースコードは拡張子が.rというファイルになります。 拡張子が何か分からないひとは、ググっておいてください。 WindowsやMacOSでもファイルの拡張子が表示されるように設定しておいてください。"
  },
  {
    "objectID": "Empoli_Chap04.html#rの基本操作",
    "href": "Empoli_Chap04.html#rの基本操作",
    "title": "4  Rの使い方",
    "section": "4.3 Rの基本操作",
    "text": "4.3 Rの基本操作\nここまでの準備が出来ていれば、画面にRのソースコードを書くためのファイルが表示されているはずです。 何も書かれていないので、まずは何か書いてみましょう。 まずは、1+2を計算してみます。\n\n1 + 2\n\nと書いて、その行にカーソルがある状態で、Ctrl + Enterを押すと、その行の計算結果が表示されます。\n\n\n[1] 3\n\n\nあとは教科書をみて、練習しておいてください。 以下の事ができるようになっていればOKです。\n\n四則演算\nsqrt()関数で平方根の計算\nc()関数でベクトルの作成\nmean()関数で平均を計算\nseq()関数で数列の作成"
  },
  {
    "objectID": "Empoli_Chap04.html#パッケージ",
    "href": "Empoli_Chap04.html#パッケージ",
    "title": "4  Rの使い方",
    "section": "4.4 パッケージ",
    "text": "4.4 パッケージ\nRはパッケージを使って機能を拡張することができます。\n\ninstall.packages()関数でパッケージをインストールして、\nlibrary()関数でパッケージを読み込むと、\n\n拡張した機能を使えるようになります。 教科書やこの資料で使う関数はたくさんあるので、その都度説明しますが、ほぼ必ずつかうのが、tidyverseというパッケージ群です。\n以下のコードを実行して、tidyverseをインストールしてください。\n\ninstall.packages(\"tidyverse\") # 最初の一回だけ実行\n\nそして、ほぼ毎回以下のコードを実行して、tidyverseを読み込みます。\n\nlibrary(tidyverse)\n\nついでに、今後使うであろう次のパッケージもインストールしておいてください。\n\ninstall.packages(\"bloom\") # 結果の整形\ninstall.packages(\"ggthemes\") # グラフの見た目\ninstall.packages(\"modelsummary\") # 回帰結果の作表\ninstall.packages(\"kableExtra\") # 表の整形\ninstall.packages(\"gt\") # 表の整形\ninstall.packages(\"patchwork\") # グラフを並べて表示\n\n\n4.4.1 Githubとの連携\nGitHubは、Gitというバージョン管理システムを使って、ソースコードのバージョン管理をクラウド上で行うことができる無料サービスです。 使いこなすには、少々勉強が必要ですが、使えれば非常に有用なので、是非やってみてください。 VS CodeはGit/GitHubとの連携も簡単なので、複数人でウェブ開発やプログラミングをする場合には、非常に有益です。\nまずは、GitHubのウェブサイトにアクセスし、アカウントを作成してください。\nGitHub\nそこから先は、書籍やウェブサイトを参考にしてください。 例えばこんな本が便利です。\n\n\n\n\n\n\nGitHubのオススメ本\n\n\n\n\n\n\n\nはじめてでもできるGitとGitHubの教科書\n\n\n\n\n\n\n\nわかばちゃんと学ぶGit使い方入門\n\n\n\n\n\n\n\n4.4.2 GitHub Copilotを使う\nGitHub Copilotは、AIがコードの作成を支援してくれる超便利なツールです。 学生は無料で利用できるので、プログラミングを学習しようとしている人は、導入の検討をしてみてください。\nGitHub Copilot"
  },
  {
    "objectID": "Empoli_Chap04.html#まとめ",
    "href": "Empoli_Chap04.html#まとめ",
    "title": "4  Rの使い方",
    "section": "4.5 まとめ",
    "text": "4.5 まとめ\nここでは、\n\nRのインストール\nRstudioのインストール\nVS Codeのインストール\nQuartoのインストール\n\nを行い、VS Code上での分析・レポート作成環境を整えました。 また、ソースコードの書き方や、パッケージのインストール方法、GitHubとの連携方法を学び、GitHub Copilotの紹介をしました。"
  },
  {
    "objectID": "Empoli_Chap05.html#データの読み込み",
    "href": "Empoli_Chap05.html#データの読み込み",
    "title": "5  Rによるデータ操作",
    "section": "5.1 データの読み込み",
    "text": "5.1 データの読み込み\n\n5.1.1 CSVファイルの読み込み\n多くのプログラミング言語で、読み込むデータとして最も多いのが、CSV形式のファイルです。ファイルの拡張子は.csvです。 CSVとは、Comma Separated Valuesの略で、カンマで区切られたデータのことです。 次のような形をしています。\n企業ID,決算年月,売上高\n13,2020/03,1000\n13,2021/03,1200\n13,2022/03,1500\n24,2020/03,2000\n24,2021/03,2200\n24,2022/03,2500\n33,2020/03,3000\n33,2021/03,3200\n33,2022/03,3500\nこのように、値とコンマ,のみで構成されたファイルのため、余計な情報が入っておらず、またファイルサイズも小さく、加工が簡単なので、データのやり取りによく使われます。\nではファイルを読み込んでみます。ここでは、松浦のウェブサイトにあるデータkeshohin_2023.csvを読み込んでみます。 Rの場合は、read.csvという関数を使って、URLを直接指定して読み込むことができます。読み込んだデータをdfという変数に代入しています。\nExcelの場合は、インターネット上のデータを直接取り込むことは難しいので、いったんパソコンの中に保存してから、ファイルを開くとします。\n\n\n\n\n\n\nRの場合\n\n\n\n\ndf &lt;- read.csv(\"https://so-ichi.com/kesho_2023.csv\")\n\n\n\n\n\n\n\n\n\nMS Excelの場合\n\n\n\n\nURLhttps://so-ichi.com/kesho_2023.csvをブラウザに入力してファイルをダウンロードし、任意の場所に保存\n「ファイル」から「開く…」をクリックして、保存したCSVファイルを選択し「開く」をクリック\n\n\n\n\n\n5.1.2 Excelファイルの読み込み\nMS Excelのファイルは拡張子が.xlsx、古いMS Excelだと.xlsです。 RでExcelファイルを読み込むときは、read_excelという関数を使います。 Excelファイルを用意するのが面倒なので、ここではこうやれば読み込めるよ、というコードだけ説明します。ファイル名はhoge.xlsxとします。\n\n\n\n\n\n\nRの場合\n\n\n\n\ndfx &lt;- readxl::read_excel(\"hoge.xlsx\")\n\n\n\n\n\n\n\n\n\nMS Excelの場合\n\n\n\n\n「ファイル」から「開く…」をクリックし、保存してあるExcelファイルを選択し「開く」をクリック\n\n\n\nMS Excelの問題点は、目的のデータがどのExcelファイルに入っていて、それがどこに保存されているのかを覚えておかないと、いちいちファイルを開いて探さないといけないことです。\nRだとソースコードを残すことができますので、 どこにあるファイルを読み込んで、そこに何が入っているのかをコメントで残しておくことができます。"
  },
  {
    "objectID": "Empoli_Chap05.html#読み込んだデータの確認",
    "href": "Empoli_Chap05.html#読み込んだデータの確認",
    "title": "5  Rによるデータ操作",
    "section": "5.2 読み込んだデータの確認",
    "text": "5.2 読み込んだデータの確認\nMS Excelは読み込んだデータが画面上に表として表示されていますが、Rでは変数に代入しただけでは、画面には何も表示されません。 そこでデータの中身を確認する関数として、次のようなものがあります。\n\nhead() : 最初の数行を表示させる基本関数\nstr() : データの構造を表示させる基本関数\nglimpse() : データの構造を表示させるdplyrパッケージの関数\nnames() : 変数名を表示させる基本関数\n\nこれらを使って、データの中身を確認し、データの形に適した処理方法を学ぶ必要があります。 以下では、head()関数を使って、データの最初の数行を表示させてから、str()関数でデータの中の変数とその型を確認します。\nExcelは目視が中心ですが、見ただけでは、文字列なのか数なのかが分からないので、やはりデータの型は確認する必要があります。\n\n\n\n\n\n\nRの場合\n\n\n\n\nhead(df)\n\n  code   name    term shubetsu ren  sales netincome month\n1  641 資生堂 1985/11       10   1 371040     14526    12\n2  641 資生堂 1986/11       10   1 375294     13632    12\n3  641 資生堂 1987/11       10   1 378977      9014    12\n4  641 資生堂 1988/11       10   1 401311      9515    12\n5  641 資生堂 1989/03       10   1 130654      4265     4\n6  641 資生堂 1990/03       10   1 456352     11362    12\n\nstr(df)\n\n'data.frame':   130 obs. of  8 variables:\n $ code     : int  641 641 641 641 641 641 641 641 641 641 ...\n $ name     : chr  \"資生堂\" \"資生堂\" \"資生堂\" \"資生堂\" ...\n $ term     : chr  \"1985/11\" \"1986/11\" \"1987/11\" \"1988/11\" ...\n $ shubetsu : int  10 10 10 10 10 10 10 10 10 10 ...\n $ ren      : int  1 1 1 1 1 1 1 1 1 1 ...\n $ sales    : int  371040 375294 378977 401311 130654 456352 517252 553299 561549 549178 ...\n $ netincome: int  14526 13632 9014 9515 4265 11362 15850 16011 13290 14668 ...\n $ month    : int  12 12 12 12 4 12 12 12 12 12 ...\n\n\n\n\n\n\n\n\n\n\nMS Excelの場合\n\n\n\n画面を見て確認する。\n\n\nこのデータには，\n\ncode : 企業コード (文字列)\nname : 企業名 (文字列)\nterm : 決算年月 (文字列)\nshubetsu : 会計基準の種類 (数値)\nren : 連結か単体 (数値)\nsales : 売上高 (数値)\nnetincome : 当期純利益 (数値)\nmonth : 決算月数 (数値)\n\nが入っています。"
  },
  {
    "objectID": "Empoli_Chap05.html#データの整形",
    "href": "Empoli_Chap05.html#データの整形",
    "title": "5  Rによるデータ操作",
    "section": "5.3 データの整形",
    "text": "5.3 データの整形\n\n5.3.1 データ操作の基礎\nさあ面白くなってきました。 次はデータを操作していきます。 Rによるデータ操作では、tidyverseパッケージ群のdplyrパッケージが大活躍します。\ndplyrパッケージの関数の中でもよく使うものに次のようなものがあります。\n\nselect() : 変数を選択する\nfilter() : データを抽出する\nmutate() : 変数を追加する\narrange() : データを並び替える\nsummarise() : データを集計する\ngroup_by() : データをグループ化する\n\n\n\n5.3.2 パイプ演算子\nRでソースコードを書く際に，理解しやすく，読みやすいコードにするために非常に便利なのが，パイプ演算子%&gt;%です。 パイプ演算子%&gt;%は，左側のオブジェクトを右側の関数の第一引数に渡すという処理を行います。 たとえば，\n\n(1 + 2) %&gt;% sqrt()\n\n[1] 1.732051\n\n\nと書くと，sqrt(1 + 2)と同じ意味になります。 たとえば，rnorm()関数を使って平均0，分散1の標準正規分から100個のデータを作りたいとします。 rnorm()関数は3つの引数を取ります。\n\nデータの個数\n平均\n標準偏差\n\nしたがって，rnorm(100, 0, 1)と書くと，平均0，分散1の標準正規分布から100個のデータを取り出すことができます。 パイプ演算子を使うと，\n\n100 %&gt;% rnorm(mean = 0, sd = 1)\n\n  [1]  0.99381303 -1.33039811  1.78117772 -0.34963590  0.02521636  0.72129978\n  [7]  0.86483979  0.60074455  0.85920662 -0.78333360 -0.39274906  1.19674851\n [13]  0.53410003  0.56703927  0.79005658  1.27358218  0.44260278 -0.64154489\n [19] -0.76959178 -0.01705219 -0.58437223 -1.63532183  0.88747971 -0.95351106\n [25] -1.13385599 -0.63992627 -1.17798623  0.15423155  0.39901398  0.27781907\n [31] -0.14171806  0.19962074  0.27180366 -0.44329049 -0.42202544  0.21974627\n [37] -0.56123070  0.46834311 -0.85663813  0.65845819 -1.55541173 -1.32647738\n [43] -0.04262920  1.47206554 -0.06861347  0.75058857  0.70516097  0.78838248\n [49]  0.73961983  0.63695151 -1.64559745 -0.23472722  0.92699219 -1.85317275\n [55]  0.09839735 -1.16002154 -0.64865102 -0.42385587 -0.78142910  0.34368795\n [61]  1.30868153 -1.97291940  1.47952280  0.51095439  0.50984086  1.06615248\n [67] -1.20099457 -0.12488484  0.24156175 -0.42089663  0.34101585 -0.25616294\n [73]  0.79220060 -0.34352332 -1.25965992  1.11426468 -0.01672348  0.38899700\n [79] -1.28831818  1.74600606  1.16740268 -1.04183152 -1.06975069 -1.43000032\n [85] -0.31678783 -1.18865499  0.02080780 -0.66975991 -1.51051703 -0.11789531\n [91] -1.89445661 -0.49512388  0.16839982 -2.22790551 -0.23057759  1.11639360\n [97]  0.96973948  0.70185786  1.54967386  0.57537626\n\n\nとなります。 これはrnorm()関数の第1引数がデータの個数なので，そこに100を渡しています。 ここで平均に値を渡したい場合を考えます。 mean引数は第2引数なので，パイプ演算子では自動で渡してくれません。 そこで.を使って渡す場所を指定してあげます。\n\n100 %&gt;% rnorm(100, mean =. , sd = 1)\n\n  [1] 101.44097  99.85024  97.43629  98.62465  99.90141 101.89854 100.56534\n  [8] 100.80197  99.90028  99.79917 100.26921 100.35974 100.30369  98.58007\n [15] 100.13741  99.07002  99.75241 100.85545 100.27762 100.90648  99.39857\n [22]  99.35532 100.94314  98.77454 100.81059  99.52137 100.89512 100.62522\n [29] 100.17931  98.57319  99.20871  99.29915 100.76645 100.35995  99.15681\n [36]  99.90999 101.38957  99.45883  99.50810  97.97256 100.35518  99.56831\n [43] 100.98350 102.10325 100.54162  99.78341 100.07026  97.83781  99.93081\n [50] 100.75789  99.85187  98.37386 100.03161  98.75249 100.53391 101.76515\n [57] 100.85319 100.79691 100.16250  98.75819  99.34431  98.91231 100.32073\n [64]  99.58538  98.62320 100.64078  99.94143 100.17683  99.44174  99.58779\n [71] 100.34606  99.66412  99.47078  99.56342 100.97405  99.19213  99.82564\n [78] 100.17977  99.42296 101.10596  99.07741 100.01268 102.55369  99.89136\n [85] 100.23009  99.74540 100.22883  99.66183  99.50982  97.98906 101.01352\n [92] 100.10207  98.94873  99.60225  98.96377  99.85626  99.61421  99.86238\n [99] 100.07741 102.41161\n\n\nこれで平均100，標準偏差1の正規分布から100個のデータを取り出せました。\nこれだけだとパイプ演算子%&gt;%の便利さが伝わらないので，たとえば次のような処理を考えてみましょう。\n\n2020年のデータを抜き出し，\n売上高当期純利益率を計算し，\n産業グループごとに平均を計算する\n利益率が高い順番に並び替える\n\nをパイプ演算子を使って書くと，\n\ndf &lt;- df %&gt;%\n    filter(term == \"2020\") %&gt;% # 2020年のみ\n    mutate( # 新しい変数を作成\n        ratio = netincome / sales # 売上高利益率\n        ) %&gt;%\n    group_by(sangyo) %&gt;% # 産業グループごとに\n    summarise( # 平均を計算\n        mean_ratio = mean(ratio) # 利益率の平均\n        ) %&gt;%\n    arrange(desc(mean_ratio)) # 利益率の高い順に並び替え\n\nのように，上から順番に処理を実行し，次に渡す，というプロセスが分かりやすく，読みやすいコードができました。 コメントも残しておけば，後から見返したときにも分かりやすいですし，他人によんでもらうときも親切ですね。 したがって，以下ではパイプ演算子を駆使して，データ操作を行っていきます。\n\n\n新しい変数を作成する mutate\n新しい変数を作成するには，dplyrパッケージのmutate()関数を使います。 先ほど読みこんだデータから，当期純利益を売上高で除して売上高当期純利益率を計算して，ratioという変数を作ってみましょう。\n\n\n\n\n\n\nRの場合\n\n\n\n\ndf &lt;- df %&gt;%\n    mutate( # 新しい変数を作成\n        ratio = netincome / sales # 売上高利益率\n        )\n\n\n\n\n\n\n\n\n\nMS Excelの場合\n\n\n\nI1のセルに変数名を表すratioと入力する。 F列のsaleとG列のnetincomeを使って，I2のセルに\n= G2 / F2\nとし，I2セルの右下の四角をダブルクリックすると，自動で下のセルにも同じ計算がコピーされる。\n\n\n次に，ある変数の値に応じて異なる値をとる変数を作るには，mutate()関数とifelse()関数を同時に使います。ifelse()関数は次のような引数を取ります。\n\nifelse(条件, 条件が真のときの値, 条件が偽のときの値)\n\n先ほど計算した売上高当期純利益率が5%以上ならば「高い」，そうでなければ「低い」という変数highlowを作ってみましょう。\n\n\n\n\n\n\nRの場合\n\n\n\n\ndf &lt;- df %&gt;%\n    mutate( # 新しい変数を作成\n        highlow = ifelse(ratio &gt;= 0.05, \"高い\", \"低い\") # 売上高利益率\n        )\n\n\n\n\n\n\n\n\n\nMS Excelの場合\n\n\n\nJ1セルにhighlowと入力する。 J2セルに\n= if(I2 &gt;= 0.05, \"高い\", \"低い\")\nと入力し，J2セルの右下の四角をダブルクリックすると，自動で下のセルにも同じ計算がコピーされる。\n\n\nExcelだとセルの移動や変数名の入力，計算式の入力，セルのコピーといった作業で，キーボードとマウスを行ったり来たりする必要があり，若干面倒です。\nついでに，mutate()関数を使って，長すぎる企業名を短くしてみます。 ここでは「ポーラ・オルビスホールディングス」を「ポーラ」と略してみます。 mutate()とifelseを使って，name変数の値が「ポーラ・オルビスホールディング」ならば「ポーラ」という値をとる変数name上書きします。を作ってみましょう。\n\n\n\n\n\n\nRの場合\n\n\n\n\ndf &lt;- df %&gt;%\n    mutate( # 新しい変数を作成\n        name = ifelse(\n            name == \"ポーラ・オルビスホールディング\", \"ポーラ\", name) # 企業名\n        )\n\n\n\n\n\nデータを抽出する filter\nデータを抽出するには，dplyrパッケージのfilter()関数を使います。 filter()関数は，次のような引数を取ります。\n\nfilter(データ, 条件)\n\n先ほど作成したratio2が「高い」企業だけを抽出してみましょう。 filter()関数の中の条件は，==を使って，\"高い\"という文字列と一致するかどうかを確認しています。 ここでは，highlow変数の値が\"高い\"と一致する企業だけを抽出し，df_highという変数に代入しています。\n\n\n\n\n\n\nRの場合\n\n\n\n\ndf_high &lt;- df %&gt;%\n    filter(highlow == \"高い\") # 条件\n\n\n\n\n\n\n\n\n\nMS Excelの場合\n\n\n\nhighlow変数のあるJ列をクリックして枠を移動させ，上の「ホーム」メニューから「並び替えとフィルター」をクリックし，「フィルター」をクリックする。 すると，変数名highlowのヨコに漏斗のようなマークが出るので，それをクリックすると，記録されたデータの種類が出てくるので，「高い」だけにチェックが入った状態にする。\n\n\nExcelのクリック回数が増えてきましたね。\nfilter()関数の中で指定する条件は，\n\n== : 一致する\n!= : 一致しない\n&gt;=や&lt;= : 以上や以下\n&gt;や&lt; : より大きいや小さい\n%in% : いずれかに一致する\n\nなどがあります。またこれらの条件を組み合わせることもできます。 その場合は，以下のように&や|を使います。\n\n& : かつ\n| : または\n\nたとえば，資生堂と花王を抽出したり，売上高当期純利益率が5%以上かつ売上高が1000億円以上の企業を抽出するには， 次のように書きます。\n\n\n\n\n\n\nRの場合\n\n\n\n\ndf_shiseido_kao &lt;- df %&gt;%\n    filter(name %in% c(\"資生堂\", \"花王\")) # 2社だけ抽出\ndf_high2 &lt;- df %&gt;%\n    filter(ratio &gt;= 0.05 & sales &gt;= 1000) # 2条件を同時に満たす\n\n\n\n\n\n変数を選択する select\nデータの中から必要な変数だけを選択するには，dplyrパッケージのselect()関数を使います。 たとえば，先ほど作成したdfから，企業コード，企業名，売上高当期純利益率の3つの変数だけを選択してみましょう。\n\n\n\n\n\n\nRの場合\n\n\n\n\ndf3 &lt;- df %&gt;%\n    select(code, name, ratio) # 3つの変数だけ選択\n\n\n\n\n\n\n\n\n\nMS Excelの場合\n\n\n\nオリジナルのデータをコピーして，下のタブから別のシートを選択し，そこに貼り付ける。\n貼り付けたデータからcodeとnameとratio以外の列を削除する。\n\n\nMS Excelだと，不要なデータを削除するのが怖い作業で，必要になったときにまた元のデータを読み込まないといけないので，面倒ですし，ミスのもとです。\nselect()関数の中で使えるものには，以下のようなものがあります。 とても便利なので，覚えておくとよいでしょう。\n\n- : 除外する (-ratioとかくとratio以外を選択)\n: : 連続する変数を選択 (code:renと書くとcodeからrenまでを選択)\nstarts_with() : ある文字列で始まる変数を選択\nends_with() : ある文字列で終わる変数を選択\n\nたとえば，mutate()で新しい変数を作る場合に，変数名に法則性をつけておけば，starts_with()を使って一気に変数を選択することができます。 たとえば，比率を表す変数はratioで始まるように統一しておく，基準化した変数には_Kを最後に付けておく，などです。\n\n\nデータを並び替える arrange\nデータを並び替えるには，dplyrパッケージのarrange()関数を使います。 たとえば，先ほど作成したdfから，売上高当期純利益率を並び替えてみましょう。\n\n\n\n\n\n\nRの場合\n\n\n\n\ndf %&gt;%\n    select(name, ratio) %&gt;% # 2つの変数だけ選択\n    arrange(ratio) %&gt;%\n    head()\n\n    name       ratio\n1 ポーラ -0.43495809\n2 資生堂 -0.07576384\n3 資生堂 -0.03859062\n4 資生堂 -0.02166802\n5 資生堂 -0.01384122\n6 資生堂 -0.01266169\n\n\n\n\n小さい順に並び替えられました。 大きい順にするには，desc()関数を使います。 ついでにknitrパッケージのkabble()関数で表を見やすく加工してみます。\n\n\n\n\n\n\nRの場合\n\n\n\n\ndf %&gt;%\n    select(name, ratio) %&gt;% # 2つの変数だけ選択\n    arrange(desc(ratio)) %&gt;%\n    head(10) %&gt;% # 先頭の10行\n    knitr::kable(booktabs = TRUE) # 表をきれいに表示\n\n\n\n\nname\nratio\n\n\n\n\nポーラ\n0.1110647\n\n\n花王\n0.1019213\n\n\n花王\n0.0987028\n\n\n花王\n0.0986613\n\n\nユニ・チャーム\n0.0929384\n\n\n花王\n0.0912752\n\n\nポーラ\n0.0895507\n\n\nユニ・チャーム\n0.0891383\n\n\nユニ・チャーム\n0.0890311\n\n\nユニ・チャーム\n0.0869777\n\n\n\n\n\n\n\nこれでどの企業のどの年度の売上高当期純利益率が大きいのかが一目瞭然になりました。\nMS Excelだと，\n\n\n\n\n\n\nMS Excelの場合\n\n\n\n「ホーム」メニューから「並び替えとフィルター」をクリックし，「昇順」をクリックする。\n必要なデータだけ選択してコピペすれば，表が完成します。\n\n\nとなります。 簡単ですが，MS Excelの並び替えは注意が必要で，並び替えた後にデータを追加すると，並び替えが解除されてしまい，元に戻せなくなったり，空列があると並び替えがうまくいかなかったりします。\n\n\n5.3.3 long形式とwide形式\n人間には読みやすいけれどパソコンは読みにくい，というデータの形式があります。 例えば下の表を見てみましょう。\n\n\n\n地点\n6時\n12時\n18時\n\n\n\n\n札幌\n12℃\n15℃\n13℃\n\n\n大阪\n20℃\n24℃\n22℃\n\n\n福岡\n23℃\n25℃\n25℃\n\n\n\nこのような形のデータをワイド形式(wide)といいます。 天気予報で見かけそうなこの表は，人間にとっては分かりやすいですが，実はコンピュータにとっては，分かりにくいものです。 コンピュータが理解しやすいデータとして表すなら，次のような表になります。\n\n\n\n地点\n時間\n気温(℃)\n\n\n\n\n札幌\n6時\n12\n\n\n札幌\n12時\n15\n\n\n札幌\n18時\n13\n\n\n大阪\n6時\n20\n\n\n大阪\n12時\n24\n\n\n大阪\n18時\n22\n\n\n福岡\n6時\n23\n\n\n福岡\n12時\n25\n\n\n福岡\n18時\n25\n\n\n\nこのような形式のデータをロング型(long)といいます。 このロング型のうち，一定のルールに従って作成されたデータを整然データ(tidy data)といい，Rでは，この整然データを扱うことが多いです。\nR神Hadley Wickham氏は，データの型を理解することを，データ分析の第一歩とし，その一貫として整然データという考え方を提唱しています。 整然データとは，次のような原則に従って構築されたデータのことです(Wickham, 2014) 参考https://id.fnshr.info/2017/01/09/tidy-data-intro/。\n\n個々の変数 (variable) が1つの列 (column) をなす。\n個々の観測 (observation) が1つの行 (row) をなす。\n個々の観測の構成単位の類型 (type of observational unit) が1つの表 (table) をなす。\n個々の値 (value) が1つのセル (cell) をなす\n\n上の表は，地点，時間，天気，気温の4つの変数があり1つの列をつくっています(ルール1)。 大阪12時の天気は雨，気温は12℃といったように1つの行が1つの観測を表しています(ルール2)。 このデータには種類の異なる観測はない(ルール3)。 また，各セルには1つの値が入っています(ルール4)。 よって，これが整然データとなります。\n上のロング型の天気データを使って，ロングからワイド，ワイドからロングの操作を学びましょう。\nまずデータを作ります。\n\ndf_weather &lt;- data.frame(\n    place = c(\"札幌\",\"札幌\",\"札幌\",\"大阪\",\"大阪\",\"大阪\",\"福岡\",\"福岡\",\"福岡\"), # 各地を3個ずつ\n    time = rep(c(\"6時\", \"12時\", \"18時\"),3),\n    temp = c(12,15,13,20,24,22,23,25,25)\n)\nprint(df_weather)\n\n  place time temp\n1  札幌  6時   12\n2  札幌 12時   15\n3  札幌 18時   13\n4  大阪  6時   20\n5  大阪 12時   24\n6  大阪 18時   22\n7  福岡  6時   23\n8  福岡 12時   25\n9  福岡 18時   25\n\n\nこれはロング型の整然データとなります。\n\n\nロングからワイド pivot_wider\nRで使うならこのままでよいのですが，あえてこれをワイド型に変えてみましょう。\n教科書で使用されているspread()は「根本的に設計ミスってた」と公式で発表されているので，R神が作ったpivot_wider()を使います。widerという名前の通り，ワイド型に変換する関数です。\npivot_wider()の引数は，names_fromとvalues_fromです。names_fromは，ワイド型に変換するときに，どの変数を列にするかを指定します。values_fromは，ワイド型に変換するときに，どの変数の値を使うかを指定します。\n以下のコードでは，time変数の値を列に，temp変数の値を値にして，df_wideという変数に代入しています。\n\ndf_wide &lt;- df_weather %&gt;%\n    pivot_wider(names_from = time, values_from = temp)\nprint(df_wide)\n\n# A tibble: 3 × 4\n  place `6時` `12時` `18時`\n  &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 札幌     12     15     13\n2 大阪     20     24     22\n3 福岡     23     25     25\n\n\nこれでワイド型に変換できました。\n\n\nワイドからロング pivot_longer\n次に，このワイド型のデータをロング型に変換してみます。 教科書では，tidyrのgather()を使っていますが，これもwider()と同じ問題を持っているので，R神によるpivot_longer()を使います。\npivot_longer()の引数は，colsとnames_toとvalues_toです。\n\ncolsは，ロング型に変換するときに，どの変数を行にするかを指定\nnames_toは，ロング型に変換するときに，どの変数の値を使うかを指定\nvalues_toは，ロング型に変換するときに，どの変数の値を使うかを指定\n\n以下のコードでは，6時，12時，18時の3つの変数を行に，timeという変数の値を列に，tempという変数の値を値にして，df_longという変数に代入しています。\n\ndf_long &lt;- df_wide %&gt;%\n    pivot_longer(\n        cols = c(\"6時\", \"12時\", \"18時\"), # 縦にする変数\n        names_to = \"time\", # 縦にした変数名\n        values_to = \"temp\") # 値\nprint(df_long)\n\n# A tibble: 9 × 3\n  place time   temp\n  &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;\n1 札幌  6時      12\n2 札幌  12時     15\n3 札幌  18時     13\n4 大阪  6時      20\n5 大阪  12時     24\n6 大阪  18時     22\n7 福岡  6時      23\n8 福岡  12時     25\n9 福岡  18時     25\n\n\n元のロング型に戻りました。\n\n\n5.3.4 データの結合\n別々のデータを結合させて使いたいことはよくあります。 例えば，次のようなデータを結合させる場合を考えてみましょう。\n\n表A\n\n\n\nname\nterm\nsale\n\n\n\n\nトヨタ\n2020\n1000\n\n\nトヨタ\n2021\n900\n\n\nトヨタ\n2022\n1400\n\n\nホンダ\n2020\n800\n\n\nホンダ\n2021\n700\n\n\nホンダ\n2022\n900\n\n\n\n\ndf_A &lt;- data.frame(\n    name = c(\"トヨタ\", \"トヨタ\", \"トヨタ\", \"ホンダ\", \"ホンダ\", \"ホンダ\"),\n    term = c(2020, 2021, 2022, 2020, 2021, 2022),\n    sale = c(1000, 900, 1400, 800, 700, 900)\n)\n\n\n\n表B\n\n\n\nname\nterm\nsale\n\n\n\n\n日産\n2020\n400\n\n\n日産\n2021\n500\n\n\n日産\n2022\n900\n\n\nマツダ\n2020\n300\n\n\nマツダ\n2021\n400\n\n\nマツダ\n2022\n200\n\n\n\n\ndf_B &lt;- data.frame(\n    name = c(\"日産\", \"日産\", \"日産\", \"マツダ\", \"マツダ\", \"マツダ\"),\n    term = c(2020, 2021, 2022, 2020, 2021, 2022),\n    sale = c(400, 500, 900, 300, 400, 200)\n)\n\n\n\n表C\n\n\n\nname\nterm\nnetincome\n\n\n\n\nトヨタ\n2020\n100\n\n\nトヨタ\n2021\n90\n\n\nトヨタ\n2022\n150\n\n\nホンダ\n2020\n140\n\n\nホンダ\n2021\n100\n\n\nホンダ\n2022\n90\n\n\nスバル\n2020\n30\n\n\nスバル\n2021\n35\n\n\nスバル\n2022\n50\n\n\n\n\ndf_C &lt;- data.frame(\n    name = c(\"トヨタ\", \"トヨタ\", \"トヨタ\", \"ホンダ\", \"ホンダ\", \"ホンダ\", \"スバル\", \"スバル\", \"スバル\"),\n    term = c(2020, 2021, 2022, 2020, 2021, 2022, 2020, 2021, 2022),\n    netincome = c(100, 90, 150, 140, 100, 90, 30, 35, 50)\n)\n\nこの3つのデータを結合させる場合を考えます。 まず表Aと表Bは同じ変数をもつデータなので，これらを結合させるには，縦につなげる必要があります。 このような結合を縦結合とか連結といいます。 縦結合は，dplyrパッケージのbind_rows()関数を使います。\n\ndf_AB &lt;- bind_rows(df_A, df_B)\nprint(df_AB)\n\n     name term sale\n1  トヨタ 2020 1000\n2  トヨタ 2021  900\n3  トヨタ 2022 1400\n4  ホンダ 2020  800\n5  ホンダ 2021  700\n6  ホンダ 2022  900\n7    日産 2020  400\n8    日産 2021  500\n9    日産 2022  900\n10 マツダ 2020  300\n11 マツダ 2021  400\n12 マツダ 2022  200\n\n\n縦に結合できたので，トヨタ，ホンダ，日産，マツダのデータが入ったデータベースdf_ABができました。\n次に，このdf_ABとdf_Cを結合させます。 df_Cはnetincomeというdf_ABにはない変数があり，異なる変数をもつデータ同士の結合となります。 これらを結合させるには，横につなげる必要があります。 このような結合を結合といいます。\n結合には，\n\n内部結合(inner join)\n外部結合(outer join)\n\nがあり，外部結合には，\n\n完全結合(full join)\n左結合(left join)\n右結合(right join)\n\nがあります。\n内部結合は両方のデータベースに存在する観測値のみを保持するため，多くのデータが欠落することになりますが，外部結合は、少なくとも1つのテーブルに存在する観測値を保持するので，大部分のデータが欠落することにはなりません。\n3つの外部結合の特徴は次の通りです。\n\n完全結合は、xとyのすべての観測値を保持します。\n左結合は、xのすべての観測値を保持します。\n右結合は、yのすべての観測値を保持します。\n\nR神の神書籍R for Data Science (2e)の図がわかりやすいので，ここで紹介します。\n\n\n\n外部結合の例\n\n\n内部結合と3つの外部結合をベン図で表すとこうなります。\n\n\n\n外部結合のベン図\n\n\n最もよく使われる結合は左結合です。 元データに他のデータを結合する場合，元データに含まれるデータのみ保持したい場合が多いので，追加データを調べるときはいつもこれを使います。 左結合はデフォルトの結合であるべきで、他の結合を選択する強い理由がない限り、これを使用します。\nでは，df_ABとdf_Cを左結合してみましょう。 結合する際にキーとなる変数を指定する必要があります。 ここではnameとtermの2つの変数をキーとして指定します。 こうすることで，nameとtermが一致する観測値を結合します。\n\ndf_left &lt;- df_AB %&gt;%\n    left_join(df_C, by = c(\"name\", \"term\"))\nprint(df_left)\n\n     name term sale netincome\n1  トヨタ 2020 1000       100\n2  トヨタ 2021  900        90\n3  トヨタ 2022 1400       150\n4  ホンダ 2020  800       140\n5  ホンダ 2021  700       100\n6  ホンダ 2022  900        90\n7    日産 2020  400        NA\n8    日産 2021  500        NA\n9    日産 2022  900        NA\n10 マツダ 2020  300        NA\n11 マツダ 2021  400        NA\n12 マツダ 2022  200        NA\n\n\ndf_ABにはトヨタ，ホンダ，日産，マツダのデータがありますが，df_Cには日産とマツダのデータがなく，スバルのデータがあります。 そのため左結合すると，日産とマツダのnetincomeにはNAが入り，スバルは欠落します。\ndf_ABとdf_Cを右結合してみましょう。\n\ndf_right &lt;- df_AB %&gt;%\n    right_join(df_C, by = c(\"name\", \"term\"))\nprint(df_right)\n\n    name term sale netincome\n1 トヨタ 2020 1000       100\n2 トヨタ 2021  900        90\n3 トヨタ 2022 1400       150\n4 ホンダ 2020  800       140\n5 ホンダ 2021  700       100\n6 ホンダ 2022  900        90\n7 スバル 2020   NA        30\n8 スバル 2021   NA        35\n9 スバル 2022   NA        50\n\n\ndf_Cには日産とマツダのデータがなく，トヨタとホンダとスバルのデータがあります。 そのため右結合すると日産とマツダのデータが欠落し，df_Cに含まれていたトヨタ，ホンダ，スバルのデータが残ります。 しかしスバルのsaleにはNAが入ります。\n最後に，df_ABとdf_Cを完全結合してみましょう。\n\ndf_full &lt;- df_AB %&gt;%\n    full_join(df_C, by = c(\"name\", \"term\"))\nprint(df_full)\n\n     name term sale netincome\n1  トヨタ 2020 1000       100\n2  トヨタ 2021  900        90\n3  トヨタ 2022 1400       150\n4  ホンダ 2020  800       140\n5  ホンダ 2021  700       100\n6  ホンダ 2022  900        90\n7    日産 2020  400        NA\n8    日産 2021  500        NA\n9    日産 2022  900        NA\n10 マツダ 2020  300        NA\n11 マツダ 2021  400        NA\n12 マツダ 2022  200        NA\n13 スバル 2020   NA        30\n14 スバル 2021   NA        35\n15 スバル 2022   NA        50\n\n\ndf_ABにはトヨタ，ホンダ，日産，マツダのデータがありますが，df_Cにはトヨタ，ホンダ，スバルのデータがあるため， 完全結合したdf_fullにはすべての企業のデータが入ります。 しかし，日産とマツダのnetincomeにはNAが入り，スバルのsaleにもNAが入ります。\nこのように，結合するデータによって，結合したデータに含まれるデータが変わるので，自分が望む結合後のデータの形を考えて，どの結合を使うかを選ぶ必要があります。\nついでに内部結合もやってみましょう。\n\ndf_inner &lt;- df_AB %&gt;%\n    inner_join(df_C, by = c(\"name\", \"term\"))\nprint(df_inner)\n\n    name term sale netincome\n1 トヨタ 2020 1000       100\n2 トヨタ 2021  900        90\n3 トヨタ 2022 1400       150\n4 ホンダ 2020  800       140\n5 ホンダ 2021  700       100\n6 ホンダ 2022  900        90\n\n\n予想どおり，両方のデータに含まれているトヨタとホンダだけが残り，片方のデータにしか含まれていない日産，マツダ，スバルのデータは欠落してしまいました。 このように内部結合は，両方のデータに存在する観測値のみを保持するため，多くのデータが欠落することになり，利用する機会があまりないです。"
  },
  {
    "objectID": "Empoli_Chap05.html#データの保存",
    "href": "Empoli_Chap05.html#データの保存",
    "title": "5  Rによるデータ操作",
    "section": "5.4 データの保存",
    "text": "5.4 データの保存\n前処理が終わったデータは，ファイルとして保存しておくとよいでしょう。 たとえば，df_leftをdf_left.csvというファイル名で保存するには，readrパッケージのwrite_csv()関数を使います。\nwrite_csv()関数の第1引数は保存したいオブジェクト(ここではdf_left)で，あとの主要な引数は，\n\nfile\nna = \"NA\"\nappend = FALSE\n\nとなります。 fileは保存するファイル名を指定します。 naは欠損値をどうするかを指定します。デフォルトではNAとなっています。 appendは，既存のファイルに追記するかどうかを指定します。基本は上書きなので，FALSEにしておきます。\n\nwrite_csv(df_left, file = \"df_left.csv\")\n\nこれで，作業ディレクトリにdf_left.csvが保存されました。 分析を進める際は，このようにして保存したデータを読み込んで使います。"
  },
  {
    "objectID": "Empoli_Chap06.html#変数の種類と記述統計",
    "href": "Empoli_Chap06.html#変数の種類と記述統計",
    "title": "6  記述統計とデータの可視化・視覚化",
    "section": "6.1 変数の種類と記述統計",
    "text": "6.1 変数の種類と記述統計\nデータには「カテゴリ変数」(category variable)と「量的変数」(quantitative variable)あるいは「連続変数」(continuous variable)があり，それぞれに対して適切なグラフの種類があります。\n\n6.1.1 カテゴリー変数と量的変数\nカテゴリー変数(category variable)とは、観測値が属するカテゴリーを表す変数です。 たとえば、日経産業中分類の「水産」は35、鉱業は37，建設は41ですが、これらの数値は足したり引いたりすることに意味はありません。\n量的変数(quantitative variable)とは、観測値が数値で表される変数です。 たとえば、売上高や株価は金額で表されるため、足したり引いたり、平均や分散を計算することに意味があります。\nしたがって、手元にあるデータベースの各変数がカテゴリー変数か量的変数かを把握することは極めて重要です。 Rでは自動で両者を区別したりはしてくれないので、データを読み込んだ後に変数の種類を確認し、自分で指定します。\n\n\n練習用データの読み込み\nここでは、教科書とは違う、企業の財務データを使いながら、データの可視化を学びます。\n\ndf &lt;- read_csv(\"data/RD_2022.csv\")\nglimpse(df)\n\nRows: 57,823\nColumns: 23\n$ 会社コード                     &lt;chr&gt; \"0000001\", \"0000001\", \"0000001\", \"00000…\n$ 企業名                         &lt;chr&gt; \"極洋\", \"極洋\", \"極洋\", \"極洋\", \"極洋\",…\n$ 決算期                         &lt;chr&gt; \"1999/03\", \"2000/03\", \"2001/03\", \"2002/…\n$ 決算種別                       &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,…\n$ 連結基準                       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ 決算月数                       &lt;dbl&gt; 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,…\n$ 上場コード                     &lt;dbl&gt; 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,…\n$ 日経業種コード                 &lt;dbl&gt; 235341, 235341, 235341, 235341, 235341,…\n$ 現金預金                       &lt;dbl&gt; 6307, 4951, 3818, 4185, 4015, 3456, 277…\n$ 資産合計                       &lt;dbl&gt; 62109, 60885, 60599, 57069, 55373, 5856…\n$ 資本金                         &lt;dbl&gt; 5664, 5664, 5664, 5664, 5664, 5664, 566…\n$ 資本剰余金                     &lt;dbl&gt; NA, NA, NA, NA, 742, 742, 742, 743, 749…\n$ 利益剰余金                     &lt;dbl&gt; 2739, 4238, 4812, 5485, 6254, 6378, 727…\n$ 自己株式                       &lt;dbl&gt; NA, NA, -79, -154, -387, -464, -368, -2…\n$ 売上高                         &lt;dbl&gt; 171944, 171031, 166644, 158006, 162773,…\n$ 経常利益                       &lt;dbl&gt; 1600, 2299, 1947, 2333, 3314, 2895, 335…\n$ 法人税等                       &lt;dbl&gt; 620, 606, 908, 856, 1234, 1302, 1422, 1…\n$ 法人税等調整額                 &lt;dbl&gt; NA, -178, -114, 44, -272, -234, 136, -3…\n$ 親会社株主に帰属する当期純利益 &lt;dbl&gt; -251, 327, 927, 1026, 1122, 1248, 1388,…\n$ 研究開発費IFRS                 &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ 研究開発費                     &lt;dbl&gt; 210, 201, 190, 179, 197, 212, 201, 193,…\n$ `開発費・試験研究費`           &lt;dbl&gt; 210, 105, 119, 153, 176, 156, 122, 148,…\n$ 現金及び現金同等物の期末残高   &lt;dbl&gt; NA, 4865, 3729, 4097, 3923, 3359, 2725,…\n\n\n23個の変数があり、データの個数は57,823となっています。 以下ではこのデータを使って、データの可視化を学びます。\n\n\n6.1.2 基本的な統計量の確認\nはじめにsummary()で基本的な統計量を確認します。\n\nsummary(df)\n\n  会社コード           企業名             決算期             決算種別 \n Length:57823       Length:57823       Length:57823       Min.   :10  \n Class :character   Class :character   Class :character   1st Qu.:10  \n Mode  :character   Mode  :character   Mode  :character   Median :10  \n                                                          Mean   :10  \n                                                          3rd Qu.:10  \n                                                          Max.   :10  \n                                                                      \n    連結基準        決算月数       上場コード    日経業種コード  \n Min.   :1.000   Min.   : 1.00   Min.   :11.00   Min.   :101001  \n 1st Qu.:1.000   1st Qu.:12.00   1st Qu.:11.00   1st Qu.:121204  \n Median :1.000   Median :12.00   Median :11.00   Median :241403  \n Mean   :1.062   Mean   :11.98   Mean   :11.46   Mean   :190751  \n 3rd Qu.:1.000   3rd Qu.:12.00   3rd Qu.:12.00   3rd Qu.:257561  \n Max.   :3.000   Max.   :17.00   Max.   :13.00   Max.   :271704  \n                                                                 \n    現金預金           資産合計             資本金          資本剰余金     \n Min.   :       4   Min.   :       70   Min.   :      1   Min.   :-161917  \n 1st Qu.:    2023   1st Qu.:    14062   1st Qu.:   1198   1st Qu.:    965  \n Median :    5370   Median :    39028   Median :   3363   Median :   2995  \n Mean   :   38172   Mean   :   363536   Mean   :  16481   Mean   :  20259  \n 3rd Qu.:   16467   3rd Qu.:   125705   3rd Qu.:  10090   3rd Qu.:   9927  \n Max.   :68502665   Max.   :303846980   Max.   :3500000   Max.   :4503856  \n NA's   :193        NA's   :44          NA's   :198       NA's   :7714     \n   利益剰余金          自己株式            売上高            経常利益      \n Min.   : -972773   Min.   :-3306037   Min.   :       1   Min.   :-869562  \n 1st Qu.:    2250   1st Qu.:   -1368   1st Qu.:   13366   1st Qu.:    425  \n Median :    9163   Median :    -279   Median :   38209   Median :   1626  \n Mean   :   75680   Mean   :   -5144   Mean   :  237440   Mean   :  14070  \n 3rd Qu.:   34436   3rd Qu.:     -39   3rd Qu.:  127091   3rd Qu.:   6126  \n Max.   :26453126   Max.   :      -1   Max.   :31379507   Max.   :5670456  \n NA's   :299        NA's   :10800      NA's   :27         NA's   :21       \n    法人税等       法人税等調整額       親会社株主に帰属する当期純利益\n Min.   : -21709   Min.   :-1139009.0   Min.   :-1708029              \n 1st Qu.:    159   1st Qu.:    -134.5   1st Qu.:     163              \n Median :    586   Median :      -7.0   Median :     823              \n Mean   :   4827   Mean   :    -114.7   Mean   :    7707              \n 3rd Qu.:   2170   3rd Qu.:      91.0   3rd Qu.:    3372              \n Max.   :1190782   Max.   : 1097414.0   Max.   : 4987962              \n NA's   :391       NA's   :3736         NA's   :29                    \n 研究開発費IFRS     研究開発費      開発費・試験研究費\n Min.   :    48   Min.   :      1   Min.   :     1    \n 1st Qu.:  2440   1st Qu.:    131   1st Qu.:   169    \n Median : 24628   Median :    547   Median :   651    \n Mean   : 91248   Mean   :   8441   Mean   :  7528    \n 3rd Qu.:108096   3rd Qu.:   2330   3rd Qu.:  2710    \n Max.   :806905   Max.   :1124262   Max.   :662610    \n NA's   :57583    NA's   :21525     NA's   :38296     \n 現金及び現金同等物の期末残高\n Min.   :    -292            \n 1st Qu.:    1913            \n Median :    5328            \n Mean   :   39185            \n 3rd Qu.:   16954            \n Max.   :68419223            \n NA's   :1591                \n\n\n文字列となっている変数以外の量的変数については、最小値、第1四分位、中央値、平均値、第3四分位、最大値、欠損値の数、といった項目が計算されています。 数値データのうち、カテゴリー変数の統計量については意味が無いです。\n23個の変数の型を確認すると、大部分の財務データは数値&lt;dbl&gt;ですが、\n\n会社コード\n企業名\n決算期\n\nの3つは文字列&lt;chr&gt;となっています。 また、数値となっているけれど、実際はカテゴリー変数であるものとして、\n\n決算種別 : 10 = 本決算\n連結基準 : 1 = 日本基準, 2 = 米国基準, 3 = IFRS, 0 = 単独\n上場コード : 11 = 東証1部, 12 = 東証2部, 13 = 東証マザーズ,\n日経業種コード : 後で説明あり\n\nがあります。 文字列となっている変数以外の量的変数については、最小値、第1四分位、中央値、平均値、第3四分位、最大値、欠損値の数、といった項目が計算されています。 数値データとなっているカテゴリー変数である決算種別，連結基準，上場コード，日経業種コードの統計量も計算されていますが，もちろん意味は無いので，Rにカテゴリー変数であることを明示するためにファクター型に変換する必要があります。\nとりあえず、数値データのうち、カテゴリー変数ではないものについて、統計量を計算してみます。 主要な統計量を返す関数には以下のものがあります。\n\nmean() : 算術平均を計算する\nmedian() : 中央値を計算する\nsd() : (不偏)標準偏差を計算する\nvar() : (不偏)分散を計算する\nmin() : 最小値を計算する\nmax() : 最大値を計算する\n\nでは、売上高の平均を計算してみましょう。 データフレームdfの売上高にアクセスするには、df$売上高のように、$を使って変数名を指定します。 Excelでいうと，dfがシート名，売上高が列名に相当します。\n\nmean(df$売上高)\n\n[1] NA\n\n\nNAが帰ってきましたね。 実は、このmean()関数は、引数となるベクトル変数の中に欠損値NAがあると、NAを返します。 欠損値を意味するNAは，その観測値が存在しないことを表します。 このような場合、NAを除外して平均を計算する必要があるので、na.rm = TRUEという引数を追加します。\n\nmean(df$売上高, na.rm = TRUE)\n\n[1] 237440.1\n\n\nこれで、売上高の平均が2.3744011^{5}となりました。\n同じように、\n\nmedian(df$売上高, na.rm = TRUE)\n\n[1] 38209\n\nsd(df$売上高, na.rm = TRUE)\n\n[1] 938244.4\n\n\nとすることで、中央値と標準偏差が求められます。\n\n\n6.1.3 カテゴリ変数の内容確認\nカテゴリー変数について見ていきましょう。 ここでは日経業種コードを例にとります。 日経業種コードは6ケタの数字ですが、最初の1ケタが大分類、次の2ケタ目が中分類、最後の3ケタ目が小分類を表します。つまり1 + 32 + 344のような構造になっています。 実証会計研究では、産業中分類をよく使うので、ここでは中分類を抽出してみましょう。 またしてもsubstr()関数を使って、2〜3ケタ目を抽出し、中分類という変数に格納します。 ついでに，決算期のデータがYYYY/MMという形式になっているので，最初の4桁を抽出して，年度という変数に格納します。\n\ndf &lt;- df %&gt;%\n  mutate(\n    中分類 = substr(日経業種コード, 2, 3),\n    年度 = substr(決算期, 1, 4)\n    )\n\nこの中分類の内容を確認するには、table()関数を使います。\n\ntable(df$中分類)\n\n\n   01    03    05    07    09    11    13    15    17    19    21    23    25 \n 2215   934   432  3915   947   178   459  1066   906  2174  4338  5016    96 \n   27    29    31    33    35    37    41    43    45    52    53    55    57 \n 1651   253  1035  1936   203   131  2715  5926  3501   832  1674   670   640 \n   59    61    63    65    67    69    71 \n  261    96   746   625   285   214 11753 \n\n\nこのように、中分類ごとの企業数が計算されました。 このカテゴリー変数の型をclass()関数で確認します。\n\nclass(df$中分類)\n\n[1] \"character\"\n\n\ncharacterつまり文字列となっています。これをファクター型に変えて、カテゴリー変数であることを明示します。as.factor()関数を使うと、ファクター型に変換できますが，産業コードだけだとどの産業なのか分かりづらいままです。 そこで、factor()関数を使って、カテゴリー変数の内容を指定します。 ついでに，上場コードや連結基準もファクター型に変換しておきます。\nまずどんな中分類があるのかを確認します。 ある変数にどんなカテゴリーがあるのかを確認するには、unique()関数を使います。\n\nchu_level &lt;- sort(unique(df$中分類))\n\nこの中分類コードに対応する産業名称を指定するには，factor()関数の引数として，levels =とlabels =を指定します。 以下では，mutate()と組み合わせて，中分類をファクター型に変換します。\n産業名称をベクトルとして収納しておきます。\n\nchu_name &lt;- c(\n  \"食品\",\"繊維\",\"パルプ・紙\",\"化学工業\",\"医薬品\",\"石油\",\"ゴム\",\"窯業\",\"鉄鉱業\",\"非金属及び金属製品\",\"機械\",\"電気機器\",\"造船\",\"自動車・自動車部品\",\"その他輸送用機器\",\"精密機器\",\"その他製造業\",\"水産\",\"鉱業\",\"建設\",\"商社\",\"小売業\",\"その他金融業\",\"不動産\",\"鉄道・バス\",\"陸運\",\"海運\",\"空輸\",\"倉庫・運輸関連\",\"通信\",\"電力\",\"ガス\",\"サービス業\")\n\n\ndf &lt;- df %&gt;%\n  arrange(中分類) %&gt;%\n  mutate(\n    中分類 = factor(\n      中分類,\n      levels = chu_level,\n      labels = chu_name),\n    上場コード = factor(\n      上場コード,\n      levels = c(11,12,13),\n      labels = c(\"1部\",\"2部\",\"マザーズ\")),\n    連結基準 = factor(\n      連結基準,\n      levels = c(1,2,3,0),\n      labels = c(\"日本基準\",\"米国基準\",\"IFRS\",\"単独\"))\n      )\n\nカテゴリー変数がファクター型に変換されたので，再度summary()関数を使って，概要統計量を確認してみましょう。\n\nsummary(df)\n\n  会社コード           企業名             決算期             決算種別 \n Length:57823       Length:57823       Length:57823       Min.   :10  \n Class :character   Class :character   Class :character   1st Qu.:10  \n Mode  :character   Mode  :character   Mode  :character   Median :10  \n                                                          Mean   :10  \n                                                          3rd Qu.:10  \n                                                          Max.   :10  \n                                                                      \n     連結基準        決算月数        上場コード    日経業種コード  \n 日本基準:55727   Min.   : 1.00   1部     :33171   Min.   :101001  \n 米国基準:  581   1st Qu.:12.00   2部     :22529   1st Qu.:121204  \n IFRS    : 1515   Median :12.00   マザーズ: 2123   Median :241403  \n 単独    :    0   Mean   :11.98                    Mean   :190751  \n                  3rd Qu.:12.00                    3rd Qu.:257561  \n                  Max.   :17.00                    Max.   :271704  \n                                                                   \n    現金預金           資産合計             資本金          資本剰余金     \n Min.   :       4   Min.   :       70   Min.   :      1   Min.   :-161917  \n 1st Qu.:    2023   1st Qu.:    14062   1st Qu.:   1198   1st Qu.:    965  \n Median :    5370   Median :    39028   Median :   3363   Median :   2995  \n Mean   :   38172   Mean   :   363536   Mean   :  16481   Mean   :  20259  \n 3rd Qu.:   16467   3rd Qu.:   125705   3rd Qu.:  10090   3rd Qu.:   9927  \n Max.   :68502665   Max.   :303846980   Max.   :3500000   Max.   :4503856  \n NA's   :193        NA's   :44          NA's   :198       NA's   :7714     \n   利益剰余金          自己株式            売上高            経常利益      \n Min.   : -972773   Min.   :-3306037   Min.   :       1   Min.   :-869562  \n 1st Qu.:    2250   1st Qu.:   -1368   1st Qu.:   13366   1st Qu.:    425  \n Median :    9163   Median :    -279   Median :   38209   Median :   1626  \n Mean   :   75680   Mean   :   -5144   Mean   :  237440   Mean   :  14070  \n 3rd Qu.:   34436   3rd Qu.:     -39   3rd Qu.:  127091   3rd Qu.:   6126  \n Max.   :26453126   Max.   :      -1   Max.   :31379507   Max.   :5670456  \n NA's   :299        NA's   :10800      NA's   :27         NA's   :21       \n    法人税等       法人税等調整額       親会社株主に帰属する当期純利益\n Min.   : -21709   Min.   :-1139009.0   Min.   :-1708029              \n 1st Qu.:    159   1st Qu.:    -134.5   1st Qu.:     163              \n Median :    586   Median :      -7.0   Median :     823              \n Mean   :   4827   Mean   :    -114.7   Mean   :    7707              \n 3rd Qu.:   2170   3rd Qu.:      91.0   3rd Qu.:    3372              \n Max.   :1190782   Max.   : 1097414.0   Max.   : 4987962              \n NA's   :391       NA's   :3736         NA's   :29                    \n 研究開発費IFRS     研究開発費      開発費・試験研究費\n Min.   :    48   Min.   :      1   Min.   :     1    \n 1st Qu.:  2440   1st Qu.:    131   1st Qu.:   169    \n Median : 24628   Median :    547   Median :   651    \n Mean   : 91248   Mean   :   8441   Mean   :  7528    \n 3rd Qu.:108096   3rd Qu.:   2330   3rd Qu.:  2710    \n Max.   :806905   Max.   :1124262   Max.   :662610    \n NA's   :57583    NA's   :21525     NA's   :38296     \n 現金及び現金同等物の期末残高        中分類          年度          \n Min.   :    -292             サービス業:11753   Length:57823      \n 1st Qu.:    1913             商社      : 5926   Class :character  \n Median :    5328             電気機器  : 5016   Mode  :character  \n Mean   :   39185             機械      : 4338                     \n 3rd Qu.:   16954             化学工業  : 3915                     \n Max.   :68419223             小売業    : 3501                     \n NA's   :1591                 (Other)   :23374                     \n\n\nカテゴリー変数はカテゴリーの種類と個数が表示されています。\n\n\n6.1.4 2つのカテゴリー変数の関係を確かめる\n2つの変数から表を作成する方法について学びます。 典型的な表として，2変数のクロス集計表があります。 例えば，連結基準，つまり企業が採用している会計基準の種類と，上場コード，つまり企業が上場している市場の種類，の2変数について，それぞれのカテゴリーごとの企業数を計算することができます。\n\ntable(df$連結基準, df$上場コード)\n\n          \n             1部   2部 マザーズ\n  日本基準 31290 22432     2005\n  米国基準   580     0        1\n  IFRS      1301    97      117\n  単独         0     0        0\n\n\n圧倒的に，日本基準で上場している企業が多いことがわかります。 2020年度のデータだけを抽出して，同じようにクロス集計表を作成してみましょう。\n\ndf %&gt;%\n  filter(年度 == 2020) %&gt;%\n  with(table(連結基準, 上場コード))\n\n          上場コード\n連結基準  1部  2部 マザーズ\n  日本基準 1474 1177      259\n  米国基準   11    0        0\n  IFRS      194   15       22\n  単独        0    0        0\n\n\n東証1部に上場している企業に注目すると，日本基準採用企業が1474社，米国基準採用企業が11社，IFRS採用企業が194社となっていることがわかりました。\nこのように，table()関数の引数として2つのカテゴリー変数を指定すると，そこから2 \\times 2のグループに属する企業数を計算し，表を作成してくれます。\nここで急に登場したwith()関数ですが，with()関数は主として次の2つの引数をとります。\n\nデータ\n式\n\n例えば，先の表を作る場合を考えてみましょう。 普通に書くと\n\ntable(df$連結基準, df$上場コード)\n\nとかきましたが，何度もdf$を書くことが面倒なので，with()関数を使って\n\nwith(df, table(連結基準, 上場コード))\n\nと，第1引数にdfを指定すれば，第2引数の式の中でdf$を書く必要がなくなります。したがって，パイプ演算子を使って，\n\ndf %&gt;% with(table(連結基準, 上場コード))\n\nと処理をつなげることができます。 便利ですね。\n\n\n6.1.5 カテゴリー別に量的変数の値を調べる\n次は，量的変数をカテゴリーごとに分析したいときがあります。 たとえば，産業別や年度別に売上高の平均値を知りたい，ということが何度もあります。 任意のグループごとに処理を繰り返したいときは，dplyrパッケージのgroup_by()関数を使います。 group_by()関数は，第1引数にグループ化したい変数を指定します。\nそしてgroup_by()関数と同時に使うことで，グループごとの統計量を計算するために便利なのがdplyrパッケージのsummarize()関数です。 summarize()関数は，次のような引数をとり，各種統計量を計算してくれます。\n\nmean = : 平均\nmedian = : 中央値\nsd = : 標準偏差\nvar = : 分散\nn() : グループごとの観測値の個数\n\n例えば，上場場所ごとに売上高の平均値を計算するには，次のようにします。\n\ndf %&gt;%\n  group_by(上場コード) %&gt;%\n  summarize(\n    企業数 = n(),\n    平均売上高 = mean(売上高, na.rm = TRUE) # 平均\n    ) %&gt;%\n  ungroup() %&gt;%\n  knitr::kable(booktabs = TRUE)\n\n\n\n\n上場コード\n企業数\n平均売上高\n\n\n\n\n1部\n33171\n393156.220\n\n\n2部\n22529\n29884.533\n\n\nマザーズ\n2123\n5459.012\n\n\n\n\n\n結果を見れば分かるとおり，group_by()で上場場所ごとにグループ化し，summarize()で企業数と平均売上高を計算しているので，上場場所，企業数，平均売上高の3変数が3つの観測値をもつ3 \\times 3の表が作成されています。 group_by()とsummarize()を組み合わせると，結果としてグループ数に応じた統計量を計算した結果となり，元のデータよりも小さなデータフレームとなって返ってきます。\nついでに，産業別の売上高合計を計算してみましょう。\n\ndf %&gt;%\n  group_by(中分類) %&gt;%\n  summarize(\n    企業数 = n(),\n    平均利益 = mean(親会社株主に帰属する当期純利益, na.rm = TRUE), # 平均\n    利益標準偏差 = sd(親会社株主に帰属する当期純利益, na.rm = TRUE)\n    ) %&gt;%\n  arrange(desc(平均利益)) %&gt;%\n  ungroup() %&gt;%\n  knitr::kable(booktabs = TRUE)\n\n\n\n\n中分類\n企業数\n平均利益\n利益標準偏差\n\n\n\n\n通信\n625\n67415.843\n284105.640\n\n\n自動車・自動車部品\n1651\n39250.629\n210604.044\n\n\n電力\n285\n24108.284\n127809.199\n\n\n医薬品\n947\n20915.376\n48451.048\n\n\n鉄道・バス\n670\n16710.421\n61053.123\n\n\nガス\n214\n16210.327\n26366.794\n\n\n鉱業\n131\n15827.588\n46860.380\n\n\n海運\n261\n15152.031\n93497.186\n\n\n石油\n178\n14830.657\n81496.356\n\n\n空輸\n96\n13813.062\n105853.201\n\n\nゴム\n459\n12362.357\n43652.986\n\n\n電気機器\n5016\n10167.927\n62674.007\n\n\nその他金融業\n832\n9388.689\n47428.745\n\n\n鉄鉱業\n906\n8887.185\n47067.285\n\n\n食品\n2215\n8370.878\n32427.752\n\n\n化学工業\n3915\n7564.608\n23530.649\n\n\n商社\n5926\n6754.815\n43249.527\n\n\n精密機器\n1035\n6338.030\n17597.021\n\n\n不動産\n1674\n5826.409\n20315.917\n\n\n機械\n4338\n5310.454\n20211.162\n\n\n建設\n2715\n4868.903\n22122.402\n\n\n陸運\n640\n4662.080\n9675.867\n\n\n小売業\n3501\n4590.688\n14968.112\n\n\n窯業\n1066\n4485.089\n13623.277\n\n\nその他輸送用機器\n253\n4227.802\n12600.550\n\n\n造船\n96\n4001.927\n18613.163\n\n\n非金属及び金属製品\n2174\n3537.316\n15694.021\n\n\nパルプ・紙\n432\n3345.630\n9869.195\n\n\nその他製造業\n1936\n2630.949\n8999.953\n\n\nサービス業\n11753\n2578.502\n17729.118\n\n\n繊維\n934\n2405.079\n10837.288\n\n\n水産\n203\n2327.473\n4202.917\n\n\n倉庫・運輸関連\n746\n1876.247\n3991.522\n\n\n\n\n\n次のグラフ作成のためのデータを作成するため，年度別ごとに，ROEの平均値を計算し，その結果をdf_yearという変数に代入します。 ROEは，ある年度の親会社に帰属する当期純利益を期首株主資本で割った値です。 株主資本は，資本金と資本剰余金，利益剰余金，自己株式の合計で計算しますが，欠損値になっている会社もあるので，replace_na()関数を使って欠損値にはゼロを代入します。\n\ndf &lt;- df %&gt;%\n  replace_na(list(資本剰余金 = 0, 利益剰余金 = 0, 自己株式 = 0)) %&gt;%\n  group_by(企業名) %&gt;% # 会社ごとに\n  mutate(\n    株主資本 = 資本金 + 資本剰余金 + 利益剰余金 + 自己株式, # 株主資本を計算\n    ) %&gt;%\n    filter(株主資本 &gt;0 ) %&gt;% # 株主資本がマイナスの企業を除外\n  mutate(\n    ROE = 親会社株主に帰属する当期純利益 / lag(株主資本) # ROEを計算\n    ) %&gt;%\n  ungroup()\n\ndf_year &lt;- df %&gt;%\n  group_by(年度) %&gt;%\n  summarize(\n    平均ROE = mean(ROE, na.rm = TRUE)\n    ) %&gt;%\n  ungroup()\n\nこれで，年度ごと，上場場所ごとに，平均ROEを計算したデータフレームdf_yearができました。\nここで注意しなければならない点として，group_by(企業名)とした上で，lag()関数を使っている点です。 lag()関数は，引数として指定した変数の値の1つ前の値に変換します。 したがって，group_by()を使わないと次のような結果になります。\n\n\n\n\n\n\n\n\n\n\n\n\n企業名\n年度\n親会社株主に帰属する当期純利益\n株主資本\nROE\n\n\n\n\nニップン\n2020\n8941\n129587\n0.0723101\n\n\nニップン\n2021\n8636\n135597\n0.0666425\n\n\nニップン\n2022\n9327\n142166\n0.0687847\n\n\n日清製粉グループ本社\n1999\n7327\n156543\n0.0515383\n\n\n日清製粉グループ本社\n2000\n10822\n175112\n0.0691312\n\n\n日清製粉グループ本社\n2001\n11136\n177671\n0.0635936\n\n\n\n\n\nここで問題になっているのが，日清製粉グループ本社の1999年のROEが計算されている点である。 ROEは分子に親会社株主に帰属する当期純利益，分母に期首株主資本，つまりは前期末の株主資本を使います。 したがって，1999年のROEを計算するためには，1998年の株主資本を使う必要がありますが，データは1999年からしか存在しないので欠損値にならないといけないのに，計算されてしまっています。 つまり，一つ上のニップンの2022年の株主資本のデータを使っているのです。 そこで，group_by()により企業ごとにグループ化して，lag()関数を使って，一つ前の観測値を使うようにし，1999年のROEは欠損値になるようにします。\n\n\n\n\n\n企業名\n年度\n株主資本\nROE\n\n\n\n\nニップン\n2020\n129587\n0.0723101\n\n\nニップン\n2021\n135597\n0.0666425\n\n\nニップン\n2022\n142166\n0.0687847\n\n\n日清製粉グループ本社\n1999\n156543\nNA\n\n\n日清製粉グループ本社\n2000\n175112\n0.0691312\n\n\n日清製粉グループ本社\n2001\n177671\n0.0635936"
  },
  {
    "objectID": "Empoli_Chap06.html#変数の可視化視覚化",
    "href": "Empoli_Chap06.html#変数の可視化視覚化",
    "title": "6  記述統計とデータの可視化・視覚化",
    "section": "6.2 変数の可視化・視覚化",
    "text": "6.2 変数の可視化・視覚化\nカテゴリー変数のファクター化，with()関数とtable()関数を使ったクロス集計表の作成，group_by()関数とsummarize()関数を使ったグループごとの統計量の計算について学んだので，これらの結果を使ってグラフを作ることで，読者に伝わるデータの可視化を行いたいと思います。 キレイなグラフを比較的簡単に作ることができるggplot2パッケージを使います。\n\n6.2.1 ggplot()関数の基本的な使い方と変数の特徴把握\nggplot2パッケージのggplot()関数は，次のような引数をとります。\n\ndata = : データフレーム\nmapping = aes() : グラフの構成要素を指定する関数\ngeom_*** : グラフの種類を指定する関数\n各種オプション\n\n最初の注意点として，ggplot()関数は，第1引数data =でtibbleかdata.frameを指定する必要があります。 データの型に気をつけましょう。\nでは，年度ごとに平均ROEを示した折れ線グラフを作図していきます。 まず土台となるデータフレームを指定します。\n\nggplot(data = df_year)\n\n\n\n\n土台ができましたが，まだ何も表示されていません。 次に，グラフの構成要素を指定するために，mapping = aes()で，軸を指定します。 今回は，横軸に年度，縦軸に平均ROEを指定します。\n\nggplot(data = df_year, mapping = aes(x = 年度, y = 平均ROE))\n\n\n\n\n縦軸と横軸が表示されました。 軸のラベルが文字化けしているので，最初に作成しておいたスタイルmystyleを適用します。\n\nggplot(data = df_year, mapping = aes(x = 年度, y = 平均ROE)) + mystyle\n\n\n\n\n次に，グラフを作成するために，geom_line()関数を使います。 ggplot関数では，次のようなgeom_***()関数を使って，グラフの種類を指定します。\n\ngeom_point() : 散布図\ngeom_line() : 折れ線グラフ\ngeom_bar() : 棒グラフ\ngeom_boxplot() : 箱ひげ図\ngeom_histogram() : ヒストグラム\ngeom_density() : カーネル密度推定図\ngeom_violin() : バイオリンプロット\ngeom_smooth() : 平滑化曲線\n\nここでは横軸が年度という文字列，縦軸が平均ROEという量的変数となるグラフを作るので，geom_bar()を使います。\n\nggplot(data = df_year, mapping = aes(x = 年度, y = 平均ROE)) +\n  geom_bar(stat = \"identity\") + mystyle\n\n\n\n\n横軸が順序に意味のある変数であれば，geom_line()で折れ線グラフを作るほうが良いでしょう。 この場合，年度は文字列ですが，本来は順序に意味のあるカテゴリー変数ですので，factor()関数を使って，ファクター型に変換します。\n\ndf_year &lt;- df_year %&gt;%\n  mutate(年度f = factor(年度,\n  levels = c(1999:2022),\n  ordered = TRUE))\n\n横軸が順序付きのファクターの年度fとなったので，geom_line()を使って折れ線グラフを作成します。 ここで，オプションとして，group = 1を指定して，データ全体が1つのグループであることを明示します。 横軸がファクター型であるときは，group = 1をつける，というおまじないを覚えておきましょう。\n\nggplot(data = df_year, mapping = aes(x = 年度f, y = 平均ROE, group = 1)) +\n  geom_line() + geom_point() + xlab(\"年度\") + ylab(\"平均ROE\") + mystyle\n\n\n\n\n上のコードは，必要な引数を省略せずに書きましたが，省略できるものを省略しつつ， すべての要素を+でつなぐよりも，レイヤーごとに代入していくほうが，コードが読みやすくなります。\n\ng &lt;- ggplot(df_year) + aes(年度f, 平均ROE, group = 1) # 基本要素\ng &lt;- g + geom_line() + geom_point() # 折れ線グラフと散布図\ng &lt;- g + xlab(\"年度\") + ylab(\"平均ROE\") + mystyle # 見た目の調整\nprint(g)\n\n\n\n\n\n\n6.2.2 ヒストグラム\n次に，前年度のROEのヒストグラムを作成してみましょう。\n\ng &lt;- ggplot(df) + aes(ROE) +\n  geom_histogram(fill=\"skyblue\", color = \"black\") +\n  xlim(-1,1) + mystyle\nprint(g)\n\n\n\n\n\n\n6.2.3 箱ひげ図とバイオリンプロット\n次に，上場場所別ROEの分布を箱ひげ図とバイオリンプロットで比較してみましょう。 箱ひげ図は，geom_boxplot()を使います。\n\ng &lt;- ggplot(df) + aes(x = factor(上場コード), y = ROE) + geom_boxplot() + mystyle\nprint(g)\n\n\n\n\nROEのばらつきが大きく，極端にROEが大きかったり小さかったりする異常値のせいで，箱ひげ図がうまく描写されていません。 そこで異常値を除外するため，ROEの範囲を[-0.5,0.5]に限定してみましょう。 先ほど箱ひげ図を作成するために作ったオブジェクトgにylim()を追加して，Y軸の範囲を指定します。\n\ng &lt;- g + ylim(-.5,.5)\nprint(g)\n\n\n\n\n箱ひげ図の箱の下辺は第1四分位(Q1)で，上辺は第3四分位(Q3)です。 真ん中の太い横棒は中央値です。 箱から出ているひげはデータの四分位範囲を超えた値の範囲ですが，黒丸は外れ値を表しています。\n次に，バイオリンプロットを作成します。 バイオリンプロットもほぼ箱ひげ図と同じですが，geom_violin()を使います。\n\ng &lt;- ggplot(df) + aes(x = factor(上場コード), y = ROE)\ng &lt;- g + geom_violin() + ylim(-.5,.5) + mystyle\nprint(g)\n\n\n\n\n箱ひげ図やバイオリンプロットから，東証1部と東証2部の上場企業のROEは中央値に差があるものの，分布の形は似ていますが，マザーズの企業は，ROEの分布が大きく異なることがわかります。\n\n\n6.2.4 図の保存\n最後に，作成した図を保存するには，ggsave()関数を使います。 ggsave()関数は，次のような引数をとります。\n\nfilename = : 保存するファイル名\nplot = : 保存する図\nwidth = : 図の幅\nheight = : 図の高さ\ndpi = : 解像度\n\n日本語を含まないグラフであったり，Windowsならこれでうまくいくのですが，Macで日本語を含むggplotのグラフを保存するには一手間必要です。\n\nMacの場合\nMacの場合，ggsave()関数を使っても，日本語が文字化けしてしまいます。 そこでquartz()関数を用いて，次のようにすれば，日本語を含むグラフを保存することができます。 quartz()は以下の引数を取ります。\n\nfilename = : 保存するファイル名\nwidth = : 図の幅\nheight = : 図の高さ\npointsize = : フォントサイズ\nfamily = : フォントファミリー\ntype = : ファイルタイプ\nantialias = : アンチエイリアス\n\n\nquartz(\"violin_plot.pdf\", width = 10, height = 6, pointsize = 10)\nprint(g)\ndev.off()\n\nこれで作業ディレクトリにviolin_plot.pdfが保存されました。"
  },
  {
    "objectID": "Empoli_Chap07.html#母集団と標本",
    "href": "Empoli_Chap07.html#母集団と標本",
    "title": "7  統計的推定",
    "section": "7.1 母集団と標本",
    "text": "7.1 母集団と標本\n\n母集団(population)とは、研究問題(research question)に基づいて選定された対象全体の集まりを指します。 しかし、その全体を調査・分析することは、時間や費用の制約から現実的ではありません。そのため、母集団から一部を抜き出した標本(sample)を選び、この標本を通じて母集団の特性を推定します。\n\n統計学とは、限られた標本から母集団の特性（母数またはパラメータとも呼ばれます）をどのように探求するかについて研究する学問です。 例えば、作ったお味噌汁全体の味を確かめるには、全部飲むのではなく、よく混ぜた上でスプーン一杯を試飲し、その全体の味を推定するのと同じです。\n標本の特徴を調べることで，観察できない母集団の母数(parameter)を推定することを，統計的推定(statistical estimation)とよびます。 統計的推定には，標本から計算される統計量(statistic)を用います。 母数の推定のために利用される統計量を推定量(estimator)といいます。\n母数は定数ですが，推定量は標本が変われば値が変わるので確率変数です。1つの標本から計算された標本平均は，たまたま今手元にある標本から計算された平均にすぎず，別の標本を集めて標本平均を計算すれば，異なる値になることが予想されます。\nまた母数を推定するために用いられる統計量と一般的な数式記号は以下の通りです。\n\n\n\n母数\n記号\n統計量\n記号\n\n\n\n\n母平均\n\\mu\n標本平均\n\\bar x\n\n\n母比率\n\\pi\n標本比率\np\n\n\n母分散\n\\sigma^2\n標本分散\ns^2\n\n\n母標準偏差\n\\sigma\n標本標準偏差\ns\n\n\n\n標本から母数を推定するためには，適切な方法で標本を集めなければなりません。 1限の講義に出席している学生にアンケートをとっても，学生全体の推定には適切とはいえない標本があつまるでしょう。\n母集団から標本を選ぶ標本抽出方法として代表的なものが，単純無作為抽出(simple randome sampling)です。 単純無作為抽出で選ばれた標本は、母集団の偏りのない標本といえます。 たとえば，平均10，分散1の正規分布からランダムに100個のデータを抽出して標本を作り，その平均値を計算してみます。\n\nn = 100\nx &lt;- rnorm(n, 10, 1)\nmean(x)\n\n[1] 10.16023\n\n\n平均値は10.1602302となり，母平均1とほぼ同じ値になりましたが、1ではありません。 これ母平均1と標本平均10.1602302の差を誤差といい、母集団と標本のズレを意味します。\n平均10，標準偏差1の正規分布からランダムに100個のデータを抽出して標本を作り，その平均値を計算する，という指向を10000回繰り返して，10000個の平均値をヒストグラムで表示してみます。\n\nn = 100\ntrial = 10000\nresult &lt;- numeric(trial)\nfor (i in 1:trial) {\n  x &lt;- rnorm(n, 10, 1)\n  result[i] &lt;- mean(x)\n}\nhist(result)\n\n\n\n\nキレイな正規分布になっており，この10000個の平均値の平均は，\n\nmean(result)\n\n[1] 10.00035\n\n\nとほぼ1と等しくなります。 このように，標本数を増やしていくと，標本平均の平均値は母平均に近づく，という法則を大数の法則(law of large numbers)といいます。 統計学における極めて重要な概念です。"
  },
  {
    "objectID": "Empoli_Chap07.html#標本分布",
    "href": "Empoli_Chap07.html#標本分布",
    "title": "7  統計的推定",
    "section": "7.2 標本分布",
    "text": "7.2 標本分布\n関心の対象となる母集団から同じサイズの標本を取り出すにしても，その組み合わせは1つではありません。\nたとえば，プレゼミのメンバー25名から5名の標本を選ぶなら，その組み合わせは，\n\n{}_{25} \\mathrm{C}_5 = \\binom{25}{5} = \\frac{25!}{5!(25-5)!} = 53130\n\nたったこの人数でもこれだけの組み合わせがあるので，すべての株式会社から標本を選ぶ組み合わせは無数になります。 したがって，その標本から計算した統計量は標本ごとに異なる値となります。このような統計量の分布を標本分布(sampling distribution)といいます。\n\n不偏推定量\n「偏りのない」(unbiased)標本をたくさん集めることができれば，標本分布は母集団の分布に近づきます。 この多くの標本から計算される統計量の平均が母数に一致する性質を不偏性(unbiasedness)といい，普遍性をもつ推定量を不偏推定量(unbiased estimator)といいます。\nたとえば，5個のデータ(2,4,6,7,9)について考えてみましょう。 ここから3つのデータを取り出して標本を作ります。 その組み合わせは，\n\n{}_{5} \\mathrm{C}_3 = \\binom{5}{3} = \\frac{5!}{3!(5-3)!} = 10\n\nとなります。 この10個の標本から計算される標本分散と標本平均を計算してみます。 それぞれの定義は次のとおりです。\n\n\\begin{aligned}\n\\text{標本平均} &= \\frac 1n \\sum_{i=1}^n x_i \\\\\n\\text{標本分散} &= \\frac 1n \\sum_{i=1}^n \\left (x_i - \\bar{x} \\right )^2\n\\end{aligned}\n 標本平均と標本分散を計算する関数を作ります。 関数の作り方については，また後で勉強する予定ですので，ここでは関数の使い方だけを覚えておいてください。\n\nmeanp &lt;- function(x){\n  sum(x) / length(x) # 合計をデータの個数で割る\n}\nvarp &lt;- function(x){\n  sum((x - meanp(x))^2) / length(x) # 分散の計算式\n}\n\nこれで平均と分散を計算する関数ができました。 これを使って，標本平均と標本分散を計算してみましょう。 まず5のサイズをもつ母集団から標本サイズ3の標本を10通り作成します。\n\nx &lt;- c(2,4,6,7,9)\nmeanp(x) # 母平均 5.6\n\n[1] 5.6\n\nres &lt;- combn(x,3) # 3つのデータを取り出す組み合わせ\nprint(res)\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n[1,]    2    2    2    2    2    2    4    4    4     6\n[2,]    4    4    4    6    6    7    6    6    7     7\n[3,]    6    7    9    7    9    9    7    9    9     9\n\n\nこれですべての組み合わせを作り出せましたので，それぞれの標本から標本平均と標本分散を計算します。 各列に，先ほど作ったmeanp()関数をapply関数で適用し，10の標本平均を作り，sample_meanという変数に代入し，その平均を計算します。\n\nsample_mean &lt;- apply(res, 2, meanp)\nmeanp(sample_mean) # 標本平均の平均は5.6\n\n[1] 5.6\n\n\n標本平均の平均5.6が母平均5.6に一致したので，標本平均は不偏推定量であることが分かります。\n次に分散を計算してみましょう。\n\nvarp(x) # 母分散 5.84\n\n[1] 5.84\n\nsample_var &lt;- apply(res, 2, varp)\nmeanp(sample_var) #\n\n[1] 4.866667\n\n\n標本分散の平均4.8666667は母分散5.84より小さな値になりました。つまり標本分散は不偏推定量ではありません。またこの結果は自明のことです(後述します)。 これには自由度という概念が関係しています。 自由度とは，標本から計算される統計量の値を決めるのに使える情報の数のことですが，ここではスルーして，標本分散ではなく標本不偏分散を計算します。 違いは，分母がnではなくn-1になっていることです。 \n\\text{標本不偏分散} = \\frac{1}{n-1} \\sum_{i=1}^n \\left (x_i - \\bar{x} \\right )^2\n\nRの基本関数であるvar()は標本分散ではなく標本不偏分散を計算するので，これを使って先ほどの計算を再現してみましょう。\n\nvar(x) # 母分散 5.84\n\n[1] 7.3\n\nres &lt;- combn(x,3) # 3つのデータを取り出す組み合わせ\nsample_var &lt;- apply(res, 2, var)\nmeanp(sample_var) # 標本平均の平均は5.6\n\n[1] 7.3\n\n\n母分散と標本不偏分散の平均は一致しました。 つまり母数である母分散を推定するためには，標本不偏分散を使う必要があるということです。\nとはいえ，違いはnで割るか，n-1で割るか，という点だけなので，標本サイズnが大きければ，標本分散と標本不偏分散の違いは無視できるので，経営学の研究ではそこまで気にしなくてもよいでしょう。\n\n\n一致推定量\n標本数が増えると，標本分布は母集団の分布に近づく，という特徴をもつ推定量を一致推定量(consistent estimator)といいます。 これが最も重要な特徴です。\n例えば，関心のある母集団が\n\n母平均\\mu = 62\n母分散\\sigma^2 = 25\n\nという母数をもつ正規分布に従っている，としましょう。 グラフにする前に，必要なパッケージの読み出しと，グラフのスタイルを設定します。\n\nlibrary(tidyverse)\nlibrary(ggthemes)\nmystyle &lt;- list (#  ggplotのテーマ\n  theme_few(), # ggthemesパッケージ\n  theme(\n    text = element_text(\n      size=16,  #  フォントサイズ\n      family = \"HiraKakuProN-W3\" # ヒラギノフォント\n    )\n  )\n)\n\nグラフにすると次のようになります。\n\np &lt;- ggplot(data = data.frame(X = c(47,77)))\np &lt;- p +aes(x = X)\np &lt;- p + stat_function(\n  fun = dnorm, \n  args = list(mean = 62, sd = 5)\n  ) + mystyle\nprint(p)\n\n\n\n\nここから，標本サイズ10の標本を取り出し，標本平均を計算する，という試行を1000回繰り返し，1000個の標本平均を作りましょう。\n\nn = 10 # 標本サイズ\ntrial = 1000 # 試行回数\nresult &lt;- numeric(trial) # 結果を入れる空の箱\nfor (i in 1:trial) { # 以下をtrial回繰り返す\n  x &lt;- rnorm(n, 62, 5) # 標本を生成\n  result[i] &lt;- mean(x) # 標本平均を計算\n}\nmean(result) # 標本平均の平均\n\n[1] 62.00914\n\n\nヒストグラムの中心が母平均の62に近づいていることが分かります。 標本平均の平均は62.0091437となりますが，これは母平均62に近い値になっています。\nグラフで確認すると，\n\nresult &lt;- as.tibble(result)\ng &lt;- ggplot(result) + aes(value) # 軸の設定\ng &lt;- g + geom_histogram( # ヒストグラム\n  aes(y = ..density..), bins = 60, # y軸を密度に  \n  fill = \"white\", color = \"black\") # ヒストグラムの色\ng &lt;- g + stat_function(fun=dnorm, args=list(mean = 62, sd = 5))　# 母集団の分布\ng &lt;- g + geom_vline(xintercept = 62, color = \"red\") # 母平均の縦線\ng &lt;- g + xlim(47,77) + mystyle # x軸の範囲を指定\nprint(g)\n\n\n\n\nと母平均と標本平均のヒストグラムの中心が一致していることが分かります。 ただ，母分散と比べて標本分散が非常に小さいことが一目瞭然です。\n標本サイズを先ほどの100倍の1000として，同じ試行を1000回繰り返してみましょう。\n\n\n\n\n\nどんどん標本サイズを増やして，100000として，同じ試行を1000回繰り返してみましょう。\n\n\n\n\n\nこのように，標本平均の分散は，標本サイズが大きくなるにつれて，どんどん小さくなっていくことが分かります。 たとえば30から150の間の値をとり，母平均62，母分散25の正規分布にしたがう母集団から標本を採ったとしましょう。 母集団が30から150の値をとるのに対して，標本サイズが大きいとき，標本平均が30とか150の値をとることはあり得ません。\n標本平均の標準偏差SD(\\bar x)は，\n\nSD(\\bar x) = \\frac{\\sigma}{\\sqrt{n}}\n\nこのように，標本サイズを大きくすると，標本平均が母平均の近くの値をとる確率が大きくなる，という性質を一致性(consistency)と呼び，一致性をもつ推定量を一致推定量(consistent estimator)といいます。"
  },
  {
    "objectID": "Empoli_Chap07.html#母平均の推定と信頼区間",
    "href": "Empoli_Chap07.html#母平均の推定と信頼区間",
    "title": "7  統計的推定",
    "section": "7.3 母平均の推定と信頼区間 ",
    "text": "7.3 母平均の推定と信頼区間 \n標本から得た統計量をつかって母数である母平均を予想したいとき，手元にある1つの標本から計算した標本平均は，どの程度の精度をもつでしょうか？\n\n7.3.1 母平均の信頼区間 \n信頼区間(confidence interval)は，非常に難解な概念です。 まず確認として，母数である母平均は観察できない数値ですが，確率変数ではなく定数です。 この母平均が計算した信頼区間に含まれるか，含まれないか，のどちらかしかありません。 信頼区間の正しい解釈は，母集団から標本を取ってきて、その標本平均から95%信頼区間を求める、という作業を100回やったときに、95回はその区間の中に母平均が含まれる，というものです。 この信頼区間の計算をしてみます。\n\n標本平均の標準偏差を推定する– 標準誤差\n標本の統計量は確率変数なので，統計量は分布します。 標本平均の標準偏差は，\n\nSD(\\bar x) = \\frac{\\sigma }{\\sqrt{n}}\n\nと定義されます。 ここでnは標本サイズなのですぐ分かりますが，$は母標準偏差なので未知です。 そこでまず$の推定のために，不偏標準偏差\n\nu = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^n \\left (x_i - \\bar{x} \\right )^2}\n\nを計算します。 先ほど定義したSD(\\bar x)の分子\\sigmaの代わりに推定量uを使ったものを標準誤差(standard error: SE)と呼びます。 \nSE = \\frac{u}{\\sqrt{n}}\n\nこの標準誤差を標本平均の標準誤差の代わりに使います。\n\n\nt分布\nさて，とうとう統計学の真骨頂であるt分布の登場です。 t分布(t-distribution)は，母集団が正規分布にしたがうとき，標本平均の分布が従う確率分布です。 絵で描くとこんな感じです。\n\nx &lt;- seq(-4, 4, length.out = 100)\n\ndf1 &lt;- dt(x, df = 1)\ndf5 &lt;- dt(x, df = 5)\ndf100 &lt;- dt(x, df = 100)\n\n# データフレームに変換\ndf &lt;- data.frame(x = rep(x, 3),\n                 y = c(df1, df5, df100),\n                 df = rep(c(\"df = 1\", \"df = 5\", \"df = 100\"), each = length(x)))\n\n# プロット\nggplot(df, aes(x = x, y = y, color = df)) +\n  geom_line() +\n  scale_color_manual(values = c(\"red\", \"blue\", \"green\")) +\n  labs(title = \"自由度が異なるt分布のプロット\") + xlab(\"t値\") + ylab(\"確率密度\") + mystyle\n\n\n\n\n標本平均\\bar xから母平均を引いて，それを標準誤差SEで割った値をt値(t-value)といい，このt値はt分布にしたがうことが知られていますが，ここでは詳細に触れません。\n自由度99のt分布の場合，95%の確率でt値は-1.98から1.98の間に入ります。\n\n# 自由度を設定\ndf &lt;- 99\n\n# データを生成\ndata &lt;- data.frame(x = seq(-5, 5, by = 0.01))\ndata$y &lt;- dt(data$x, df)\n\n# 90%の領域の上限と下限をqt()で計算\nql &lt;- qt(0.025, df)\nqu &lt;- qt(0.975, df)\n\n# t分布を書く\ng &lt;- ggplot(data) + aes(x=x, y=y) + geom_line()\ng &lt;- g + geom_area(data = data %&gt;% filter(x &gt; ql & x &lt; qu), fill = \"blue\", alpha = 0.3)\ng &lt;- g + xlab(\"t値\") + ylab(\"確率密度\") + labs(title = \"90%の確率で起こるt値の範囲\") + xlim(-3,3)\ng &lt;- g + annotate(geom = \"text\", x = qu, y = 0.12,\n  label = \"1.98\", size = 6) +\n  annotate(# 始点や終点などを指定して矢印を追加\n  geom = \"segment\", x = qu, xend = qu,\n  y = 0.1, yend = 0.07, color = \"black\", size = 0.3,\n  arrow = arrow(length = unit(0.3, \"cm\"))\n  )\ng &lt;- g + annotate(geom = \"text\", x = 0, y = 0.15,\n  label = \"95%\", size = 8)\ng &lt;- g + annotate(geom = \"text\", x = ql, y = 0.12,\n  label = \"-1.98\", size = 6) +\n  annotate(# 始点や終点などを指定して矢印を追加\n  geom = \"segment\", x = ql, xend = ql,\n  y = 0.1, yend = 0.07, color = \"black\", size = 0.3,\n  arrow = arrow(length = unit(0.3, \"cm\"))\n  ) + mystyle\nprint(g)\n\n\n\n\nt分布は確率分布ですので，面積は1となります。 青い領域が95％の確率でt値が入る範囲です。 ということは両側の白い領域は，片方が2.5％と面積となっています。 これを次のように書きます。\n\n[ -t _{100-1, 0.025}, \\ t_{100-1, 0.025}]\n\nt分布表を使って，自由度99のときのt値を調べると，t_{100-1, 0.025} = 1.98となります。 Rだとqt()関数を使って計算できます。\n\nround(qt(0.025, df = 99),digits =2)\n\n[1] -1.98\n\nround(qt(0.975, df = 99),digits =2)\n\n[1] 1.98\n\n\n\n\n信頼区間を求める\n標本サイズnの標本から計算される標本平均\\bar xから計算される次のt値 \nt = \\frac{\\bar x - \\mu}{SE}\n が自由度n-1のt分布にしたがうことが知られています。\nつまり，標本の95％のt値は，t_{n-1, 0.025}からt_{n-1, 0.975}の間に入ります。 よって，\n\n-t _{n-1, 0.025} \\leq \\frac{\\bar x - \\mu}{SE} \\leq  t_{n-1, 0.025}\n 両辺にSEをかけると， \n-t _{n-1, 0.025} \\times SE \\leq \\bar{x} - \\mu \\leq  t_{n-1, 0.025}\\times SE\n\nこの区間を95％信頼区間といいます。\n\n\n\n7.3.2 信頼区間の解釈\n信頼区間とは、観察できない真の値である母数が存在し、その母集団から標本を抽出し、標本平均を計算するということを繰り返したときに、95%の標本平均の信頼区間の中に真の値である母平均が入っている、ということです。\n先の例を使って、信頼区間を表現してみます。 いま、母集団が平均62，標準偏差5の正規分布にしたがうとします。 この母集団から標本サイズ50の標本を50個抽出して，標本平均と標本標準偏差を計算します。\n\ntrial &lt;- 50 # 標本数\nn &lt;- 50 # 標本サイズ\nmu &lt;- 62 # 母平均\nsigma &lt;- 5 # 母標準偏差\n\nset.seed(1234) # 乱数を準備\n\n# 標本ごとの統計量を収納する空のベクトルを作成\nsample_mean &lt;- numeric(trial) # 標本平均の入れ物\nsample_sd   &lt;- numeric(trial) # 標本標準偏差の入れ物\nuplimit     &lt;- numeric(trial) # 信頼区間の上限の入れ物\nlowlimit    &lt;- numeric(trial) # 信頼区間の下限の入れ物\n\n# 標本の数だけ，以下の計算を繰り返す\nfor (i in 1:trial) {\n  temp_sample    &lt;- rnorm(n, mu, sigma) # 標本を抽出\n  sample_mean[i] &lt;- mean(temp_sample) # 標本平均を計算\n  sample_sd[i]   &lt;- sd(temp_sample) # 標本標準偏差を計算\n}\n\n# 信頼区間の計算\np &lt;- .95 # 信頼水準の設定 (95%信頼区間)\nalpha &lt;- qt( (1 - p) / 2, df = n - 1, lower.tail=FALSE) # 限界値の計算\n\n# 信頼区間の上限と下限の計算\nuplimit  &lt;- sample_mean + alpha * sample_sd/sqrt(n)\nlowlimit &lt;- sample_mean - alpha * sample_sd/sqrt(n)\n\n\nconfidence_interval &lt;- data.frame(\n  標本平均 = sample_mean,\n  上限 = uplimit,\n  下限 = lowlimit,\n  標本番号 = 1:trial\n)\n\n# Plot using ggplot2 \ng_ci &lt;- ggplot(confidence_interval) +\n  aes(x = 標本番号, y = 標本平均)\n  # aes(x = reorder(標本番号, 標本平均), y = 標本平均)\ng_ci &lt;- g_ci + geom_errorbar(\n  aes(ymin = 下限, ymax = 上限,\n      color = (下限 &lt;= 62 & 上限 &gt;= 62)\n      ), width = 0.2)\ng_ci &lt;- g_ci + scale_color_manual(\n  values = c(\"blue\", \"black\"),\n  guide = FALSE)\ng_ci &lt;- g_ci + geom_point(aes(y = 標本平均)) \ng_ci &lt;- g_ci + geom_hline(yintercept = 62, color = \"red\")\ng_ci &lt;- g_ci + xlab(\"標本ID\") + ylab(\"95%信頼区間\")\ng_ci &lt;- g_ci + ylim(47,77) + coord_flip() + mystyle\n\np &lt;- ggplot(data=data.frame(X=c(47,77)), aes(x=X))\np &lt;- p + stat_function(fun=dnorm, args=list(mean=62, sd=5)) +\ngeom_vline(xintercept = 62, color=\"red\") + mystyle\n\nlibrary(patchwork)\n\np/g_ci\n\n\n\n\n本当は未知である母平均62，母標準偏差5の母集団から標本を50個取り出し，50個の標本平均と95%信頼区間を計算し，グラフにしています。 この50個の標本から計算した95％信頼区間に母平均62が含まれているかどうかを確認すると，4つの95％信頼区間に母平均が含まれていないことが分かります。4/50の割合で信頼区間に母平均が含まれていないので，信頼水準は1-4/50=0.92となります。\n信頼区間を50%にするとどうなるでしょうか？ こうなります。\n\n\n\n\n\n信頼区間が短くなり，母平均を含まない50%信頼区間が増えました。"
  },
  {
    "objectID": "Empoli_Chap08.html#統計的仮説検定の基礎",
    "href": "Empoli_Chap08.html#統計的仮説検定の基礎",
    "title": "8  統計的仮説検定",
    "section": "8.1 統計的仮説検定の基礎",
    "text": "8.1 統計的仮説検定の基礎\n母集団の母数(パラメータ)を知りたいけれど観察できないので、母集団から標本(sample)を抽出して、標本の特徴をつかって母集団の母数を予想しようとすることを、統計的推定(statistical estimation)といいます。\nこの章では、母数に対して立てた仮説が妥当かどうかを検証する方法を学びます。\n\n仮説をたてる\n有意水準を設定する\n検定統計量を計算する\n検定統計量の確率分布を求めて有意水準で棄却域を決める\n検定統計量が棄却域に入るかどうかを確認する\n\n\n8.1.1 仮説の立て方：帰無仮説と対立仮説\n仮説の立て方は、帰無仮説(null hypothesis)と対立仮説(alternative hypothesis)の2つに分けられます。 (頻度主義)統計学では、本当に示したい仮説(対立仮説)ではなく、その排反事象である帰無仮説を立てて、帰無仮説が棄却されることで、対立仮説が採択されるという考え方をとります。 排反事象(incompatible events)とは、同時に起こりえない事象のことです。\n例えば、\n\n帰無仮説H_0 : 利益反応係数ERCはゼロである。　ERC =0\n対立仮説H_A : 利益反応係数$ERCはゼロではない。 ERC \\not = 0\n\nというように、帰無仮説は対立仮説と背反となるように立てます。 また、帰無仮説は母数に対して等号で成立する仮説となります。 なぜこんなことをするのかというと、母数がある特定の値をとる、という帰無仮説を否定するためには、その値以外の取りうることを示せばよいだけですが、もし対立仮説がERC=0であったなら、これを示すためには、ERC \\not = 0を示す必要があります。 これは不可能です。\n\n\n8.1.2 有意水準の設定\n次に、どんなときに帰無仮説を棄却するのかを決めます。 帰無仮説として仮定した母数の値から標本から計算した値が大きく異なる場合には、帰無仮説を棄却する、とします。 このとき、どのくらい帰無仮説として仮定した母数の値から離れたら帰無仮説を棄却するのかを決めるのが有意水準(significance level)です。優位水準と書かないように気をつけましょう。\n有意水準は、\\alphaで表され、会計研究では0.01、0.05、0.10が使われることが多いです。 標本サイズが大きい場合だと、0.001とか0.005とかも使われます。\n例えば、母集団の平均\\muが0である、という帰無仮説を考えます。このとき対立仮説は母集団の平均\\muは0ではない、というものです。 標本サイズ100の標本から抽出した標本平均の分布から計算したt値が自由度100-1のt分布にしたがうとき、\n\nt = \\frac{\\bar{x} - \\mu}{s/\\sqrt{n}}\n となり，今\\bar{x} = \\muという帰無仮説を仮定しているので、t = 0となります。\n\n# 自由度を設定\nn = 100\ndf &lt;- n-1\n\n# データを生成\ndata &lt;- data.frame(x = seq(-5, 5, by = 0.01))\ndata$y &lt;- dt(data$x, df) # 変数yを作成\n\n\n# 90%の領域の上限と下限をqt()で計算\nql &lt;- qt(0.025, df)\nqu &lt;- qt(0.975, df)\n\n# t分布を書く\ng &lt;- ggplot(data) + aes(x = x, y = y) + geom_line()\ng &lt;- g + geom_area(data = data %&gt;% filter(x &lt;= ql), fill = \"blue\", alpha = 0.3) + geom_area(data = data %&gt;% filter(x &gt;= qu), fill = \"blue\", alpha = 0.3)\ng &lt;- g + geom_vline(xintercept = 0, color = \"red\")\ng &lt;- g + xlab(\"t値\") + ylab(\"確率密度\") + labs(title = \"90%の確率で起こるt値の範囲\")\ng &lt;- g + geom_hline(yintercept = 0)\ng &lt;- g + annotate(geom = \"text\", x = 2.4, y = 0.08, label = \"α/2\", size = 10)\ng &lt;- g + annotate(# 始点や終点などを指定して矢印を追加\n  geom = \"segment\", x = 2.4, xend = 2.2,\n  y = 0.07, yend = 0.04, color = \"black\", size = 0.5,\n  arrow = arrow(length = unit(0.3, \"cm\"))\n  )\ng &lt;- g + annotate(geom = \"text\", x = -2.4, y = 0.08, label = \"α/2\", size = 10) +\n  annotate(# 始点や終点などを指定して矢印を追加\n  geom = \"segment\", x = -2.4, xend = -2.2,\n  y = 0.07, yend = 0.04, color = \"black\", size = 0.5,\n  arrow = arrow(length = unit(0.3, \"cm\"))\n  ) + mystyle\nprint(g)\n\n\n\n\n\n\n8.1.3 検定統計量の計算 \n標本から平均などの統計量を計算し，その統計量は確率変数なので分布をもち，その分布 \n\\begin{align*}\nt = \\frac{\\bar{x} - \\mu}{SE} = \\displaystyle \\frac{\\bar{x} - \\mu}{\\frac{u}{\\sqrt{n}}}\n\\end{align*}\n を検定統計量\n\n\nRでやってみる\n母平均62、母標準偏差5の正規分布にしたがう変数Xを考えます。 母集団のサイズは10000とします。 この母集団の分布は次のようになっています。\n\nN &lt;- 10000\nX &lt;- rnorm(N, 62, 5) # 母集団\nggplot(data.frame(X)) + aes(X) + geom_histogram() + ggtitle(\"母集団\") + geom_vline(xintercept = 62, color = \"red\") + mystyle\n\n\n\n\nこの母集団から標本サイズ100の標本を100個とりだし、平均を100個計算します。\n\nn &lt;- 100\nsample_mean &lt;- numeric(n) # 空の箱を用意\nfor(i in 1:100){\n  x_sample &lt;- sample(X, n) # 標本を抽出\n  sample_mean[i] &lt;- mean(x_sample) # 標本平均を計算\n}\ndf_mean &lt;- data.frame(sample_mean)\n\nたとえば、ある標本の平均値は62.75はこうなります。\nこの平均値がどのように分布しているのかを調べるために、ヒストグラムを作成してみます。\n\ng_mean &lt;- ggplot(df_mean) + aes(x=sample_mean) +\n  geom_histogram() + xlab(\"標本平均\") + ylab(\"度数\") +\n  geom_vline(xintercept = mean(sample_mean), color = \"blue\") +\n  geom_vline(xintercept = 62, color=\"red\") + mystyle\nprint(g_mean)\n\n\n\n\n\ng_m &lt;- ggplot(df_mean) +\n    aes(x = reorder(seq_along(sample_mean), sample_mean), y = sample_mean) +\n    geom_bar(stat=\"identity\") + geom_hline(yintercept = 62, color = \"red\") +\n   coord_cartesian(ylim = c(60, 64)) +\n    ylab(\"標本平均\") + xlab(\"標本ID\") + ggtitle(\"標本平均の分布\") + mystyle\nprint(g_m)\n\n\n\n\nおおよそ母平均\\mu = 62の周りに分布していることがわかりますが，かなり離れた標本平均をもつ標本もあるようです。 たとえば，100個の標本で最小の標本平均となった標本の平均は60.59です。 このように母平均62，母標準偏差5の母集団から抽出した1つの標本サイズ100の標本平均が，60.59という値になる確率はどのくらいでしょうか。 標本平均からt値を計算し，そのt値が自由度99のt分布にしたがう確率を求めることで，この確率を求めることができます。\n\nt &lt;- (min(df_mean$sample_mean) - 62) / (5 / sqrt(n))\nprint(t)\n\n[1] -2.81836\n\n\n自由度99のt分布の下で，となる確率は求めると，\n\npt(t, df = n-1)\n\n[1] 0.00291464\n\n\nとなり，この確率は非常に小さい値となります。 つまり100個の標本をとってくると，いくつかの標本から計算された標本平均は，母平均62からかなり離れた値となることがわかります。 それぞれの標本平均から計算されたt値の分布を調べると，次のようになります。\n\ndf_mean &lt;- df_mean %&gt;%\n  mutate(\n    t_value = (sample_mean - 62) / (5 / sqrt(n)),\n    p_value = pt(t_value, df = n-1)\n  )\n\nggplot(df_mean) +\n    aes(x = reorder(seq_along(p_value), p_value), y = p_value) + # グラフの設定\n    geom_bar(stat=\"identity\", fill = ifelse(df_mean$p_value &lt; 0.05, \"red\", \"black\")) + #\n    geom_hline(yintercept = 0.05, color = \"red\") + # 有意水準0.05\n    ylab(\"p値\") + xlab(\"標本ID\") + ggtitle(\"p値の分布\") + mystyle # 軸の設定\n\n\n\n\nとなり，t値が生じる確率が5%未満となる標本がいくつかあることがわかった。 自分が集めた標本の1つから計算した標本平均、そしてt値が、帰無仮説が正しいと仮定した場合に、その標本平均がどのくらいの確率で生じるかを調べ、それが5%未満や1%未満であったならば、帰無仮説が正しいと考えるよりも、帰無仮説とは異なる母平均をもつ母集団から標本を集めたから、そのような標本平均が生じたと考えるほうがもっともらしいと考えることができます。 これが統計的仮説検定の考え方です。"
  },
  {
    "objectID": "Empoli_Chap09.html#カテゴリー変数の関連",
    "href": "Empoli_Chap09.html#カテゴリー変数の関連",
    "title": "9  変数間の関連性",
    "section": "9.1 カテゴリー変数の関連",
    "text": "9.1 カテゴリー変数の関連\n\n9.1.1 クロス集計表\nカテゴリー変数は、その値がどのカテゴリーに属するかということを表す変数です。 2つのカテゴリー変数の関連性を調べるためにはクロス集計表を作ることが有益です。 例えば、40名のクラスに、男が25名、女が15名います。 また、クラスの中で、メガネをかけている男が4名、メガネを掛けている女が8名いました。 このクロス集計表は次のようなものになります。\n\n\n\n\nメガネをかけている\nメガネをかけていない\n合計\n\n\n\n\n男\n41\n204\n245\n\n\n女\n81\n74\n155\n\n\n合計\n122\n278\n400\n\n\n\nこの表から、メガネをかけている人の割合は、男性の中で0.2009804、女性の中で0.52であることから、女子学生の方がメガネをかける傾向にあることが分かりました。\n\n\n9.1.2 カイ二乗検定\nこのクロス集計表から読み取れる関係が、統計的に意味があるのかどうかを調べるためには、\\chi ^2(カイ二乗)検定を行います。 \\chi^2検定は次のステップで実行します。\n\n帰無仮説として、カテゴリー変数間に関連性はないと仮定\nその仮定のもとで、観測されたクロス集計表の度数が、理論的に予測される度数と大きく異なるかどうかを検定\n予測される度数と観測された度数の差が大きいほど、帰無仮説が棄却される\n\n\\chi^2検定で用いられる統計量は、\\chi^2統計量と呼ばれ、次の式で計算されます。\n\n\\chi^2 = \\sum_{i=1}^n \\sum_{j=1}^m \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\n ここで、O_{ij}は観測された度数(観測度数)、E_{ij}は理論的に予測される度数(期待度数)です。nとmはカテゴリー変数のカテゴリー数です。 つまり、2つのカテゴリー変数の関連性を調べる場合、\\chi^2統計量は次のように計算されます。\n\n\\begin{aligned}\n\\chi^2 &= \\frac{(O_{11} - E_{11})^2}{E_{11}} + \\frac{(O_{12} - E_{12})^2}{E_{12}} \\\\\n&+ \\frac{(O_{21} - E_{21})^2}{E_{21}} + \\frac{(O_{22} - E_{22})^2}{E_{22}}\n\\end{aligned}\n\nここで、期待度数Eをどうやって求めるのか、が問題となります。 期待度数の「期待」の意味は、帰無仮説のもとで期待される度数です。\n\nE_{ij} = \\frac{O_{i\\cdot} \\times O_{\\cdot j}}{O_{\\cdot \\cdot}}\n ここで、O_{i\\cdot}はi行目の合計(横の合計)、O_{\\cdot j}はj列目の合計(縦の合計)、O_{\\cdot \\cdot}は全体の合計です。\n先のメガネの例で計算してみます。 観察度数Oは次のようになります。\n\n\n\n\nメガネをかけている\nメガネをかけていない\n合計\n\n\n\n\n男\n41\n204\n245\n\n\n女\n81\n74\n155\n\n\n合計\n122\n278\n400\n\n\n\n男の行合計O_{男\\cdot}は245、女の行合計O_{女\\cdot}は155、メガネ有りの列合計O_{\\cdot メガネ有}は122、メガネなしの列合計O_{\\cdot メガネ無}は278、全体の合計O_{\\cdot \\cdot}は400となります。 ここから、期待度数は次のように計算されます。\n\n\\begin{aligned}\nE_{男, メガネ} &= \\frac{245 \\times 122}{400} = 74.725 \\\\\nE_{男, メガネ無} &= \\frac{245 \\times 278}{400} = 170.275 \\\\\nE_{女, メガネ} &= \\frac{155 \\times 122}{400} = 47.275 \\\\\nE_{女, メガネ無} &= \\frac{155 \\times 278}{400} = 107.725\n\\end{aligned}\n\nよって期待度数Eは次のようになります。\n\n\n\n\nメガネをかけている\nメガネをかけていない\n合計\n\n\n\n\n男\n74.725\n170.275\n245\n\n\n女\n47.275\n107.725\n155\n\n\n合計\n122\n278\n400\n\n\n\nここから、定義通りに、\\chi^2統計量を計算します。\n\n\\begin{aligned}\n\\chi^2 = \\frac{(41 - 74.725)^2}{74.725} + \\frac{(204 - 170.275)^2}{170.275} + \\frac{(81 - 47.275)^2}{47.275} + \\frac{(74 - 107.725)^2}{107.725} = 7.2\n\\end{aligned}\n\nここで計算した\\chi^2統計量は、自由度1の\\chi^2分布に従うということが知られています。この自由度は、カテゴリー変数のカテゴリー数から1を引いたものです。 ここでは、2カテゴリー同士のクロス集計表なので、自由度は(2-1) \\times (2-1) = 1となります。\n自由度1のカイ二乗分布の確率密度関数は次のようになります。\n\nx = c(1:2500) / 250\ny1 = dchisq(x,1)\n\ndf &lt;- data.frame(x,y1)\np &lt;- ggplot(df) + aes(x = x,y = y1)\np &lt;- p + geom_line(size = 1)\np &lt;- p + ylim(c(0,1)) + ylab(\"密度\") + xlab(\"カイ二乗値\") +\n  scale_y_continuous(expand = c(0,0), limits = c(0,1)) +\n  scale_x_continuous(expand = c(0,0), limits = c(-0.1,10))\np &lt;- p + ggtitle(\"自由度1のχ2分布の確率密度\") +  mystyle\nprint(p)\n\n\n\n\n参考までに、自由度が変わると\\chi^2分布の形状は次のようなものになります。\n\nx = c(1:2500) / 250\ny1 = dchisq(x,1)\ny3 = dchisq(x,3)\ny5 = dchisq(x,5)\n\ndf &lt;- data.frame(x,y1,y3,y5)\ndf &lt;- df %&gt;% pivot_longer(names_to = \"y\",values_to = \"value\",cols = -x)\np &lt;- ggplot(df) + aes(x = x,y = value, group = y, color = y)\np &lt;- p + geom_line(size = 1)\np &lt;- p + ylim(c(0,1)) + ylab(\"密度\") + xlab(\"カイ二乗値\") +\n  scale_y_continuous(expand = c(0,0), limits = c(0,1)) +\n  scale_x_continuous(expand = c(0,0), limits = c(-0.1,10))\np &lt;- p + ggtitle(\"自由度1,3,5のχ2分布の確率密度\") +  mystyle\nprint(p)\n\n\n\n\n自由度1の\\chi^2分布における有意水準5%の値を調べるにはqchisq()関数を使います。引数は、pに確率、dfに自由度を指定します。\n\nalpha &lt;- 0.05  # 有意水準（ここでは5%）\ndf &lt;- 1        # 自由度\nqchisq(1 - alpha, df)\n\n[1] 3.841459\n\n\n自由度1のカイ二乗分布における有意水準5%の値は3.84であることが分かりました。 この値を超えると、有意水準5%で帰無仮説を棄却することになります。\nでは先程計算した\\chi^2統計量は、有意水準5%で帰無仮説を棄却するかどうかを調べてみましょう。\n\nchi2 &lt;- 7.2\nqchisq(1 - alpha, df) &lt; chi2\n\n[1] TRUE\n\n\nより、\\chi^2統計量は有意水準5%で帰無仮説を棄却することが分かりました。 ちなみに、自由度1のカイ二乗分布の確率密度関数と\\chi^2統計量の位置を重ねてみると次のようになります。\n\ndf &lt;- data.frame(x,y1)\np &lt;- ggplot(df) + aes(x = x,y = y1)\np &lt;- p + geom_line(size = 1)\np &lt;- p + ylim(c(0,1)) + ylab(\"密度\") + xlab(\"カイ二乗値\") +\n  scale_y_continuous(expand = c(0,0), limits = c(0,1)) +\n  scale_x_continuous(expand = c(0,0), limits = c(-0.1,10))\np &lt;- p + ggtitle(\"自由度1のχ2分布の確率密度\") +  mystyle\np &lt;- p + geom_vline(xintercept = chi2, linetype = \"dashed\", color = \"red\")\np &lt;- p + annotate(\"text\", x = chi2, y = 0.1, label = \"χ2 statistics\", color = \"red\")\nprint(p)\n\n\n\n\nこのように、\\chi^2統計量は、自由度1のカイ二乗分布のもとで生じる確率は、\n\n1 - pchisq(chi2, df = 1)\n\n[1] 0.007290358\n\n\nとなり、非常に小さな値であることが分かりました。 つまり、2つのカテゴリー変数の間に関係がない、という帰無仮説の下で、観測された度数が発生することはほぼありえない、ということが言えるので、帰無仮説は棄却され、2つのカテゴリー変数には関係があると結論付けられます。\n\n\n9.1.3 Rでχ2検定\nRではchisq.test()関数を使ってχ2検定を行うことができます。 引数は、xに度数表、correctに補正を行うかどうか、pに期待度数を指定します。\n先ほどの男女とメガネの例をここでも使ってみます。 まずmatrix()関数を使ってクロス集計表を行列として作成します。\n\nO &lt;- matrix(c(41, 81, 204, 74), nrow = 2, ncol = 2)\nrow.names(O) &lt;- c(\"男性\", \"女性\")\ncolnames(O) &lt;- c(\"メガネ\", \"メガネなし\")\n\nE &lt;- matrix(c(\n  sum(O[,1])*sum(O[1,])/sum(O), #男眼鏡\n  sum(O[,1])*sum(O[2,])/sum(O), #男眼鏡無\n  sum(O[,2])*sum(O[1,])/sum(O), #女眼鏡\n  sum(O[,2])*sum(O[2,])/sum(O)  #女眼鏡無\n), nrow = 2, ncol = 2)\n\nprint(O)\n\n     メガネ メガネなし\n男性     41        204\n女性     81         74\n\nprint(E)\n\n       [,1]    [,2]\n[1,] 74.725 170.275\n[2,] 47.275 107.725\n\n\nこの観察度数と期待度数から、定義通りに\\chi^2統計量を計算してみます。\n\nchi &lt;-  (O[1,1] - E[1,1])^2 / E[1,1] + #男眼鏡\n        (O[1,2] - E[1,2])^2 / E[1,2] + #男眼鏡無\n        (O[2,1] - E[2,1])^2 / E[2,1] + #女眼鏡\n        (O[2,2] - E[2,2])^2 / E[2,2]   #女眼鏡無\nprint(chi)\n\n[1] 56.51731\n\n\n\\chi^2統計量がとなりました。 この\\chi^2統計量が自由度1の\\chi^2分布にしたがう場合，この統計量が得られる確率は次のようになります。\n\nprop &lt;- 1 - pchisq(chi, df = 1)\nprint(prop)\n\n[1] 5.57332e-14\n\n\nこの確率は0.0000000000000055733となり，ほぼゼロであることが分かりました。 よって、2つのカテゴリー変数は無関係である，という帰無仮説は棄却され、2つのカテゴリー変数には関係があると結論付けられます。\nちなみに，上記のようなめんどくさい処理をしなくても，Rにはchisq.test()という関数が用意されています。 chisq.test()は引数として、xに度数表、correctに補正を行うかどうか、pに期待度数を指定します。 補正は行わないので，correctはFALSEとします。 pはデフォルトで等確率となっているので，今回は省略します。\n\nchisq.test(O, correct = FALSE)\n\n\n    Pearson's Chi-squared test\n\ndata:  O\nX-squared = 56.517, df = 1, p-value = 5.571e-14\n\n\nとなり，先ほどの結果と一致しました。\n各マスに入る度数が少ない場合には、フィッシャーの直接確率検定を使います。\n\nfisher.test(O)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  O\np-value = 1.204e-13\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.1127341 0.2982245\nsample estimates:\nodds ratio \n 0.1845096"
  },
  {
    "objectID": "Empoli_Chap09.html#量的変数間の関係",
    "href": "Empoli_Chap09.html#量的変数間の関係",
    "title": "9  変数間の関連性",
    "section": "9.2 量的変数間の関係",
    "text": "9.2 量的変数間の関係\nここでは、2つ以上の量的変数間の関係を調べる方法について学びます。 具体的には、相関係数と散布図について学習します。\n\n9.2.1 相関関係の種類・散布図・相関係数\n2つの量的変数(連続変数)が同時に変化する関係を相関関係(correlation)といいます。 相関関係には、\n\n正の相関(positive correlation)\n負の相関(negative correlation)\n無相関(no correlation)\n\nの3種類があります。\nまずは，2つの量的変数を使って散布図(scatter diagram)を描いて，目で見て相関関係があるかどうかを判断します。 そして，相関係数(correlation coefficient)を計算して，数値的に相関関係があるかどうかを判断します。 相関係数は次のように計算されます。\n\nr = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^n (x_i - \\bar{x})^2}\\sqrt{\\sum_{i=1}^n (y_i - \\bar{y})^2}}\n\n分子は、xとyの共分散(covariance)で、分母はxの標準偏差とyの標準偏差の積です。 相関係数rは-1から1の値をとります。 rが1に近いほど正の相関が強く、-1に近いほど負の相関が強く、0に近いほど無相関になります。\n相関係数が-1から1の値をとることを証明することは簡単なのですが，それを書くには余白が足りないので，ここには示しません。 コーシー・シュワルツの不等式を使うか，xとyの偏差のベクトルの角度が\\cosであることを示すか，のどちらかで証明できます。\n\n\n9.2.2 相関係数を使った統計的仮説検定\n相関係数が同じでも統計的に有意になるか否かは、標本サイズで決まるということを教科書で理解しておきましょう。\n\n\nRでやってみる\n母平均0、母標準偏差1の正規分布にしたがう変数XとYを考えます。 母集団のサイズは10000とします。\n\nN &lt;- 10000\nX &lt;- rnorm(N, 0, 1)\nY &lt;- rnorm(N, 0, 1)\nP &lt;- data.frame(X,Y)\nggplot(P) + aes(X,Y) + geom_point() + ggtitle(\"母集団\") + mystyle\n\n\n\n\nこの母集団から標本サイズ100の標本を100個とりだし、相関係数を100個計算します。\n\nn &lt;- 100\nsig &lt;- numeric(n)\ncor &lt;- numeric(n)\nfor(i in 1:100){\n  x_sample &lt;- sample(X, n)\n  y_sample &lt;- sample(Y, n)\n  res &lt;- cor.test(x_sample, y_sample)\n  sig[i] &lt;- res$p.value\n  cor[i] &lt;- cor(x_sample, y_sample)\n}\ndf_cor &lt;- data.frame(cor,sig)\ndf_cor %&gt;% arrange(sig) %&gt;% head()\n\n         cor         sig\n1  0.3032027 0.002166295\n2 -0.2678916 0.007045710\n3 -0.2637771 0.008007666\n4 -0.2509923 0.011774694\n5  0.2344974 0.018857503\n6 -0.2343658 0.018926257\n\n\nたとえば、ある標本の散布図はこうなります。\n\nx_sample &lt;- sample(X, n)\ny_sample &lt;- sample(Y, n)\ndata.frame(x_sample, y_sample) %&gt;%\n    ggplot() + aes(x_sample, y_sample) + geom_point() + geom_smooth(method = \"lm\", se = FALSE) +\n    ggtitle(\"標本\") + mystyle\n\n\n\n\n微妙に右肩上がりの関係がありそうですが、ほぼ無相関といえるでしょう。\nでは、100個の標本から計算した100個の相関係数の大きさを並べてみましょう。 無相関となる母集団からの標本を100個とっているので、標本の相関係数も0に近い値となることが予想されますが、いくつかの標本では-0.3や0.2といった相関があるという結果が得られています。\n\nggplot(data.frame(df_cor)) +\n    aes(x = reorder(seq_along(cor), cor), y=cor) +\n    geom_bar(stat=\"identity\", fill = ifelse(sig &lt; 0.05, \"red\", \"black\")) +\n    ylab(\"相関係数\") + xlab(\"標本ID\") + ggtitle(\"相関係数の分布\") + mystyle\n\n\n\n\nでは、それらの値が、母集団では相関係数が0であるという帰無仮説が正しいとした場合に、どのくらいの確率で得られるのかを調べてみましょう。\n\nggplot(data.frame(df_cor)) +\n    aes(x = reorder(seq_along(sig), sig), y=sig) +\n    geom_bar(stat=\"identity\", fill = ifelse(sig &lt; 0.05, \"red\", \"black\")) +\n    ylab(\"p値\") + xlab(\"標本ID\") + ggtitle(\"相関係数のp値の分布\") + mystyle\n\n\n\n\n相関係数が0である母集団から標本を抜き出して、その標本相関係数の値が0.3となる確率p値は0.002となりました。 もし自分がもっている広告費と売上高のデータから相関係数を計算し、その値が0.3であったなら、母集団では相関係数が0であるという帰無仮説の下では、ほとんど起こりえないことが起こったということになります。 この場合、帰無仮説が間違っていて、対立仮説である広告費と売上高には関係があるという仮説のほうがもっともらしい、ということになります。 逆に、帰無仮説を棄却できなかった場合、広告費と売上高の間に関係は無いと主張することはできません。 帰無仮説が棄却できなかった場合は、関係があるかどうかはわからないということになります。\n\n\n9.2.3 相関関係と因果関係\n\n\n\n\n\n\nImportant\n\n\n\n相関関係があるからといって、必ずしも因果関係があるとは限らない。\n\n\n広告費と売上高の関係について考えてみましょう。\n\n因果関係\n可能性1：広告費が売上高に影響を与えている、という関係を想定しています。\n\n\n\n\ngraph LR\n    A[広告費] --&gt; B[売上高]\n\n\n\n\n\n\n\n因果関係\n可能性2：売上高が広告費に影響を与えている、という関係を想定しています。\n\n\n\n\ngraph RL\n    B[売上高] --&gt; A[広告費]\n\n\n\n\n\n\n\n互恵関係\n可能性3 : 可能性1と可能性2が同時に起こっている、という関係を想定しています。\n\n\n\n\ngraph LR\n    A[広告費] --&gt; B[売上高]\n    B[売上高] --&gt; A[広告費]\n\n\n\n\n\n\n\n見せかけの相関\n広告費と売上高の両方に影響を与える第3の要因が存在する場合、広告費と売上高の間に相関関係があるように見える、という想定です。 ここでは、広告費と売上高の両方に影響を与える第3の要因として、内部資金を想定しています。内部資金が潤沢な会社は、広告宣伝費も増加させることができるし、売上高も増加させることができる、という想定です。\n\n\n\n\ngraph TB\n    A[内部資金] --&gt; B[広告費]\n    A[内部資金] --&gt; C[売上高]\n\n\n\n\n\n\n\n\n\ngraph TB\n    A[内部資金] --&gt; B[広告費]\n    A --&gt; C[売上高]\n    B -.-&gt; C"
  },
  {
    "objectID": "Empoli_Chap10.html#線形回帰-散布図への直線の当てはめ",
    "href": "Empoli_Chap10.html#線形回帰-散布図への直線の当てはめ",
    "title": "10  回帰分析の基礎",
    "section": "10.1 線形回帰 – 散布図への直線の当てはめ",
    "text": "10.1 線形回帰 – 散布図への直線の当てはめ\n前章では2変数の関係を表すために散布図を作り，相関係数を求めましたが，この章では，背後にモデルとして原因と結果の関係をもつと仮定し，そのモデルを表すために直線を当てはめる回帰分析について学びます．\n分析に使うデータとして，2006年から2022年の東京証券取引所のプライム市場に上場している会社の決算データを使います。 売上高と広告宣伝費や研究開発費の関係を分析するために，研究開発費が1億円以上，広告宣伝費が1000万円以上の会社に限定し，決算月数が12ヶ月の会社を対象にします。\n\ndf &lt;- read_csv(\"data/adv_2023.csv\")\ndf &lt;- df %&gt;%\n  filter(決算月数 == 12 & 研究開発費 &gt;= 100 & 広告宣伝費 &gt; 10)\nglimpse(df)\n\nRows: 4,442\nColumns: 14\n$ 日経会社コード &lt;chr&gt; \"0000001\", \"0000001\", \"0000003\", \"0000003\", \"0000003\", …\n$ 企業名称       &lt;chr&gt; \"極洋\", \"極洋\", \"日本水産\", \"日本水産\", \"日本水産\", \"日…\n$ 決算期         &lt;chr&gt; \"2006/03\", \"2007/03\", \"2006/03\", \"2007/03\", \"2008/03\", …\n$ 決算種別       &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,…\n$ 連結基準       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ 決算月数       &lt;dbl&gt; 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,…\n$ 業種           &lt;dbl&gt; 235341, 235341, 235341, 235341, 235341, 235341, 235341,…\n$ 資産合計       &lt;dbl&gt; 65049, 66459, 384819, 404173, 396739, 385462, 383924, 4…\n$ 売上高         &lt;dbl&gt; 152899, 157088, 539653, 552871, 533970, 505250, 481574,…\n$ 販管費         &lt;dbl&gt; 13702, 14455, 95566, 98200, 100394, 98413, 99938, 10490…\n$ 広告宣伝費     &lt;dbl&gt; 304, 279, 2699, 2569, 2953, 2568, 2636, 3160, 3009, 288…\n$ 拡販費         &lt;dbl&gt; 111, 158, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ 研究開発費     &lt;dbl&gt; 193, 188, 3083, 3377, 3718, 3803, 3994, 4499, 4809, 361…\n$ 設備投資額     &lt;dbl&gt; 897, 1841, 17186, 16031, 19105, 28872, 21121, 18633, 16…\n\n\nでは売上高と広告宣伝費の散布図を書いてみます。\n\ng &lt;- ggplot(df) + aes(x = 広告宣伝費, y = 売上高) + geom_point() + mystyle\nprint(g)\n\n\n\n\n散布図を見ると，売上高も広告宣伝費もばらつきが大きいので，とりあえず対数変換してみます。\n\ndf &lt;- df %&gt;%\n  mutate(\n    log_広告宣伝費 = log(広告宣伝費),\n    log_売上高 = log(売上高),\n    log_研究開発費 = log(研究開発費)\n  )\nglimpse(df)\n\nRows: 4,442\nColumns: 17\n$ 日経会社コード &lt;chr&gt; \"0000001\", \"0000001\", \"0000003\", \"0000003\", \"0000003\", …\n$ 企業名称       &lt;chr&gt; \"極洋\", \"極洋\", \"日本水産\", \"日本水産\", \"日本水産\", \"日…\n$ 決算期         &lt;chr&gt; \"2006/03\", \"2007/03\", \"2006/03\", \"2007/03\", \"2008/03\", …\n$ 決算種別       &lt;dbl&gt; 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,…\n$ 連結基準       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ 決算月数       &lt;dbl&gt; 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,…\n$ 業種           &lt;dbl&gt; 235341, 235341, 235341, 235341, 235341, 235341, 235341,…\n$ 資産合計       &lt;dbl&gt; 65049, 66459, 384819, 404173, 396739, 385462, 383924, 4…\n$ 売上高         &lt;dbl&gt; 152899, 157088, 539653, 552871, 533970, 505250, 481574,…\n$ 販管費         &lt;dbl&gt; 13702, 14455, 95566, 98200, 100394, 98413, 99938, 10490…\n$ 広告宣伝費     &lt;dbl&gt; 304, 279, 2699, 2569, 2953, 2568, 2636, 3160, 3009, 288…\n$ 拡販費         &lt;dbl&gt; 111, 158, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ 研究開発費     &lt;dbl&gt; 193, 188, 3083, 3377, 3718, 3803, 3994, 4499, 4809, 361…\n$ 設備投資額     &lt;dbl&gt; 897, 1841, 17186, 16031, 19105, 28872, 21121, 18633, 16…\n$ log_広告宣伝費 &lt;dbl&gt; 5.717028, 5.631212, 7.900637, 7.851272, 7.990577, 7.850…\n$ log_売上高     &lt;dbl&gt; 11.93753, 11.96456, 13.19868, 13.22288, 13.18809, 13.13…\n$ log_研究開発費 &lt;dbl&gt; 5.262690, 5.236442, 8.033658, 8.124743, 8.220941, 8.243…\n\n\n対数変換した売上高と広告宣伝費の関係を示す、散布図を作成します。\n\ng &lt;- ggplot(df) + aes(x = log_広告宣伝費, y = log_売上高) + geom_point() + mystyle\nprint(g)\n\n\n\n\nキレイに正の相関があるようにみえる散布図ができあがりました。 相関係数を計算してみると，\n\ncor(df$log_広告宣伝費, df$log_売上高)\n\n[1] 0.7530297\n\n\nとなり，非常に高い正の相関があることが分かりました。\nこの散布図に回帰直線を追加するには，geom_smoothを使います。\n\ng &lt;- g + geom_smooth(method = \"lm\", se = FALSE, color = \"red\") + xlab(\"広告宣伝費の対数\") + ylab(\"売上高の対数\") + mystyle\nprint(g)\n\n\n\n\nこの赤い直線を回帰直線(regression line)といい，原因となる変数y(ここでは広告宣伝費)と結果となる変数x(ここでは売上高)の線形関係を表す次のようなモデルとなります。\n\ny = a + bx\n\n先の広告宣伝費と売上高の散布図に引いた直線だと，\n\nres01 &lt;- lm(log_売上高 ~ log_広告宣伝費, data = df)\nsummary(res01)\n\n\n\\text{売上高の対数} = 7.770869 + 0.550978 \\times 広告宣伝費の対数"
  },
  {
    "objectID": "Empoli_Chap10.html#最小二乗法",
    "href": "Empoli_Chap10.html#最小二乗法",
    "title": "10  回帰分析の基礎",
    "section": "10.2 最小二乗法",
    "text": "10.2 最小二乗法\n先ほどの求めた回帰直線の切片や傾きの値を求める方法の1つに最小二乗法(least squares method)があります。\n最小二乗法は、観測値y_iとモデル上の予測値\\hat{y}_iの差を残差(residual)と定義し、この残差の二乗の和を最小にするような回帰直線を求める方法です。\nサイズNの標本(y_i, x_i)_{i \\in N}をデータとして持っているとしましょう。 ここでは、広告宣伝費と売上高のデータがN組あるということです。\nこのデータの関係を線形で表すモデルとして、\\hat y = \\hat a + \\hat b xを考えます。 観測値はy_i = a + bx_i + e_iです。 したがって、残差e_iはy_i - \\hat y_iとなります。\n\ndata &lt;- data.frame(\n  x = c(1, 2, 3, 4, 5),\n  y = c(3, 10, 9, 12, 18)\n)\nmodel &lt;- lm(y ~ x, data = data)\n\n# 回帰直線と残差を含むグラフを作成する\nggplot(data, aes(x, y)) +\n  geom_point(size = 2) +  # 散布図のプロット\n  geom_smooth(method = \"lm\", se = FALSE, fullrange = TRUE) +  # 回帰直線のプロット\n  geom_segment(aes(xend = x, yend = predict(model), color = \"Residuals\")) +  # 残差のプロット\n#  geom_hline(yintercept = 0, linetype = \"dashed\") +  # 残差0の水平線\n  labs(title = \"回帰直線と残差\", x = \"x\", y = \"y\") +  # グラフのタイトルと軸ラベル\n  scale_color_manual(values = c(\"Residuals\" = \"blue\")) + # 残差の色を指定する\n  xlim(0, 6) + ylim(0, 20) + mystyle # x軸とy軸の範囲を指定する\n\n\n\n\nこの観測値を表す点から回帰直線に向けて書かれた垂線の長さが残差eとなります。 この二乗和を最小にするような回帰直線を求めることが最小二乗法です。 残差の二乗和は、次のように計算できます。\n\n\\begin{aligned}\n\\sum_{i \\in N} e_i^2 &= \\sum_{i \\in N} (y_i - \\hat y_i)^2 \\\\\n&= \\sum_{i \\in N} (y_i - \\hat a - \\hat b x_i)^2 \\\\\n&= \\sum_{i \\in N} (y_i - \\bar y + \\bar y - \\hat a - \\hat b x_i)^2 \\\\\n&= \\sum_{i \\in N} (y_i - \\bar y)^2 + \\sum_{i \\in N} (\\bar y - \\hat a - \\hat b x_i)^2 + 2 \\sum_{i \\in N} (y_i - \\bar y)(\\bar y - \\hat a - \\hat b x_i) \\\\\n&= \\sum_{i \\in N} (y_i - \\bar y)^2 + \\sum_{i \\in N} (\\bar y - \\hat a - \\hat b x_i)^2 + 0 \\\\\n\\end{aligned}\n\nこの最小二乗法による回帰直線の傾きと切片を推定するには、lm関数を使います。 lm()関数は引数にformulaとdataを取ります。\n\nformula : 回帰式を指定します。y ~ xとすると、yをxで回帰します。\ndata : データフレームを指定します。\n\n\nres01 &lt;- lm(log_売上高 ~ log_広告宣伝費, data = df)\n\n推定結果を代入したresの中を詳細に見るには、summary関数を使います。\n\nsummary(res01)\n\n\nCall:\nlm(formula = log_売上高 ~ log_広告宣伝費, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.6125 -0.7040 -0.0514  0.7580  3.5226 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    7.770869   0.056878  136.62   &lt;2e-16 ***\nlog_広告宣伝費 0.550978   0.007225   76.26   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.077 on 4440 degrees of freedom\nMultiple R-squared:  0.5671,    Adjusted R-squared:  0.567 \nF-statistic:  5815 on 1 and 4440 DF,  p-value: &lt; 2.2e-16\n\n\n重要な情報が表示されますが、いろいろ表示されすぎて見づらいので、modelsummary関数を使って見やすくします。\n\nlibrary(modelsummary)\nmodelsummary(res01)\n\n\n\n\n\n (1)\n\n\n\n\n(Intercept)\n7.771\n\n\n\n(0.057)\n\n\nlog_広告宣伝費\n0.551\n\n\n\n(0.007)\n\n\nNum.Obs.\n4442\n\n\nR2\n0.567\n\n\nR2 Adj.\n0.567\n\n\nAIC\n13272.0\n\n\nBIC\n13291.2\n\n\nLog.Lik.\n-6632.994\n\n\nF\n5815.313\n\n\nRMSE\n1.08\n\n\n\n\n\n\n\nいろいろオプションを追加して、もっと見やすい表にします。\n\nlibrary(modelsummary)\ncm  &lt;-  c(\n    \"(Intercept)\" = \"切片\", # 切片のラベルを変更する\n    \"log_広告宣伝費\" = \"対数広告宣伝費\" # 傾きのラベルを変更する\n)\nmsummary(res01,\n  stars = TRUE, # p値の有意性を星で表示する\n  fmt = '%.2f',\n  coef_map = cm,\n  gof_omit = \"AIC|BIC|Log.Lik.\",\n  output = 'html'\n)\n\n\n\n\n\n (1)\n\n\n\n\n切片\n7.77***\n\n\n\n(0.06)\n\n\n対数広告宣伝費\n0.55***\n\n\n\n(0.01)\n\n\nNum.Obs.\n4442\n\n\nR2\n0.567\n\n\nR2 Adj.\n0.567\n\n\nF\n5815.313\n\n\nRMSE\n1.08\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\n\nとなり、切片が7.77、傾きが0.55と推定されました。 独立変数も従属変数も対数変換をしているため、解釈としては、 広告宣伝費が1\\%上昇すると、売上が0.55\\%増加する、という統計的に正の関係があるといえます。"
  },
  {
    "objectID": "Empoli_Chap10.html#単回帰と重回帰",
    "href": "Empoli_Chap10.html#単回帰と重回帰",
    "title": "10  回帰分析の基礎",
    "section": "10.3 単回帰と重回帰",
    "text": "10.3 単回帰と重回帰\n今までは説明変数が1つだけでしたが、複数の要因が応答変数に影響を与える場合もあります。その場合は、複数の説明変数を使った重回帰分析を行います。\n\ny_i = \\beta_0 + \\beta _1 x_1 + \\beta_2x_2 + e_i\n\nという回帰式を考えます。 この式は、x_1とx_2の2つの説明変数が応答変数yに影響を与えることを表す回帰モデルとなっています。 先の例で用いたデータを使って、広告宣伝費と研究開発費が与える影響についてみてみましょう。\nまずは、単回帰と同様に、散布図と回帰平面を描いてみます。 単回帰では、説明変数が1つであったため、応答変数との関係を2次元平面上にプロットすることができましたが、今回の重回帰では説明変数2個と応答変数の関係となるため、3次元空間にプロットする必要があります。 そのため、回帰直線では無く、回帰平面を描くことになります。\n\n# install.packages(\"rgl\")\nlibrary(rgl) # 3Dグラフのパッケージ\nlibrary(knitr) # グラフの表示を操作\nknitr::knit_hooks$set(webgl = hook_webgl) # おまじない\n\n# 回帰モデルを推定する\nmodel &lt;- lm(log_売上高 ~ log_広告宣伝費 + log_研究開発費, data = df)\n\n# プロットする範囲の値を指定する\nx1_range &lt;- range(df$log_広告宣伝費)\nx2_range &lt;- range(df$log_研究開発費)\n\n# # メッシュグリッドを作成する\ngrid &lt;- expand.grid(\n  log_広告宣伝費 = seq(x1_range[1], x1_range[2], length.out = 50),\n  log_研究開発費 = seq(x2_range[1], x2_range[2], length.out = 50)\n  )\n# メッシュグリッド上での予測値を計算する\ngrid$log_売上高 &lt;- predict(model, newdata = grid)\n\n# メッシュグリッドの座標を行列に変換する\nx1_matrix &lt;- matrix(grid$log_広告宣伝費, nrow = 50)\nx2_matrix &lt;- matrix(grid$log_研究開発費, nrow = 50)\ny_matrix &lt;-  matrix(grid$log_売上高,    nrow = 50)\n\n# グラフを出力\nplot3d(df$log_広告宣伝費, df$log_研究開発費, df$log_売上高,\n xlab = \"対数広告宣伝費\", ylab = \"対数研究開発費\", zlab = \"対数売上高\"\n ) # 3D散布図を描く\nsurface3d(x1_matrix, x2_matrix, y_matrix, alpha = 0.5, color = \"red\") # 回帰平面を描く"
  },
  {
    "objectID": "Empoli_Chap10.html#会計データを使った重回帰",
    "href": "Empoli_Chap10.html#会計データを使った重回帰",
    "title": "10  回帰分析の基礎",
    "section": "10.4 会計データを使った重回帰",
    "text": "10.4 会計データを使った重回帰\nでは実際に会計データを使った重回帰分析を行ってみましょう。 売上高yを広告宣伝費x_1と研究開発費x_2で説明する、つまり\n\n\\log y_i = \\beta_0 + \\beta_1 \\log x_{1,i} + \\beta_2 \\log x_{2,i} + e_i\n\nという線形回帰モデルを考えます。 重回帰式の推定は、単回帰式と同様にlm関数を使い、複数の説明変数を+でつなげて指定します。\n\nres02 &lt;- lm(log_売上高 ~ log_広告宣伝費 + log_研究開発費, data = df)\nsummary(res02)\n\n\nCall:\nlm(formula = log_売上高 ~ log_広告宣伝費 + log_研究開発費, \n    data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.9369 -0.5689 -0.0217  0.5057  3.5677 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    6.298486   0.055753  112.97   &lt;2e-16 ***\nlog_広告宣伝費 0.323990   0.007583   42.73   &lt;2e-16 ***\nlog_研究開発費 0.402482   0.008479   47.47   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8775 on 4439 degrees of freedom\nMultiple R-squared:  0.7128,    Adjusted R-squared:  0.7127 \nF-statistic:  5509 on 2 and 4439 DF,  p-value: &lt; 2.2e-16\n\n\n回帰係数だけを知りたいときは、coef()関数を使うと便利です。 ここでは単回帰の例と同様に、modelsummaryパッケージを使って結果をまとめてみましょう。\n\nresults &lt;- list() # 結果を格納するリストを作成\nresults[[\"単回帰\"]] &lt;- res01 # 単回帰の結果\nresults[[\"重回帰\"]] &lt;- res02 # 重回帰の結果\n\nmodelsummary(results, # 結果を表にして出力\n  stars = TRUE, # p値の有意性を星で表示する\n  fmt = '%.2f', # 小数点以下2桁で表示する\n  gof_omit = \"AIC|BIC|Log.Lik.\", # 不要な指標を除去\n  output = 'html' # 出力形式をhtmlにする\n  )\n\n\n\n\n\n単回帰\n重回帰\n\n\n\n\n(Intercept)\n7.77***\n6.30***\n\n\n\n(0.06)\n(0.06)\n\n\nlog_広告宣伝費\n0.55***\n0.32***\n\n\n\n(0.01)\n(0.01)\n\n\nlog_研究開発費\n\n0.40***\n\n\n\n\n(0.01)\n\n\nNum.Obs.\n4442\n4442\n\n\nR2\n0.567\n0.713\n\n\nR2 Adj.\n0.567\n0.713\n\n\nF\n5815.313\n5509.365\n\n\nRMSE\n1.08\n0.88\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\n\n\n広告宣伝費の対数の回帰係数が、単回帰のときの0.55から0.32に減少しています。 これは、研究開発費の対数が追加されたことで、広告宣伝費が売上高を説明する部分が減少したことを意味します。 そして、研究開発費の対数の回帰係数は0.40となっており、広告宣伝費とともに統計的に有意な値となっています。 つまり、研究開発費も売上高を説明する要因となっていることがわかります。"
  },
  {
    "objectID": "Empoli_Chap10.html#単回帰と重回帰の違い",
    "href": "Empoli_Chap10.html#単回帰と重回帰の違い",
    "title": "10  回帰分析の基礎",
    "section": "10.5 単回帰と重回帰の違い",
    "text": "10.5 単回帰と重回帰の違い\n単回帰と重回帰の違いを、実際にデータを使って確認してみましょう。 つまり、以下の3つの回帰モデルの関係について考えてみます。\n\n\\begin{aligned}\ny &= \\beta_0 + \\beta _1 x_1 + \\beta _2 x_2 + e\\\\\ny &= \\alpha_0 + \\alpha _1 x_1 + e_1\\\\\ny &= \\gamma_0 + \\gamma _1 x_2 + e_2\n\\end{aligned}\n\nこのとき、\\beta_1 = \\alpha_1と\\beta_2 = \\gamma_1でとなるのでしょうか？ やってみましょう。\nまず、研究開発費の対数を説明変数として、売上高の対数を目的変数として回帰分析を行います。\n\nres03 &lt;- lm(log_売上高 ~ log_研究開発費, data = df)\n\nこれをmodelsummaryパッケージを使ってまとめてみましょう。\n\nresults &lt;- list()\nresults[[\"単回帰1\"]] &lt;- res01 # 単回帰の結果\nresults[[\"単回帰2\"]] &lt;- res03 # 単回帰の結果\nresults[[\"重回帰\"]] &lt;- res02 # 単回帰の結果\nmodelsummary(results, # 結果を表にして出力\n  stars = TRUE, # p値の有意性を星で表示する\n  fmt = '%.3f', # 小数点以下3桁で表示する\n  gof_omit = \"AIC|BIC|Log.Lik.\", # 不要な指標を除去\n  output = 'html' # 出力形式をhtmlにする\n  )\n\n\n\n\n\n単回帰1\n 単回帰2\n重回帰\n\n\n\n\n(Intercept)\n7.771***\n6.936***\n6.298***\n\n\n\n(0.057)\n(0.064)\n(0.056)\n\n\nlog_広告宣伝費\n0.551***\n\n0.324***\n\n\n\n(0.007)\n\n(0.008)\n\n\nlog_研究開発費\n\n0.631***\n0.402***\n\n\n\n\n(0.008)\n(0.008)\n\n\nNum.Obs.\n4442\n4442\n4442\n\n\nR2\n0.567\n0.595\n0.713\n\n\nR2 Adj.\n0.567\n0.595\n0.713\n\n\nF\n5815.313\n6515.603\n5509.365\n\n\nRMSE\n1.08\n1.04\n0.88\n\n\n\n + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\n\n\n\n\n\n\n\n\n\n\\beta_1 = \\alpha_1と\\beta_2 = \\gamma_1にはなっていないようです。 なぜでしょう？ それは、重回帰分析の係数は、他の変数を一定としたときのある説明変数が応答変数に与える影響の強さ、なので、単回帰ごとの結果と重回帰の結果は異なります。 そのことを確認するために、研究開発費と広告宣伝費の散布図を描いてみましょう。\n\nggplot(df) + aes(x = log_広告宣伝費, y = log_研究開発費) + geom_point() + mystyle\n\n\n\n\n研究開発費と広告宣伝費の間には、やや強い相関があるようです。相関係数は、0.6306058となります。\nこの関係を前提として，単回帰分析の結果から重回帰分析の結果を導出してみます。 この方法を回帰解剖(regression anatomy)といいます。\nまず，売上高の対数を広告宣伝費の対数で回帰した結果から回帰誤差を得ます。回帰残差を取り出すには、residuals()関数を使います。 この回帰誤差は，売上高の変動のうち，広告宣伝費とは関係ない部分といえます。\n\nres &lt;- lm(log_売上高 ~ log_広告宣伝費, data = df)\nresid_sale &lt;- residuals(res)\n\n売上高の自然対数を広告宣伝費の自然対数で回帰した残差をresid_saleに代入しました。 次に，広告宣伝費を研究開発費で回帰します。\n\nres_adv = lm(log_研究開発費 ~ log_広告宣伝費 , data = df)\ncoef(res_adv)\n\n   (Intercept) log_広告宣伝費 \n     3.6582599      0.5639725 \n\n\nこの結果の残差は、研究開発費の対数の変動のうち、広告宣伝費の対数が説明できていない部分です。 つまり広告宣伝費のうち、研究開発費とは関係のない部分となります。 回帰残差を取り出すには、residuals()関数を使います。\n\nresid_adv &lt;- residuals(res_adv)\nplot(resid_adv)\n\n\n\n\n売上高の変動のうち広告宣伝費とは関係ない部分である残差resid_saleを，研究開発費の変動の内広告宣伝費とは関係のない部分である残差resid_advで回帰します。\n\nres_ee &lt;- lm(resid_sale ~ resid_adv)\nround(coef(res_ee), digits = 3)\n\n(Intercept)   resid_adv \n      0.000       0.402 \n\n\nこのresid_advの回帰係数をみると，0.402となっており，前に計算した重回帰分析の研究開発費の自然対数の回帰係数と一致しております。\nつまり，重回帰分析の係数とは，複数の説明変数の中で，他の説明変数とは関係の無い部分が，応答変数と他の説明変数との間の関係のない部分に与える影響の強さを表しているということです。\nここでいうと，重回帰分析における研究開発費の回帰係数の意味するところは，研究開発費の変動のうち広告宣伝費とは関係ない部分が，応答変数の変動のうち広告宣伝費とは関係の無い部分に与える影響，を意味しています。"
  },
  {
    "objectID": "Empoli_Chap10.html#決定係数",
    "href": "Empoli_Chap10.html#決定係数",
    "title": "10  回帰分析の基礎",
    "section": "10.6 決定係数",
    "text": "10.6 決定係数\n重回帰分析の結果を見ると、R^2という値が表示されています。 これは、決定係数と呼ばれる値で、回帰モデルの当てはまりの良さを表す指標の1つです。\n決定係数について，以下の点くらいは覚えておくとよいでしょう。\n\n決定係数は、0から1の値をとります。\n\n決定係数は、説明変数の数が増えると必ず増加するので，重回帰分析では修正決定係数を使うことが多いです。\n\n決定係数が1に近いほど、回帰モデルがデータによく当てはまっていることを表しますが，どれほど高いと良いかの目安はありません。\n決定係数は検定統計量ではないため，すべての回帰係数がゼロであるという帰無仮説を検定するF統計量でモデルの有意性を判断します。\n決定係数以外にも，赤池情報量規準やベイズ情報量規準などの指標もありますが，今回は後者の2つは扱いません。"
  },
  {
    "objectID": "Empoli_Chap11.html#単回帰による統計的推定",
    "href": "Empoli_Chap11.html#単回帰による統計的推定",
    "title": "11  回帰分析による統計的推定",
    "section": "11.1 単回帰による統計的推定",
    "text": "11.1 単回帰による統計的推定\n\n11.1.1 単回帰モデル\n前章では，1つの説明変数xで応答変数yを回帰するモデルを単回帰モデルと呼びました。\n\ny_i = \\beta _0 + \\beta_1 x_i\n\n現実のデータで，1つの説明変数が応答変数を完全に説明できる(つまりモデル上にすべてのデータが載っている)ことはほとんどありません。単回帰モデルに誤差項\\epsilon_iを加えたモデルを考えます。\n\ny_i = \\beta _0 + \\beta_ 1 x_i + \\varepsilon_i\n\nこのモデルを単回帰モデルと呼ぶこともありますが，本書では単回帰モデルとは\\varepsilon_iが正規分布に従うと仮定したモデルを指します。\n図で書くと，次のようなモデルです。\n\n\n\n\n\nあるx_iの値を所与としたときの誤差項の分布が正規分布にしたがう，ので，\n\n\n11.1.2 信頼区間と仮説検定"
  },
  {
    "objectID": "Empoli_Chap11.html#重回帰分析による統計的推定",
    "href": "Empoli_Chap11.html#重回帰分析による統計的推定",
    "title": "11  回帰分析による統計的推定",
    "section": "11.2 重回帰分析による統計的推定",
    "text": "11.2 重回帰分析による統計的推定\n\n11.2.1 重回帰モデル\n\n\n11.2.2 信頼区間と仮説検定"
  },
  {
    "objectID": "Empoli_Chap15.html#ロジスティック関数",
    "href": "Empoli_Chap15.html#ロジスティック関数",
    "title": "12  ロジスティック回帰分析",
    "section": "12.1 ロジスティック関数",
    "text": "12.1 ロジスティック関数\n「当たったか、外れたか」、「ある会計基準を選択したか、否か」、「ある商品を購入したか、否か」など、結果が二値で表されるような変数を二値変数(binary variable)といい、二値変数を応答変数として回帰分析したいとき、ロジスティック回帰分析が便利です。\n応答変数が二値変数ということは、手元の応答変数データは0と1の2種類しかなく、このようなデータを生み出す確率モデルにはベルヌーイ分布が適しています。 ベルヌーイ分布は、確率pで1、確率1-pで0をとる確率分布です。 確率pは、ロジスティック関数(logistic function)と呼ばれる関数で表されます。\n\n\\text{logistic}(x) = \\frac{\\exp(x)}{1 + \\exp(x)} = \\frac{1}{1 + \\exp(-x)}\n\nこのロジスティック関数を使って、確率pを次のように表すことができます。\n\n\\Pr(y_i = 1)  = \\text{logistic}(b_0 + b_1x_i) =  \\frac{1}{1 + \\exp(-\\beta_0 - \\beta_1 x_i)}\n\nこの式は、x_iが与えられたときにy_iが1となる確率を表しています。 この式を変形すると、次のようになります。\n\n\\log \\left( \\frac{\\Pr(y_i = 1)}{1 - \\Pr(y_i = 1)} \\right) = \\beta_0 + \\beta_1 x_i"
  }
]